#+STARTUP: inlineimages

* [2017-04-03 lun.]
** Notes on setting up for the MoNoGe project              :eclipse:emfviews:
Eclipse 3.8 does not start with Java 9 from Oracle.

: sudo update-alternatives java

-> java8-openjdk was installed on the machine

Installed Eclipse 4.6 anyway.

Additional dependencies for the project:

- ATL
- Xtext
- Epsilon (http://download.eclipse.org/epsilon/updates/)

First two can be installed from Eclipse (Help -> Install modeling components).
Epsilon has an update site.

For running the ECNA2014 demo, I will probably need:

- BPMN 2
- RMF (ReqIf)

Short-term tasks:

- Re-run the examples from the video with the source code
- Learn EMF
- Draw a diagram of how EMFViews works, structurally (what plugin does what, how
  they fit together, etc.)

** Importing EMFViews into Eclipse                         :eclipse:emfviews:
For some reason, when importing the plugin projects, Eclipse thinks the packages
in the src/ folder begin with src.  Save for the very first one.

I just need to open the project properties, go to build path, and click apply.
The src folder is already the build path, but the setting is not applied
correctly.

Then, I also need to add the "plugin dependencies" library for each project.

Doing that for all plugins...

There are still errors from missing dependencies.  Why is there no "one-button"
install?

Finally, some discrepancies in version numbers for our own plugins, that could
be tracked to the way different versions of the plugins have been merged into
the repository.

Only 7 errors left out of >1000 thousands when I started.  The remaining errors
I have to look into the APIs of the libraries to see if some things have changed
since 2013.

* [2017-04-04 mar.]
** Inria provided infrastructure                                   :atlanmod:
R told me about continuous integration server provided by Inria.  They run on
jenkins, and we can have a decent amount of VMs apparently.

They also host a GitLab service, so we could host repositories there as well.

** Understanding the code                                          :emfviews:
There's a feature.xml that seem to describe the EMFViews feature, with juicy
info like dependency with version numbers:

: <import plugin="org.eclipse.uml2" version="4.0.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.emf.ecore.xmi" version="2.7.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.uml2.uml" version="4.0.0" match="greaterOrEqual"/>

Not all dependencies have explicit version numbers, but that's a start.

There's also a discrepancy in version numbers: in the feature.xml file, all the
plugins have the version "0.2.0.qualifier", but in the MANIFEST.MF for the
EMFViews plugin, we ask for 1.0.0 versions:

: Require-Bundle: org.eclipse.emf.ecore,
:  org.eclipse.emf.ecore.xmi;bundle-version="2.7.0",
:  fr.inria.atlanmod.emfviews.vlink-mm;bundle-version="1.0.0",
:  org.eclipse.core.resources;bundle-version="3.8.1",
:  fr.inria.atlanmod.emfviews.virtuallinksdelegator;bundle-version="1.0.0",

I understand we also have code generated from ECore models (vlink-mm) which is
checked in the repo.  Since the code is generated from the model, it might make
more sense to not check it in, and regenerate after a ~build~ step.

Other discrepancy: copyright attribution on the feature.xml file is for Inria
Rennes Bretagne Atlantique, while the rest of the plugin, you can see individual
contributor names.  Which is it?

* [2017-04-05 mer.]
** Exploring Eclipse                                     :eclipse:
Specifically, I'm interested in understanding how and where Eclipse saves
preferences for a project: dependencies, how to build, etc.

That's important when putting these things into a repository.

For instance: when I "Run as.. Eclipse Application" an Eclipse plugin like the
one from this [[http://eclipsesource.com/blogs/tutorials/emf-tutorial/][EMF tutorial]], it runs the new Eclipse under another workspace.
The path of this new workspace is specified by the "Eclipse Application" run
configuration.

By default, it is:

: ${workspace_loc}/../runtime-EclipseApplication

So it creates a folder above the current workspace.  Since my workspace is in
$HOME, it creates $HOME/runtime-EclipseApplication.  But, for the purpose of the
tutorial, the files I create in this new workspace should reside inside the
repository.  So, I rather want:

: ${project_loc}/../runtime-EclipseApplication

so it creates the folder at the same level of the project folder I am running.

Now, where is this preference saved?

: $ rg --hidden "project_loc" ./eclipse/ eclipse/ workspace/ proj/monoge/emftuto/
: workspace/.metadata/.plugins/org.eclipse.debug.core/.launches/Eclipse Application.launch

In my workspace.  I guess it makes sense since "Run as..." is an Eclipse thing,
so it should be an Eclipse pref.

But, if you checkout the repository, you would have to manually replicate the
"Run as..." setting in order to get my examples working.

One solution is to export the workspace preferences and put it in the
repository.  So at least, if you use Eclipse, you can import these settings as a
one-click solution.

** Speeding up Eclipse                                              :eclipse:
Even on a powerful and recent machine, Eclipse is quite slow and feels
unresponsive.  Things to set in eclipse.ini to ([[https://www.eclipsecon.org/europe2015/sites/default/files/slides/Boosting%2520the%2520Performance%2520of%2520your%2520Eclipse%2520IDE_0.pdf][allegedly]]) speed it up:

#+BEGIN_EXAMPLE
-server
-Xms512m
-Xmx2g
-Xmn512m
-Xverify:none
-XX:+AggressiveOpts
-XX:+UseParallelGC
#+END_EXAMPLE

Removing unnecessary stuff also helps: Git control, startup plugins,
auto-updates, etc.

Curiously, in the Modeling Tools distribution, there is another EGit plugin that
you also have to remove.

** Trying to replicate the ECNA2014 demo                           :emfviews:
I've got the emfviews plugin building without errors in Eclipse.  Run
as... application (I guess?)

Now to create an EAdata project, add the travelAgencyEA.xmi.

Uhoh, error:

: http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' not found

Hmm hmm.  Maybe I need [[https://github.com/ObeoNetwork/TOGAF-Designer][this plugin]]?

Getting the source, adding the plugin (subfolders) to the EMFViews workspace,
and adding them as a dependency for the EMFViews plugin, running "Run as.."
again.  I can check in Help -> Installation details of the recursive Eclipse
that EMFViews and TOGAF plugins are both present.

After that, opening the travelAgencyEA.xmi again yields:

: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'belongsTo' not found. (platform:/resource/EAdata/models/1_travelAgencyEA.xmi, 26, 270)

A bunch of them.  'isOwnedByUnit', 'communicatedWithFunctions',
'providesEntities', 'containers', 'labels'.

And some IllegalValueExceptions:

: Value 'BusinessService[TRANSIENT]' is not legal. (platform:/resource/EAdata/models/1_travelAgencyEA.xmi, -1, -1)

Could it be a mismatch between the TOGAF version I'm using and the one used in
the demo?

Grepping around the TOGAF repo, I can see hits for these strings, especially in

: plugins/org.obeonetwork.dsl.togaf.contentfwk/model/contentfwk.aird

#+BEGIN_EXAMPLE
1277:      <ownedDiagramElements xmi:type="diagram:DEdge" xmi:id="_eyUzMP63Ed-AK7xgn-H1PA" name="[0..1] isOwnedByUnit - [0..*] ownsFunctions" sourceNode="_ugYTwJ-9Ed-hg-_nMagkzg" targetNode="_zjeaMJ-9Ed-hg-_nMagkzg">
1280:        <semanticElements xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2562:        <lines xmi:type="table:DLine" xmi:id="_BsDvz6AREd-mRqry0T_xvQ" label="EReference : isOwnedByUnit">
2563:          <target xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2564:          <semanticElements xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2567:            <target xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
#+END_EXAMPLE

I can also see these strings in the EA.ecore metamodel, and these looks like
definitions.

Maybe the example was self-sufficient after all.  But how to link the XMI file
to an ECore metamodel?

Further investigation.  If I load up the TOGAF contentfwk model (one I found to
load it is to create a dummy ECore file, and Right click -> Load resource, and
look for the obeo URL near the bottom).

I can see the mismatch.  The TOGAF contentfwk has, in the Function class:

- communicatesWithFunctions
- isOwnedByOrganizationUnit

whereas the EA.ecore has:

- communicatedWithFunctions
- isOwnedByUnit

So the errors make sense.  And, it would seem that I need to point the XMI files
to use my EA.ecore metamodel.

Looking for help.. G helpfully answered my questions:

You can't link an XMI to an Ecore as-is.  Eclipse has a global registry of
metamodels, and there is no way to Right-click on an Ecore file, and add it to
the registry.

(Unless, possibly maybe, through some ATL plugin, but I don't have it installed
right now)

The alternative is to generate plugin code from the Ecore metamodel, and "Run
as.." again.

So:

In the base Eclipse workspace (where the EMFViews plugin resides), create an
empty EMF project add the EA.ecore file to the model folder.  Create a genmodel
file, and generate the model code.

Then, launch the recursive Eclipse.  All open projects will be loaded as
plugins, so no need to add this project (or TOGAF) as dependency to EMFViews.

This time, I can load the XMI without troubles.

The two other XMI files require BPMN2 and ReqIf10.  At this point, I'm
remembering that the emfviews repo had a "dropins" folder containing JAR files
for BPMN, ReqIf and.. TOGAF contentfwk.  And eclipse has a dropins folder as
well.

I'm thinking that the dropins are supposed to be added to Eclipse in order to
run the examples.

And indeed, it works.
For BPMN2 and ReqIf.  For TOGAF, I get a NullPointerException when trying to
open the Ecore file.  So maybe sticking to what I have generated is better.

Next step in the demo is to create an EMF Viewtype through an Eclipse wizard.  I
don't have that wizard in my recursive Eclipse.  Probably because the "editor"
and "ui" plugin projects are closed in my base Eclipse.

Let's open them.

Uhoh, compile error.

: Viewtype.getHiddenElements()

is undefined.  There is a ~getHiddenAttributes()~ method though.  Let's try
that.

Haha!  Now I have the wizard in my recursive Eclipse.  Clicking next
enthusiastically and:

: java.lang.ArrayIndexOutOfBoundsException: 0
: 	at fr.inria.atlanmod.emfviews.ui.wizard.view.CreateViewtypeScreen.createControl(CreateViewtypeScreen.java:132)

:(

Time to quit for the day.

* [2017-04-07 ven.]
** IndexOfOfBounds exception                                       :emfviews:
Okay so, the incriminating line:

: comboLinksDsl.setText(availableLinksDsls[0]);

We made no provision to check that this array (of strings) had any element, and
we access the first one.

Let's add a check.  I guess I'll be greeted by an empty window, since it means
we haven't found any LinkDSL, but at least I won't crash.

(Though, like JavaScript, Eclipse doesn't crash: it just throws an Exception and
keeps going).

Changing the array value at runtime in the debugger to {"foo"} let me proceed.
I can add the metamodels.  But I can't select any linking DSL (since there is
none, and "foo" isn't a valid one I'd wager).

(To change an array of String in the debugger, right-click -> change value, and:

: return new String[]{"foo"}

primitive values are easier to change, usually just click.)

Still, it let me proceed to the next screen.  Of course, "Finish" triggers a
NullPointerException.

In the demo video, he has "ecl" as DSL language.

Looking at the code that populates availableLinksDsls, it iterates into:

#+BEGIN_SRC java
extensions = Platform
				.getExtensionRegistry()
				.getExtensionPoint(
						"fr.inria.atlanmod.emfviews.virtuallinksdelegator.type")
				.getExtensions();
#+END_SRC

But this is also empty.  I guess because I haven't opened
virtuallinksepsilondelegate.  Let's do that.

I need ECL to compile it.  It comes from org.eclipse.epsilon.  Let's not install
that into Eclipse, but put the JAR in dropins instead.  Wait no, I don't want it
to run as plugin in my Eclipse.  I just need to add it as a dependency to the
project.

Import errors disappear.  Other errors appear.  Deprecated methods
and... methods that are not here anymore.  Presumably because I got the latest
ECL version, and the project used another one.  Is there any trace of the
versions we used previously?

In emfviews/feature.xml:

: <import plugin="org.eclipse.epsilon.ecl.engine"/>
: <import plugin="org.eclipse.epsilon.eol.engine" version="1.0.0" match="greaterOrEqual"/>

Let's try the 1.0.0 version then.  It's from 2012.  I guess the project was
working in 2016, so let's try the 1.3 instead.

1.3 makes one error disappear, still 2 left.  1.2 has only deprecation warnings.

Still errors in the MANIFEST file for unmet dependencies.  But it's for stuff we
don't need, otherwise we wouldn't compile, right?  Let's ditch them.

Ah!  I've got "ecl" in the dropdown menu now.  But clicking "Finish" triggers a
NullPointerException in CreateViewtypeWizard.  It's because we want to open the
newly created .eviewtype using our editor for that file type, and we fail in
Viewtype.loadFilterMetamodel:

#+BEGIN_SRC java
private void loadFilterMetamodel(String filtersMetamodel) {
  ResourceSet filtersResourceSet = new ResourceSetImpl();
  attributesToHideMM = filtersResourceSet.getResource(URI.createPlatformResourceURI(filtersMetamodel, true), true);
}
#+END_SRC

because filtersMetamodel is null at this point.

Culprit: Viewtype.doLoad which pass

: loadFilterMetamodel(properties.getProperty("filtersMetamodel"));

but there is no "filtersMetamodel" property there.  "properties" is created from
parsing an inputStream which seem to correspond to the contents of the eviewtype
file.  And the eviewtype file has no filtersMetamodel value.

When is this written?

Line 545, in Viewtype.serialize.  It puts the value of ~filtersMM~, which is a
String, and populated in the constructor of Viewtype.  Hmm, so that's actually
just the serialization of a Viewtype, but since the constructor already calls
loadFilterMetamodel, I guess this is the wrong place.

In CreateViewtypeWizard.performFinish, we are writing to the eviewtype file.
Then it calls

: serializeViewtype(viewTypeFile, fileContent);

Stepping through CrewteViewtypeWizard.performFinish, there is no code adding the
"filtersMetamodel" line.  And I see no trace of code that /would/ add these
lines to the file.

Also, in the video, there are four files created by the wizard: an ECL, an
Ecore, an EViewtype and an XMI.

I've only got two: EViewtype and XMI.

Strange.

** Reading about Eclipse as a platform                              :eclipse:
http://www.aosabook.org/en/eclipse.html

All classes in a plugin are not considered part of the plugin API.  You need to
define extension points for that.  Visibility of class/method/attributes
is presumably restricted to your plugin.

At Eclipse startup, all plugins manifests are scanned to know the extension
points in advance, but the plugins themselves are not loaded.  It's very much
like Emacs autoloads: they give an example of a plugin adding a menu item, and
only when the user clicks on the menu item will the corresponding plugin be
actually loaded.

Instead of Swing or AWT, Eclipse uses SWT as widget toolkit.  JFace comes on
top, and provides frameworks for preferences and wizards.

Hmm the bit about plugin class visibility is somewhat in contradiction in \sect6.2:

#+BEGIN_QUOTE
If plugin A requires plugin B, plugin A can see all the Java classes and
resources from B, respecting Java class visibility conventions
#+END_QUOTE

Ah I get it know: the above describe the situation before the move to OSGi, and
the paragraph at the start describes the situation after the move.

#+BEGIN_QUOTE
With the switch to OSGi, Eclipse plugins became known as bundles. A plugin and a
bundle are the same thing [...]  Previously, dependencies, exported packages and
the extensions and extension points were described in plugin.xml. With the move
to OSGi bundles, the extensions and extension points continued to be described
in plugin.xml since they are Eclipse concepts. The remaining information was
described in the META-INF/MANIFEST.MF, OSGi's version of the bundle manifest.
#+END_QUOTE

Good news: OSGi supports semantic versioning, very much like SemVer:

major.minor.service.qualifier

Increment major when breaking API
Increment minor when adding API
Increment service for bug fixing
Qualifier is used to indicate a build tag

It's OSGi that takes care of resolving dependencies for a package.

Ah: apart from the extension registry in Eclipse, there is also a service
registry provided by OSGi.  Unlike extensions, services can be discovered
dynamically, after startup.

#+BEGIN_QUOTE
A feature is a PDE (Plugin Development Environment) artifact that defines a set
of bundles that are packaged together in a format that can be built or
installed. Features can also include other features.
#+END_QUOTE

p2 has replaced Update Manager for provisioning Eclipse.  Might be useful for
continuous integration.

** What if I provide filtersMetamodel myself?                      :emfviews:
Since it seems this line is not going to write itself in the eviewtype file,
might as well put it, just to see if the rest of the demo can work.

Ah yes, of course, it points to an ECore file that was also not generated.
Let's bring that in.

Hmm, this time I have a NPE in ViewtypeEditor.createViewtypeTreeEditorPage,
at this line:

: treeViewer.setInput(((Viewtype) viewtypeResource).getResourceSet().getPackageRegistry().values());

because the ~getResourceSet()~ returns null.  The viewtypeResource is populated
from the file at the beginning of the try block:

: viewtypeResource.load(uri.toURL().openStream(), new HashMap<Object, Object>());

and after that, the resourceSet attribute is null.

Since viewtypeResource is an EMF Resource object, maybe a change in the EMF API?

I am tempted to try archeology and rebuild an environment circa 2014.  Here I've
got EMF Ecore 2.12.0 and the feature... has no version requirement.

But, there are version requirements for:

: <import plugin="org.eclipse.emf.ecore.editor" version="2.8.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.emf.ecore.xmi" version="2.8.1" match="greaterOrEqual"/>

and I've got 2.12 loaded, again.  So since these are part of EMF, a safe guess
would be to find EMF Ecore 2.8.

2.8 is from 2012.

Now, according to the semantic versioning, that shouldn't change anything,
right?

Hmm, trying to put the EMF 2.8 JARs into a copy of my Eclipse Neon 3 resulted in
lots of deep stack straces and an error at launch.  p2 couldn't resolve the
frankenEclipse I created I guess.

Let's get a MDE Eclipse circa 2012 then.  Luna is the first version supporting
Java 8.  That's 2014; maybe it will still make a difference.

Ah of course, I have to set up a new workspace.

Hmm, just importing the projects, and everything builds without errors.
Adding dropins, TOGAF project...

And same exact error!  ViewtypeEditor.createViewtypeTreeEditorPage.

So I guess I would like to know what a ResourceSet is, and what value it should
take at this point.  Maybe brush up my EMF knowledge.

* [2017-04-10 lun.]
** Trying to replicate friday's situation: new error       :eclipse:emfviews:
Can't even get to the EViewtype creation wizard as Eclipse crashes on load with:

: org.eclipse.core.runtime.CoreException: Plug-in "fr.inria.atlanmod.emfviews.virtuallinksepsilondelegate" was unable to instantiate class "fr.inria.atlanmod.emfviews.virtuallinksepsilondelegate.EclDelegate".

How in hell did it work Friday?

Looking at changes I did on the project in Git... wow, there are .class files
checked in.

There are also ~._trace~ files, which I understand are generated by Xtex.  Since
I'm not dealing with Xtext there, and these are generated files, I'd rather get
rid of them.

Some .classpath are checked in, some are not.

Let's just remove the useless files and ignore them to get a usable git diff.

Now, I did modify the MANIFEST which included ECL.  Maybe this wasn't a good
idea?

If I restore these lines, Eclipse complains that it cannot resolve bundles
pertaining to ECL in the MANIFEST of virtuallinksepsilondelegate.

The JARs are in the build path, but maybe they need to be loaded into Eclipse
instead.  Let's remove them from the build path.  Cannot build now because
imports are not resolved.  Let's add them as drop-ins.

Hmm, they don't seem to be recognized when added to the dropins folder.

Opening Window -> Show view -> Error log displays the errors when loading
Eclipse.  To start, I can see that it's trying to load the Git plugin for each
project, even though I've removed it.

Removing all org.eclipse.team plugins fails to start Eclipse.  It's not as
modular when many pieces depend on each other!

Restoring team.core and team.ui did the trick.  At least I got rid of CVS.
I might investigate a minimal Eclipse setup another time.  And one that can be
auto-provisioned trough a config file for reproductibility.

Still have GitProvider errors.  Why is it trying to load the plugin?  Since I
see to Git-related feature under eclipse/features, I'm guessing Git is tightly
integrated into another feature that is still being loaded.  Ugh.

In any case, I can see errors related to my dropins JAR:

#+BEGIN_EXAMPLE
!ENTRY org.eclipse.equinox.p2.publisher.eclipse 4 0 2017-04-10 15:04:47.288
!MESSAGE Unable to acquire PluginConverter service during generation for: /home/fmdkdd/eclipse/dropins/epsilon-1.2-emf-src.jar.

!ENTRY org.eclipse.equinox.p2.core 4 0 2017-04-10 15:04:47.411
!MESSAGE Provisioning exception
!STACK 1
org.eclipse.equinox.p2.core.ProvisionException: No repository found at jar:file:/home/fmdkdd/eclipse/dropins/epsilon-1.2-emf-src.jar!/.
#+END_EXAMPLE

(the Error log view just pretty prints the content of .metadata/.log ... without
giving you the ability to copy lines; and why is there a hidden file in a hidden
folder?  Grmpf).

Maybe, the 1.2 JAR of Epsilon is not OSGi compliant or whatever.  Let's try to
dropins the 1.4.

Hmm nope, same error.

Okay then let's install them from inside Eclipse.  Version 1.2, preferably.

That does get rid of the build errors and MANIFEST errors.  Now, to run.

I have worrying warnings in my .log though:

: org.eclipse.core.runtime.CoreException: Executable extension definition for "class" not found.

But, I can launch the recursive Eclipse.  So, lessons learned:

Required bundles are actually runtime requirements?

** Explaining the discrepancy with the 2014 demo                   :emfviews:
According to H, the previous engineers might have already started some
refactoring in the goal of simplifying Viewtype creation.  In the demo, we see
an Ecore file being created along the Eviewtype.  That's something H did not
want, since we could just register the selected filters in the XMI itself.

In the current version, there is no Ecore file being generated, and the
XMI contains the line:

: <linkedElements elementRef="//Process" modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0" name="Process" estructuralFeatures="isAutomated"/>

which corresponds to what I've cliked on in the last step of the wizard.

In emfviews.core.Viewtype, there is a serialize method that added the
filtersMetamodel line that was in the demo.  It isn't called anymore by the
wizard.

Looking through the history of this file and in the commit history, all I can
see is that there was a first version of emfviews (0.1 I presume) with a vastly
different Wizard.  Then there was a version 2 (0.2), where the wizard was
changed to basically what I have inherited.

In any case, we don't have a definitive reference of source of truth for "how it
should work" other than examples and videos.  Possibly outdated.

Better brush up my knowledge of Eclipse plugins and EMF.

** A clean Eclipse                                                  :eclipse:
I've found the minimal Eclipse experience:

From [[http://download.eclipse.org/eclipse/downloads/][this page]], go to the latest release, and grab the "Platform runtime binary"
for your arch.

Very snappy Eclipse.  No crap like Mylin and EGit installed by default.

Then, I can pass a configuration folder on the command line:

: eclipse -configuration ~/eclipse-configs/test/configuration

From there, I can install new software from inside eclipse, and they will be
installed at eclipse-configs/test/plugins.  The eclipse-configs/test folder
becomes the new home folder for eclipse.

No pollution between configurations.

So that's good for reproductible environments (except, you know, the manual step
of actually provisioning Eclipse with the new packages).

But now if I need to install the Java dev tools for every
configuration... or even update them... that's going to be a pain.  Ideally, I
read somewhere that p2 was able to pool from a common bundle.  So I should be
able to download all this stuff in just one place, then let Eclipse get the
plugins from one pool.

But I really don't want Eclipse to load /all/ the plugins in the pool.  Even if
it's "lazy-loading" them, it's still taking ages AND I have no say in how
what plugins are /actually/ loaded even if I don't use them.

* [2017-04-11 mar.]
** Trying bundle pools in Eclipse                                   :eclipse:
For speeding up provisioning, and making updates more sane.

I tried to use Oomph, which is actually the Eclipse Installer, the default
download provided by Eclipse.  In the advanced mode, you can select the Eclipse
Platform, and additional projects.  Except, these are pulled from master and put
/into/ your workspace; not additional plugins.  The use case this solved is when
you want to contribute to some Eclipse project.

It also works with any Github project, so I guess you could use Oomph to
somewhat easily provision an Eclipse to work on EMFViews.  You just have to say
"pick the MDE product, then add EMFviews, done".

But in my case I don't want all the cruft.

What you should be able to do is run Oomph, install an Eclipse platform, and
that Eclipse will be setup to get its bundles from the bundle pool.  Except
Oomph fails to install Eclipse platform.

Well, so much for saving bandwidth.

** Installing EMF tools in the platform                             :eclipse:
So installing the EMF sdk feature is apparently not enough to run the tutorial.
I lack emf.edit.  Even though they are part of EMF Core, according to [[http://www.eclipse.org/modeling/emf/][the
website]].

Maybe I'm not pulling from the correct update site?

Adding the update site mentioned on [[http://www.eclipse.org/modeling/emf/updates/][this page]] does not work.  After adding it to
the available sites list in the preferences, and loading up the preferences
again, the site has mysteriously disappeared.

But, there is an update site with URL:

: http://www.eclipse.org/modeling/updates/

disabled by default.  Enabling it and going through "Install new software",
selecting it...

waiting a long time...

Now it has added a bunch of other sites (what?)

And I can install EMF... 2.7.  From 2012.

Gosh, why is this so hard?

On [[http://www.eclipse.org/modeling/emf/downloads/][this page]], it seems I can /download/ an update site containing EMF.  So let's
try to add this ZIP as a local update site.

It does not disappear from the list when I leave it there.

And it's lightning fast when I go into "Install new software".  And it's version
2.12

But EMF Edit is grayed out, since it's already installed.

Removing... installing from this local update site...

EMF edit plugin is marked as loaded in Eclipse, but it's marked as not found in
the plugin.xml dependencies.

Let's remove everything EMF related, and try to load it as a dropin.

There's no dropins folder in my test configuration.  AAArgh.

There's one in eclipsen/platform though.

Hmm, maybe I only have the /runtime/, and not the SDK.  That's another download
on the page.  Let's try that.

Well, the SDK feature seems to only add documentation and source.  No
difference.  Other than that, still not finding emf.edit.

Ah, it works!  [[https://www.eclipse.org/forums/index.php/t/134617/][This thread]] was golden.  Apparently, for building plugins, you
need to setup the Target Platform correctly.  And, for some reason, even though
in my two workspaces they target platforms are set up correctly, they do not
find the same plugins.  One finds 190 plugins, the other 316.

Trying to clean up my test configuration now... trying to install things in
dropins, but that's a BadIdea.  Stuff's missing.  "Install new software" works
when I pull from the default update sites.

Installing PDE, JDT and EMF is enough to be able to run the tutorials.

** Eclipse plugin tutorial                                   :eclipse:plugin:
Following "Eclipse 4 plug-in development by example", by Alex Blewitt, Packt
Open Source.

Plugins which add to the UI or require the UI to operate conventionally have
'ui.' in their package name.

MANIFEST.MF file is for dependencies (OSGi-related stuff).  While the plugin.xml
file is for describing extensions and extension points.

Having extensions described as XML speeds up plug-in loading: you don't have to
execute any code of the plugin (though you do need to parse XML).

** Some links on building plugins with Maven+Tycho           :eclipse:maven:
https://zeroturnaround.com/rebellabs/building-eclipse-plug-ins-with-maven-3-and-tycho/
http://www.vogella.com/tutorials/EclipseTycho/article.html

* [2017-04-12 mer.]
** Eclipse plugin tutorial (cont.)                           :eclipse:plugin:
Clock tuto.

Some issue with Display.getDisplay() that crashes when launching Eclipse with
multiple monitors.  Did not happen when hot loading the code.

How are you supposed to get the current display then?

* [2017-04-14 ven.]
** Eclipse plugin tutorial (cont.)                           :eclipse:plugin:
Re: error from last time.  [[http://stackoverflow.com/questions/33157856/getting-swterror-not-implemented-multiple-displays-with-simple-code-sample][Found someone]] who raised the error on SO.  No answer,
no fix.

From what I gather, you /shouldn't/ use Display.getDisplay, since it creates a
new display (that you need to dispose of).

(Also, the error has nothing to do with multiple /monitors/, but multiple
Display objects as understood by Eclipse.)

If I use Display.getCurrent instead, I get null back, since no display has been
created when Activator.start is called.  Another suggestion is to use:

: PlatformUI.getWorkbench().getDisplay()

this also fails on startup with:

: java.lang.IllegalStateException: Workbench has not been created yet.

Again, it seems the plugin is started very early in the process.  One workaround
would be to create the tray item as soon as the workbench started.  This is
[[https://wiki.eclipse.org/FAQ_Can_I_activate_my_plug-in_when_the_workbench_starts%253F][possible]].

Yep, this works nicely.

** Resource management in JFace and SWT
SWT has manual resource management: when create instance of Color or Image, you
are supposed to .dispose() of them when you don't need them anymore.  That way,
SWT, releases the associated native objects.

JFace has resource registries to deal with the allocation and disposal of resources.

* [2017-04-19 mer.]
** Nearly done with the Eclipse Plugin book                  :eclipse:plugin:
Lots of learning were had.

Chapter 9 touches automated testing with JUnit.  Nothing fancy; plugins just
need to run with a special JUnit configuration.

More interesting is the UI testing with SWTBot, to simulate click and go through
the UI programmatically.  It's fun seeing Eclipse launch and crunch through
dialogs at inhumane speeds.

Although, even if the JUnit bar fills with green, I get a bunch of Exceptions in
the host console after the tests are run.  Presumably, SWTBot is too fast for
Eclipse, and does not take care of disposing some resources properly when
exiting then client instance.

: org.eclipse.swt.SWTException: Failed to execute runnable (org.eclipse.swt.SWTException: Widget is disposed)

** Building the plugins with Maven+Tycho                      :maven:plugin:
Following Chapter 10 of the book.  Apart from writing XML files, it's rather
smooth.

: mvn clean package

seems to poll the Eclipse update sites on each build, which takes a loooooooong
time.  You can avoid that check with the ~--offline~ flag:

: mvn --offline clean package

Hmm can't seem to run the SWTBot tests using Maven.  Might be that the book is
slightly outdated, as it was tested with Tycho 0.18, whereas we now have Tycho
1.0.0.

[[http://www.vogella.com/tutorials/EclipseTycho/article.html][This tutorial]] is fresher.

Still have troubles loading requirements for the test... It seems the client
Eclipse launched by Maven is really barebones (good): there are basically no
views!

I should at least get the Clock View that the tutorial plugins adds.

From what I understand, Maven /should/ obey the plugin dependencies in the
MANIFEST file.  But the runtime target configuration is different.

Maybe try to test with a barebones run configuration in Eclipse itself.

* [2017-04-21 ven.]
** Getting Maven+Tycho to run the tests                        :maven:plugin:
Trying with a barebones run configuration in Eclipse.

Only adding "Required plugins".  Cannot validate due to a not very talkative
error:

: org.eclipse.e4.ui.workbench.swt [9]
: Unresolved requirement: Require-Capability: osgi.extender; filter:="(&(osgi.extender=osgi.component)(version>=1.2)(!(version>=2.0)))"

Maybe it's a [[https://bugs.eclipse.org/bugs/show_bug.cgi?id=494913][bug]]?  Anyway, adding org.eclipse.equinox.ds and clicking "Required
plugins" (for the requirements of equinox) fixes it.

Another way to do it is to add equinox.ds to the dependencies in the MANIFEST,
saving it, and and clicking "Required plugins".  But at this point I don't know
if these dependencies should be declared in the MANIFEST itself...!

Now:

: org.eclipse.core.runtime.AssertionFailedException: null argument:Could not find IExtension for application: org.eclipse.ui.ide.workbench

I know that it works if I select all plugins in the Target Platform, so the
question is: which plugin is missing?

: org.eclipse.ui.ide.application

seems to do it.  At least the client Eclipse runs, but the tests all fail, and
the console is full of:

: Event Admin service is not available, unable to publish event org.osgi.service.event.Event

Adding org.eclipse.equinox.event to the dependencies solved it.  Thanks [[https://www.eclipse.org/forums/index.php/t/293382/][thread]].

Now only the third test fails:

: org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException: Timed out waiting for tree item General

Because when SWTBot does File->New->Project, the dialog is empty.  There's no
General folder.  There's only "Project", no categories.  Hmm, then I can just
use "Project" without adding another dependency.

It works.. not.  It creates the project, but the assertion fails.  Somehow it
runs too fast and does not wait for the project to be created.  Adding a
bot.sleep does it, but there's a nicer way with wait conditions.

Okay so now, back to Maven.

: Tests run: 3, Failures: 0, Errors: 0, Skipped: 0

Actually, before that, I had to remove one testUI that's just too brittle, the
one testing against the String value of the SWTBot shells.

But, it works.

** General best-practices for Eclipse plugins               :eclipse:plugins:
In Mastering Eclipse Plugin Development, by the same author as the tutorial book
I finished this week, there's a chapter Designing Modular Applications with some
pointers on best practices for Eclipse plugins.

How semantic versioning works for Java.  Like semver, adding a method is a minor
increase, changing or removing API is a breaking change.  In Java, adding
methods to interfaces is a breaking change, since classes that implement this
interface have to be modified.  Interfaces can be @noimplement, and adding
methods to these is only a minor version increase.

There's also the @since annotation which is rather useful.

There are tools for looking at the API of your releases and suggesting the
correct semantic version increases, like the API baseline in Eclipse.  Maven can
also do it.

** State of EMFViews                                               :emfviews:
We have no tests.  But, there are 15 examples in the examples/ folder.  Do they
still all work?

I've already asserted that the project is not in the state of running the ECNA
demo from 2014.  (Might not be too far, but things have changed since the demo
at least).

The examples are mostly models: XMI, Ecore, UML files.  Cloc is in fact totally
unable to give me a count, as it ignores basically all files except one in this
folder.

More interesting is when I cloc the plugins directory:

#+BEGIN_EXAMPLE
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Java                           223          12613          19404          36444
Assembly                         3              0              0           6062
XML                             14             44             18            978
-------------------------------------------------------------------------------
SUM:                           240          12657          19422          43484
#+END_EXAMPLE

That seems like a lot of Java.  And assembly, strangely.  But many Java files
are in fact generated.  Let's look at only emfviews.* plugins.

#+BEGIN_EXAMPLE
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Java                            58           1268           3376           4856
XML                              7             11              2            149
-------------------------------------------------------------------------------
SUM:                            65           1279           3378           5005
-------------------------------------------------------------------------------
#+END_EXAMPLE

Less daunting.  Many files are smallish to tiny:

: cloc --by-file plugins/fr.inria.atlanmod.emfviews.* | cut -c180-190

#+BEGIN_EXAMPLE
588
272
234
204
188
179
173
167
154
153
139
134
129
126
126
113
110
106
98
93
83
82
77
77
74
73
70
65
60
58
56
55
54
51
50
48
43
38
37
31
24
24
21
20
20
19
16
15
15
15
15
15
15
12
11
11
10
10
10
9
7
7
6
5
5
#+END_EXAMPLE

The largest one is emfviews.editor.editors.ViewtypeEditor, which looks all hand
coded and not generated.

[Still have issues with Epsilon missing; have to install 1.2 from the update
site; ecore, ecore development tools, emf; and also UML2 extenders from the Neon
update site... it builds!]

Now let's look at the dependencies.

* [2017-04-24 lun.]
** Dependency graph for EMFViews                                   :emfviews:

[[file:doc/emfviews-plugin-dependencies.svg]]

All the beige boxes are plugins, eggs don't have a plugin.xml, and all are
included in emfviews.feature.

Most depend on the VirtualLinks model, as expected.

Even though it's included in the feature, emfviews.util has no plugin.xml, and
contains only public static methods.

Curiously, virtuallinksocldelegate does not depend on virtuallinksdelegator,
because it does not implement the interface IVirtualLinksDelegate, even though
virtuallinksepsilondelegate does.

In fact, I'm not sure the OCLDelegate is plugged into anything.  The
VirtualLinksDelegator declares an extension point that is used by the
EpsilonDelegate, but not the OCLDelegate.

There are also two plugins (cream) not declared by the feature.  They don't
compile due to change to emfviews.core, so not sure what their role is.

Other plugins: vpdl.dsl.* and monoge.dsl.*.  VPDL is the View Point Description
Language mentionned in the EMFViews paper.  It seems monoge.dsl.* fits the same
role; all of it was added in one commit title "Added DSL for metamodel
extension".  It might do more.  Hard to say.  Most of it is generated by Xtext.
Have to lookup how Xtext works.  On a cursory examination, monoge.dsl.* seems
less fleshed out than Vpdl.

** Point with H                                                    :emfviews:

- Merge emfviews.util in emfviews preferably
- Merge virtuallinksdelegator in vlink-mm
- monoge.dsl is the DSL for the second paper, vpdl.dsl is the DSL for the first
  paper.  Both are useful, but will be tackled later.
- Check for dead code, duplicates.
- Remove unnecessary dependencies that come from transitivity (if you include
  emfviews, you don't need to include vlink-mm explicitly).

* [2017-04-25 mar.]
** Cleaning up warnings                                            :emfviews:
Mostly generics missing, unused vars, and other niceties.

Could not get at everything, since I don't understand the code fully yet.

* [2017-04-26 mer.]
** Still cleaning up and formatting                                :emfviews:
The autoformatter of Eclipse is helpful, but for wrapping especially, multiple
rules can apply, and I'm not sure of the priority between them.  At least, the
process is deterministic (I hope).

Some things are plain weird in the code.  Pretty sure I am looking at dead code
sometimes, but Eclipse cannot tell me that because these are all plugins, and
public methods are part of the API.

Trying to eliminate the dead code...  Eclipse can tell me if a method is used
in the workspace with Ctrl+Alt+H.  That's helpful.  Then, let's say method M is
unused and I remove it.  M called A.  Now A is unused, and Eclipse tells me so.
But if A was the sole caller of B, Eclipse does not immediately tell me by
transitivity that B is also unused.  A bit annoying.

Wait no.  That's not the good approach.  If B subclasses A, and B is given as an
A somewhere, Eclipse can't know that the overridden methods in B will be
called.

Checking for unused constructors I think should be safe.  Static methods as
well.  And methods that are not overridden.

The case of emfviews.elements.MergeElementsImpl is curious: I can't find any
calls for its constructor, but there are references to /casts/ to this class.
Maybe the instances are created through reflection somewhere, but grepping
around does not help.  Also, it seems it's only partially implemented, as
presumably emfviews.rules.MergeRule is strongly related, and most of the methods
there return null.

So, I'm not sure what's truly dead code and what was just forgotten.  Observations:

In emfviews.ui.CreateViewWizard.performFinish, I have a
EMFViewsFactory.createEView call that's seemingly unused.  Instead, we write
directly to a file in the code that follows.  Same thing with the createViewtype
constructor in the factory; it's called nowhere, and in turn one Viewtype
constructor is never called.  In Viewtype.serialize, there's a bunch of stuff
that's eerily similar to EView.serialize.

That was a part that didn't seem to work when I tried to replicate the ECNA
demo... definitely a hot point.

* [2017-04-28 ven.]
** Looking at the examples                                         :emfviews:
Okay so from what I can see, the examples all contain model files (ECore, XMI,
UML).  No code.

Crucially, the only instructions to use the examples are in videos.  Some
examples contain already-created viewtypes and views.

Opening a viewtype file with the viewtype editor throws an exception:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at org.eclipse.emf.common.util.URI$URIPool$PlatformAccessUnit.setValue(URI.java:865)
	at org.eclipse.emf.common.util.URI$URIPool.intern(URI.java:1949)
	at org.eclipse.emf.common.util.URI.createPlatformResourceURI(URI.java:2680)
	at fr.inria.atlanmod.emfviews.core.Viewtype.loadFilterMetamodel(Viewtype.java:171)
	at fr.inria.atlanmod.emfviews.core.Viewtype.doLoad(Viewtype.java:160)
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:1518)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createViewtypeTreeEditorPage(ViewtypeEditor.java:118)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createPages(ViewtypeEditor.java:445)
#+END_EXAMPLE

The ER2015 video shows that you can also open the viewtype as an ECore model.
Doing that also throws an exception:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl$4.getChildren(ResourceImpl.java:522)
	at org.eclipse.emf.common.util.AbstractTreeIterator.hasAnyChildren(AbstractTreeIterator.java:97)
	at org.eclipse.emf.common.util.AbstractTreeIterator.hasNext(AbstractTreeIterator.java:85)
	at org.eclipse.emf.ecore.presentation.EcoreEditor.createModel(EcoreEditor.java:1278)
	at org.eclipse.emf.ecore.presentation.EcoreEditor.createPages(EcoreEditor.java:1339)
	at org.eclipse.ui.part.MultiPageEditorPart.createPartControl(MultiPageEditorPart.java:363)
#+END_EXAMPLE

This one is more concerning, since it's not tied directly to any code in our
plugins.  Might be that we implement some interface incorrectly.

** Trying to open an eviewtype with the editor                     :emfviews:
So the first NPE was due to missing plugins.  This line in Viewtype:

: EPackage contributingEcoreModelPackage = EPackage.Registry.INSTANCE.getEPackage(modelURI);

was returning null.  The modelURI came from the eviewtype file:

#+BEGIN_EXAMPLE
contributingMetamodels=smartEAintegration/metamodels/contentfwk.ecore,http://www.omg.org/spec/BPMN/20100524/MODEL-XMI,http://www.omg.org/spec/ReqIF/20110401/reqif.xsd
#+END_EXAMPLE

In Viewtype.loadContributingMetamodels, we split on this property value, and for
each model, we make a copy of it and in the copy remove attributes and
classifiers.

But this was null, since the plugins were not in the registry.  This should be a
better error.

Anyway, I could have added the model plugins in the dropins folder of my
Eclipse, but I wanted them to run only on the target configuration.  Going into
run configurations, you cannot add arbitrary plugins that are not already loaded
in the current Eclipse: the plugins can only be a subset of the workspace +
target platform.  But you can change the target platform.  And there, you can
add arbitrary plugins.

Adding the model plugins and their requirements did the trick.

Now, another NPE:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createViewtypeTreeEditorPage(ViewtypeEditor.java:143)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createPages(ViewtypeEditor.java:445)
#+END_EXAMPLE

This is because of that line:

: treeViewer
          .setInput(((Viewtype) viewtypeResource).getResourceSet().getPackageRegistry().values());

Namely, viewtypeResource.getResourceSet is null.  [[*What if I provide filtersMetamodel myself?][Wait a minute]].  I got to the
same conclusion two weeks ago.  But then, I have no idea why the resourceSet is
null.

All I know is Viewtype extends ResourceImpl, but does not override that method,
so ResourceImpl returns its resourceSet.  Which, from what I see in the code, is
only ever set by basicSetResourceSet.  Which is never called anywhere.

However, we do have a virtualResourceSet in Viewtype.  Could that be it?

Oh wow, adding:

#+BEGIN_SRC java
  @Override
  public ResourceSet getResourceSet() {
    return virtualResourceSet;
  }
#+END_SRC

does seem to work.  I do have a property editor, a tree viewer, and the text
source view.

I wonder how this ever worked... other than changes in the API.

Anyway, success!

* [2017-05-02 mar.]
** Eclipse non-determinism                                 :emfviews:eclipse:
Launching Eclipse, trying to open an eviewtype file with the editor that I've
fixed Friday... only the source tab works.  The other two are blank.  Friday
this was working...

What changed?

After opening other files... the tabs have mysteriously appeared.  Okay, what's
going on here?  Some lazy loading of plugins?  Then our views are silently
failing if we fail to create them?

Okay so starting Eclipse again... Opening up
~EAview_Test/1_viewtype/myEAviewpoint.eviewtype~ haha!  Blank tabs.  At least
it's consistent this time.

(Note: for some reason, when switching tabs, the eviewtype file is marked as
dirty even though we didn't change its contents)

After I open the XMI file in the same folder, the tabs appear.  When opening the
XMI file I noticed a pause, so it most probably did load something.

** Fixing Eclipse tooltip background                                :eclipse:
The background for Javadoc tooltips is black, with white text, and crucially,
dark blue links.  That's a hard contrast, but crucially, the links are difficult
to read.

It seems Eclipse inherits the value from GTK.  It's true that the tooltips in
Firefox are also white on black.

So what do I have to change?

Adding a ~/.config/gtk-3.0/gtk.css file with:

#+BEGIN_SRC css
.tooltip .info {
  background-color: #f5f5bf;
  color: #000;
}
#+END_SRC

This changes the tooltip color in Firefox, and in Eclipse when I hover buttons
in the toolbar, but /not/ the Javadoc tooltips.

[[https://bugs.eclipse.org/bugs/show_bug.cgi?id=501742][This bug]] seems relevant; the issue has been fixed in the Oxygen pre-release.
But what if I don't want to switch?

There's a Javadoc background color preference in Eclipse->Appearance.  It's for
the Javadoc view, not the Javadoc tooltip.  Curiously, there's no setting for
the foreground, which is white by default, with dark blue links again making
selecting a good background color difficult.

Using ~SWT_GTK3=0~ does have an effect: Eclipse seems to switch to the awful
GTK3 theme, where every widget is large.  The Javadoc tooltips are readable then
(black on light grey), but the links are missing since the SWT browser fails to
instantiate.  That's not a solution.

Changing gtk2 preferences has no effect.

I see that the commit fixing the bug just changes one line in the JDT UI
plugin.xml:

#+BEGIN_SRC diff
       <colorDefinition
             label="%JavadocBackgroundColor.label"
             categoryId="org.eclipse.jdt.ui.presentation"
-            value="COLOR_INFO_BACKGROUND"
+            defaultsTo="org.eclipse.ui.workbench.HOVER_BACKGROUND"
             id="org.eclipse.jdt.ui.Javadoc.backgroundColor">
#+END_SRC

My understanding is that ~COLOR_INFO_BACKGROUND~ is picked up from GTK3, but
that's clearly not the case here as the setting is ignored.  Would have to dig
into the source.

: git clone https://git.eclipse.org/r/jdt/eclipse.jdt.ui
: rg --hidden COLOR_INFO_BACKGROUND

Oh hey:

#+BEGIN_SRC java
eclipse.jdt.ui/org.eclipse.ltk.ui.refactoring/src/org/eclipse/ltk/internal/ui/refactoring/RefactoringStatusDialog.java
87:			Color foreground= parent.getDisplay().getSystemColor(SWT.COLOR_INFO_FOREGROUND);
88:			Color background= parent.getDisplay().getSystemColor(SWT.COLOR_INFO_BACKGROUND);

eclipse.jdt.ui/org.eclipse.jdt.ui/ui/org/eclipse/jdt/internal/ui/infoviews/AbstractInfoView.java
390:			fgColor = display.getSystemColor(SWT.COLOR_INFO_FOREGROUND);
401:			bgColor= display.getSystemColor(SWT.COLOR_INFO_BACKGROUND);
#+END_SRC

getSystemColor then.  Trying to get the values returned for that by Eclipse, I
do get black for background, and white for foreground, even with the gtk.css
file.

In the Display class, there are two functions that set ~INFO_BACKGROUND~ from
GTK: ~gtk_css_default_theme_values~ and ~initializeSystemColors~.

The first looks like it's reading the CSS file for the current theme:

#+BEGIN_SRC java
case SWT.COLOR_INFO_FOREGROUND:
if (OS.GTK_VERSION >= OS.VERSION(3, 20, 0)) {
  tSelected = cssOutput.indexOf ("tooltip * {");
} else {
  tSelected = cssOutput.indexOf (".tooltip {");
}
selected = cssOutput.indexOf ("@define-color tooltip_fg_color");
if (tSelected != -1) {
  if (OS.GTK_VERSION >= OS.VERSION(3, 20, 0)) {
    COLOR_INFO_FOREGROUND = gtk_css_parse_foreground(themeProvider, "tooltip * {");
  } else {
    COLOR_INFO_FOREGROUND = gtk_css_parse_foreground(themeProvider, ".tooltip {");
  }
  return "parsed";
} else if (selected != -1) {
  color = simple_color_parser(cssOutput, "@define-color tooltip_fg_color", selected);
  if (!color.isEmpty()) {
    break;
  }
}
#+END_SRC

Looks like it's not really parsing the whole CSS, just looking for specific
strings and getting the colors.

The search for the background color is slightly different:

#+BEGIN_SRC java
case SWT.COLOR_INFO_BACKGROUND:
			tSelected = cssOutput.indexOf ("tooltip.background {");
			selected = cssOutput.indexOf ("@define-color tooltip_bg_color");
			if (tSelected != -1) {
				COLOR_INFO_BACKGROUND = gtk_css_parse_background(themeProvider, "tooltip.background {");
				return "parsed";
			} else if (selected != -1) {
				color = simple_color_parser(cssOutput, "@define-color tooltip_bg_color", selected);
				if (!color.isEmpty()) {
					break;
				}
			}
			break;
#+END_SRC

It's not picking up the background-color property.  initializeSystemColors is
the one who calls the code above, with the logic:

#+BEGIN_SRC java
if (OS.GTK_VERSION >= OS.VERSION(3, 14, 0)) {
			String colorInfoForeground = gtk_css_default_theme_values(SWT.COLOR_INFO_FOREGROUND);
			if (!colorInfoForeground.isEmpty()) {
				if (colorInfoForeground != "parsed") {
					rgba = gtk_css_property_to_rgba (colorInfoForeground);
					COLOR_INFO_FOREGROUND = toGdkColor (rgba);
				}
			} else {
				styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
				COLOR_INFO_FOREGROUND = toGdkColor (rgba);
			}
		} else {
			styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
			COLOR_INFO_FOREGROUND = toGdkColor (rgba);
		}
#+END_SRC

I don't know how what CSS Eclipse gets back from GTK, but the ones I have in the
theme are separated into multiple files, with a main.css that includes other
files with @import directives.  Since the code above is grepping for
@define-color, I'm guessing it's looking at the raw CSS files sitting on my
drive.  In that case, it will only match the @define-color line, which goes
through ~simple_color-parser~.

#+BEGIN_SRC java
String simple_color_parser (String output, String value, int index) {
	/*
	 * This method takes a color value (rgb(...), #rgb, an X11 color, etc.)
	 * and makes sure it's input we can handle. We can handle rgb/rgba values,
	 * X11 colors, or colors in the format #rgb or #rrggbb.
	 *
	 * We cannot handle shade/gradient functions or references to other colors.
	 * Because of this we strip out values that start with "@" and check
	 * non rgb values against X11 named colors.
	 *
	 * The following would be invalid input:
	 *
	 * shade(@bg_color, 0,7)
	 * or
	 * define-color error_bg_color @bg_color
	 */
	if (output != null && value != null) {
		int position;
		String color;
		position = index + value.length() + 1;
		color = output.substring(position);
		// Check for rgb color case
		if (color.startsWith("#") || color.startsWith("rgb")) {
			return color;
		} else if (!color.startsWith("@")) {
			// Check for an X11 color
			String [] cut = color.split(";");
			if (colorList.contains(cut[0])) {
				return color;
			}
		}
	}
	return "";
}
#+END_SRC

This function, again, seems rather brittle; it will break if there is more than
one space before the actual color value given to a @define-color prop.  Since
this is clearly a flavor of CSS used by GTK, maybe they have a stricter syntax
than CSS.  Or maybe all CSS files on the web are actually non-compliant, but web
browsers are lax in parsing?

Anyway, my ~tooltip_bg_color~ has a hexadecimal value, so it should return it.
And then... since we are not returning "parsed", the color is converted to RGBA,
which calls delegates to native code.

#+BEGIN_SRC java
GdkRGBA gtk_css_property_to_rgba(String property) {
	/* Here we convert rgb(...) or rgba(...) properties
	 * into GdkRGBA objects using gdk_rgba_parse(). Note
	 * that we still need to remove the ";" character from the
	 * input string.
	 */
	GdkRGBA rgba = new GdkRGBA ();
	String [] propertyParsed = new String [1];
	propertyParsed = property.split (";");
	OS.gdk_rgba_parse (rgba, Converter.wcsToMbcs (null, propertyParsed[0], true));
	return rgba;
}
#+END_SRC

The comment suggests that this method only works on rgb and rgba color values,
not hexadecimal.  Changing the values in the gtk-main.css to rgb color values
has no effect.

(I wish I could add a breakpoint into the code I'm seeing Eclipse).

Maybe it's using default colors somehow?  These are the calls to get the default
foreground and background colors:

: styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
: getBackgroundColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);

The first one calls into native code.  The second draws a surface and look at
the color in it.

Oh wait: I /can/ put breakpoints into the code.  That's going to be much
simpler.

Okay so the CSS Eclipse is looking at to determine the colors is... not the one
I was modifying.  It's much larger, and has rule declarations instead of only
@define-color calls and @import statements.

Unfortunately, the debugger is unable to give me the full value.  In the part
I've managed to extract, I don't see any comments.  That might indicate the file
was generated.

So this file apparently contains a ~.tooltip~ declaration, since that's a hit
for the code in Display.  When it gets to it, here is what it finds:

#+BEGIN_SRC css
.tooltip {
  border-bottom-left-radius: 5px;
  border-bottom-right-radius: 5px;
  border-top-left-radius: 5px;
  border-top-right-radius: 5px;
  box-shadow: none;
  color: rgb(255,255,255);
  padding-bottom: 4px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 4px;
  text-shadow: 0 1px rgb(0,0,0);
}
#+END_SRC

That's coherent with the white foreground.  For background:

#+BEGIN_SRC css
tooltip.background {
  background-clip: padding-box;
  background-color: rgba(0,0,0,0.8);
  border-bottom-color: rgba(255,255,255,0.1);
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-image-repeat: initial;
  border-image-slice: initial;
  border-image-source: initial;
  border-image-width: initial;
  border-left-color: rgba(255,255,255,0.1);
  border-left-style: solid;
  border-left-width: 1px;
  border-right-color: rgba(255,255,255,0.1);
  border-right-style: solid;
  border-right-width: 1px;
  border-top-color: rgba(255,255,255,0.1);
  border-top-style: solid;
  border-top-width: 1px;
}
#+END_SRC

So the question now is: where is this CSS coming from?  It's not from the theme
I've specified, and not from the user CSS file.  Maybe it's a file used by
Eclipse?

It is requesting the "Adwaita" theme by name.

Okay so I've dumped the CSS that Eclipse gets from GTK to disk.  I still have no
clue how it's constructed, and how it sets the color values for tooltips.

Looking at the GTK documentation:

#+BEGIN_EXAMPLE
In addition, certain files will be read when GTK+ is initialized. First, the
file $XDG_CONFIG_HOME/gtk-3.0/gtk.css is loaded if it exists. Then, GTK+ loads the
first existing file among XDG_DATA_HOME/themes/theme-name/gtk-VERSION/gtk.css,
$HOME/.themes/theme-name/gtk-VERSION/gtk.css,
$XDG_DATA_DIRS/themes/theme-name/gtk-VERSION/gtk.css and
DATADIR/share/themes/THEME/gtk-VERSION/gtk.css, where THEME is the name of the
current theme (see the “gtk-theme-name” setting), DATADIR is the prefix
configured when GTK+ was compiled (unless overridden by the GTK_DATA_PREFIX
environment variable), and VERSION is the GTK+ version number. If no file is
found for the current version, GTK+ tries older versions all the way back to
3.0.

In the same way, GTK+ tries to load a gtk-keys.css file for the current key theme, as defined by “gtk-key-theme-name”.
#+END_EXAMPLE

If we actually look in these folders, the gtk.css for Adwaita is empty, since
it's the default theme.  Presumably, all is implemented in the code.

I don't have ~XDG_CONFIG_HOME~ set, but I suspect the user file is still getting
read, since it's modifying the tooltip colors for other parts of Eclipse.

Okay, what about pointing to a custom theme?  Will it follow the CSS then?

Creating a Foo theme and setting as default, with this gtk.css:

#+BEGIN_SRC css
.tooltip {
  color: rgb(91, 91, 91);
}

.tooltip.background {
  background-color: rgb(230, 230, 230);
}
#+END_SRC

In Eclipse, the CSS dump for Foo is as huge as Adwaita's.  Tooltip values are
the same as well:

#+BEGIN_SRC css
.tooltip {
  border-bottom-left-radius: 5px;
  border-bottom-right-radius: 5px;
  border-top-left-radius: 5px;
  border-top-right-radius: 5px;
  box-shadow: none;
  color: rgb(255,255,255);
  padding-bottom: 4px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 4px;
  text-shadow: 0 1px rgb(0,0,0);
}
#+END_SRC

Something is fishy with this GTK function, and I can't find a way to influence
the values.

Looks like I have to switch to Oxygen.  Oh well.

Oxygen fixed it... but not the colors in the Content Assist.  I understand
that's a fresh commit that should go in the release.

* [2017-05-03 mer.]
** Fixing the empty tabs in the EMF Views editor                   :emfviews:
So: loading an eviewtype, I get a MultiPageEditor with 3 pages.  Page 2 and 3
are blank.  After I load the XMI file in the same folder, the two pages have
content.

Trying to add a very simple page to the MultiPageEditor with a single button:
switching to this page, the button exists.

Trying to add a more involved page with a ScrolledForm and a TreeViewer:
switching to this page, it is blank.

However, using setActivePage to point to this new page, the page is indeed
constructed and visible, and all the other pages are blank, except the first
one.

Using setActivePage to point to the properties page: it is visible on launching
Eclipse and after switching to and back from other pages.  First page is
visible, other two pages are not.

The common factor in the invisible pages seem to be that they use a
ScrolledForm.

I just need a Control to put into a page.  A ScrolledForm is a Control, but a
Composite is a Control as well.

Trying to put a button and a TreeViewer in a Composite: grey page.

If I add a layout to the composite:

: comp.setLayout(new GridLayout());

Now it's displayed.  Same thing with a ScolledForm actually: adding the
setLayout to its Composite returned by getBody will make the widgets visible
when switching to the page.

But creating the ScrolledForm through the FormToolkit, that doesn't work.

Need to look into forms and editors.

* [2017-05-05 ven.]
** Eclipse forms and editor bug                            :eclipse:emfviews:
Reading: https://www.eclipse.org/articles/Article-Forms/article.html

This is a good (albeit dated) resource on what Eclipse Forms are useful for.  It
seems PDE uses them extensively for editing the plugin.xml file for instance.
So now I understand what the EViewType editor tries to emulate.

Since we are trying to build a multi-page form, it seems the preferred way is to
extend FormEditor rather than MultiPageEditor.

Found [[http://git.eclipse.org/c/platform/eclipse.platform.ui.git/plain/examples/org.eclipse.ui.forms.examples/src/org/eclipse/ui/forms/examples/internal/rcp/FreeFormPage.java][an example]] of using FormEditor and multiple FormPage.

Doing that seems to fix the blank page bug.  I just converted the code that
created the forms to FormPage inner classes.  It's not as clean as I'd like,
since there seem to be weird explicit dependencies between models and views.
Considering that all three pages must stay in sync, it would seem that changing
the model and listening to changes would be cleaner.

But, I also don't know if we want to keep the editor in this current form.  So
that fix should do it for now.

** More dead code                                                  :emfviews:
Looking around, I see there are two classes that are not used: FormComposite, a
small utility class to adapt a composite with a toolkit, and Overview, which
seem to be the properties view as it existed before.

Of importance, the Overview class takes care of using text strings pooled from a
text file for the UI, so they can be translated.  But I can't seem to succeed in
including the page in the editor, so...  Dead code.

* [2017-05-09 mar.]
** Fixing the TreeViewer in the Viewtype editor                    :emfviews:
So, first of all, there was the issue of dirtying the state of the editor when
switching to the TreeViewer.

While trying to understand what the page is for, it hit me that a few things are
not working properly: some boxes should be ticked, and selected elements should
be expanded as well.

In addition, I see that basically all objects can be expanded in the TreeViewer,
even when they don't have any children.

Luckily, I've already done the TreeViewer tutorial from the book.

So, we are reusing the ContentProvider from our Viewtype creation wizard.
Basically, we delegate to the EMFContentProvider to display models, except we
add another layer of EPackage.

Rewriting the ContentProvider getChildren and hasChildren to be in sync fixes
the issue with empty children showing a twistie.

But we expand/tick/reveal calls still have no effect.

Debugging a reveal call indicates that it returns null internally.

So I can get the treeViewer to reveal/tick/expand elements when I build the
elements array myself.  I guess what we get from viewtype.getHiddenAttributes
are not elements related to the input of the tree.

Wait a minute.  The tree is not complete in the view... Looks like the models we
display are the one from the virtual resource set of the viewtype... so the
items are already filtered out.  The code is trying to tick the exact same
items, so of course that shouldn't work.

Not removing the items in the resource set... well, that still doesn't tick
them.  But I think that's because the virtual resource set contains clones of
the models, and the hidden attributes are objects of the base resource set, so
maybe they cannot be equal to one another.

Ah!  Yes, that's it.  After putting the originals in the virtual resource set
and not the copies, the ticks appear.  But the containing classes are not
expanded.

Which is weird, because we construct the array of containing class based on the
hidden attributes.  So if the hidden attributes are ticked because the tree
contains the same objects, it should also contain the right classes.

Hmm maybe we are changing the expanded elements at another point.  We do, in
pageChange.

But commenting that does not help.

Wait, after adding breakpoints to step through the code that sets the expanded
state internally in AbstractTreeViewer, it does work!  Shenanigans.  I guess the
hot code replace can get confused by my changes, without warning me.  This is
unfortunate.

Also, the code was trying to set the expanded state on a tree item below the top
level.  According to the documentation, this should work: expanded states are
saved even if you close the parent, so when you reopen the parent, the expanded
children should still be open.

However, if I manually do it in the tree, that's not the behavior I observe.
Expanding a child, and toggling its parent: the child is closed.  Looks like
closing an item closes its children recursively.  What works is to reveal the
elements.

Okay so now, I still haven't solved the mysterious dirtying of the editor when
opening the Contents page.

There's an editorDirtyStateChanged which I can override.  But it doesn't get
called.

Okay, found it.  The AttributeSelectionAdapter is changing the model every time
we select something.  That's overkill, and wrong.  We should only update the
model when there are actual changes in the tree: that is, when we check/uncheck
elements.

But I'm not fixing it right now.  Better focus on cleaning up the core of
EMFViews: the virtual model.  I'm leaving notes to know that these parts of the
code are busted.

** Notes on EMFViews core                                          :emfviews:
What is referred to as the Weaving model in the paper is our VirtualLinks
package.  It's a collection of links between models and metamodels.  For the
moment, we have two kind of links: associations and filters.

Associations are virtual references.

Filters hide attributes from models.

We don't have virtual attributes or virtual classes, but that might be something
to improve upon (the Extension paper was a step in that direction).

The virtual models are realized by the emfviews.core package.  There we have
Viewtype (a viewpoint in the paper), View and EView.

We have two levels: the viewtype describes the links between contributing
metamodels, and the view describes how to construct a virtual model from
contributing models (which are instances of the contributing metamodels of the
viewtypes).

Practically speaking, when opening an EView file with an ECore editor, EMF will
display the virtual model.  This is achieved by registering EMFViewsFactory as
the parser class in an extension point.

This class then creates an EView and Viewtype, depending on the file extension.
These two files extend ResourceImpl, so they can be transparently used as
resources by EMF.

How being a resource helps in displaying a model, I still have to find out.

H pointed out some redundancies in the EView file: we specify the ECL file, but
we don't need it.  It's already in the EViewtype, which is also specified, and
in any case we only need the XMI describing the weaving model.  The ECL file is
used to generate the weaving model, but once we have one, we don't need the ECL
anymore.  And in any case, we can also provide the weaving model XMI manually.

Same thing in the EViewtype: the examples have an ECore file that contains the
hidden attributes.  These should be part of the XMI, which already register the
association virtual links.

* [2017-05-10 mer.]
** Renaming VirtualLinks package and freshening up the model       :emfviews:
Annoyingly, we had a package named fr.inria.atlanmod.emfviews.virtualLinks.  Note
the camelCase.

Since this package is generated by EMF, better to update the model directly.
I'm not quite sure what to make of the namespace URI we have:

: http://inria.fr/virtualLinks

But I know that changing it will break existing serialized XMI files, so that's
probably a bad idea for the time being if I want to run the examples, without
having to change the namespace there as well.

** Testing out containment references in EMF                            :emf:
In a language where objects are allocated on the heap, I did not understand the
use of containment references.

Turns out, a containment reference and vanilla reference both include a list of
target objects.  The list implementation are different classes, but I don't see
anything vastly different about them.

According to the EMF bible, an object B that has a container can only be in one
container at the time.  Changing its container will remove it from the previous
container.  That's neat.

But doesn't that apply to bidirectional references with a single multiplicity at
one end as well?

Looks like it does.  So, a containment reference is equivalent to a
bidirectional reference with multiplicity 1 at one end.  One difference is that
to make a bidirectional reference in ECore, you have to create two references.

But the major difference since to lie in the serialization.  Contained targets
will be serialized in the same resource as the container, whereas vanilla
references are serialized in different resources.  In other words, it does what
you expect when you consider storage.  A quick test reveals that indeed,
contained objects are saved in the same file as their parent, whereas with
vanilla references you are dealing with multiple files.

So, for simplicity, and simplified management of serialized resources,
we should prefer containment references.

** Trying to use the MoDisCo model browser                         :emfviews:
Because the model browser provided by ECore is very basic, and does not follow
references.  The MoDisCo browser does.

However, trying to open the examples XMI with it, I am greeted with familiar
errors concerning unknown features from the TOGAF metamodel:

: !MESSAGE org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'belongsTo' not found. (platform:/resource/1_EAdata/models/1_travelAgencyEA.xmi, 26, 270)

I slayed this dragon previously, and I kept my custom TOGAF plugin.  Re-using
it...

Okay, it works.  I can follow recursive links in the model.  It's... not very
impressive, or convincing, but it works.  The Modisco browser is dog slow
however.

** Following the code                                              :emfviews:
After the EmfViewsFactory delegates to either the EView or Viewtype constructor,
what happens?

Well, nothing at that point: the constructor returns a resource.  That resource
is only loaded when its doLoad method is called.  That's where the magic
happens.

In Viewtype.doLoad, we parse the eviewtype file, load the models, and create the
virtual resource set.

The correspondenceModelBase seem unused at this point.  The Viewtype only uses
it in serialize()... except this function is never used.  The actual
serialization happens in the doSave method of the resource.

First we load the filter metamodel: the ECore file that should not be here.

Then we load the contributing metamodels.  We get the corresponding package, and
each package is cloned and kept in contributingEPackages.

Then, we first filter out any attributes as specified by the filter metamodel.
If the package matches one in the filters, we remove every structure from common
classifiers.

There are two issues currently: we loop through all filtered packages, for
each contributing package.  That's unnecessarily quadratic.

Second issue: we only seem to care about EClass classifiers with an unchecked
downcast.  So I'm pretty sure that's an exception if the filter metamodels
contains an Enum or Datatype.

Hmm, it crashes, but not where I expected.  Actually, I see other downcasts in
the same method, and they seem unsafe, but no warnings.  Need to check that as
well.

*** DONE Check copyright/contributions
CLOSED: [2017-09-29 ven. 17:54]
Copyright is attributed to Inria in some places, Atlanmod in others (or should
it be AtlanMod?).

Copyright years are 2013,2014 tops.

Copyright notice should maybe be generated for VirtualLinks.

Copyright notice should be included in all packages.

AtlanMod should be the provider of all packages.

*** Investigate dependencies
Some EMF plugins depends on other EMF plugins, some depend on EMF packages
directly.  The book I read on Eclipse plugin development recommended to depend
on packages.

*** Change the logo background to be transparent
This is unnerving.

* [2017-05-12 ven.]
** Downcasts in Java are "safe"                                        :java:
Because there will be runtime checks...  I was under the impression the compiler
would complain, but it's just in case of unchecked cast with generics.  Because
of type erasure, the compiler cannot insert a runtime check (a List is still a
List), so the warning is to make sure you know what you are doing.

Otherwise, Java assumes you do know what you are doing with straight downcasts
from A to B, even though the compiler only knows that this downcast /could/
work (if B :< A).

That's disappointing.

Is there a linter out there that could at least pick up downcasts so I could
review them?  FindBugs [[http://findbugs.sourceforge.net/bugDescriptions.html#BC_UNCONFIRMED_CAST][appears to]].

The Eclipse plugin is a bit rough, but it does report the stupid downcast from
my test code.  However, it does not report the troubling downcasts in EMFViews.
So, more trouble than it's worth.

** Mysterious crash when loading funky ECore file                  :emfviews:
So adding other classifiers (EEnum, EDataType) to the Ecore file containing our
filters and opening the Eviewtype with the ECore editor results in 3 thrown NPE.

The puzzling part is that, in all of the stack traces, our code is not on the
stack.  Maybe we implement something wrongly.

Adding a breakpoint shows Viewtype.getContents is called and returns the null in
question.  But since the null value is used by ResourceImpl, that's where the
NPE is thrown.

Anyway, we only set virtualContents after doLoad() has completed.

Hmm, I see!  Stepping through again, and in fact ResourceImpl.load wraps our
doLoad with a try/finally, but no catch.  So we do throw a cast exception due to
the presence of other classifiers!  But that was masked by ResourceImpl.
Sneaky.

** EMFViews archeology                                             :emfviews:
So, H found the original demo paper along with the initial prototype
implementation of EMFViews (then called VirtualEMF).  The novel idea at the time
was to have a /virtual/ model, that composed multiple contributing models.  The
virtual model is lazy: attributes are proxies to the concrete models, and the
virtual attributes are synthesized on-demand.

In the code, you can find a VirtualModel class that's absent from the current
version.  That's because at the time, only models were virtualized, not
metamodels.  But, the same virtualization approach can be applied to metamodels,
since they can be viewed as models as well; hence EMFViews.  In EMFViews, we
have Viewtype which should be the equivalent of VirtualModel for metamodels, and
View, which would be closer to the original VirtualModel.

Looking at the rest of the code, everything in emfviews.elements seem very
similar to the first version.

In emfviews.rules, the MergeRule was severely cut.

In emfviews.core, the MetaModelManager was mostly changed.  The
VirtualLinkManager was slightly changed, and that's it (other than added/removed
files).

** Further code investigation                                      :emfviews:
Now I'm in Viewtype.loadCorrespondenceModel.  The correspondenceModel is the XMI
file that describe the VirtualLinks: it gives us the info we need to compose the
contributing models (and in this case, metamodels).

There are two kinds of links actually: Filter and Association.  But filter links
are not currently used in this path of code; the filters are specified in a
separate ECore file which is used in the loadFilterMetamodel phase.

So the code is concerned only with Association links.  For each Association, we
synthesize an EReference with the Association attributes (source, target,
lower and upper bounds) and add it to the EClass in which it resides (in the
virtual packages we created earlier).

Ultimately, in Viewtype.setVirtualContents, we turn the EPackage from our
virtual resource set into a VirtualContents object (which is just an EList).  I
had looked at VirtualContents before: it's a curious implementation of an EList
from a list of lists, which only purpose seem to be to simulate a flat list:

#+BEGIN_SRC java
public E get(int index) {
    if (index >= 0) {
      for (List<E> l : subLists) {
        if (index < l.size()) {
          return l.get(index);
        } else {
          index -= l.size();
        }
      }
    }
    throw new IndexOutOfBoundsException();
  }
#+END_SRC

I'm assuming this is done because getContents requires an EList.  But, then, why
not flatten the lists once and for all?  The VirtualContents list seem to be
read-only, since the set method is implemented by a call to super
which... throws UnsupportedOperation.

** Open questions                                                  :emfviews:
- Is Viewtype creating a truly virtual metamodel?  It doesn't seem to do any
  demand-loading, but maybe that's behind the scenes.  Should compare with what
  View/EView does for models, or what VirtualModel did in the first prototype.

- There are still a bunch of files in the core, are they used by View/EView or
  not?  MergeRule, TranslationRule, etc.

* [2017-05-15 lun.]
** Is Viewtype proxying metamodels?                                :emfviews:
To me it seems that no, it just plain clones them into the virtual resource
set.  This is done in loadContributingMetamodels:

#+BEGIN_SRC java
EPackage contributingEcoreModelPackage = EPackage.Registry.INSTANCE.getEPackage(modelURI);

Copier copier = new Copier();
EObject copy = copier.copy(contributingEcoreModelPackage);
copier.copyReferences();
EPackage copiedPackage = (EPackage) copy;
EcoreUtil.remove(copiedPackage);
contributingEpackages.add(contributingEcoreModelPackage);
#+END_SRC

Regardless of whether there are filters, we clone the packages.  Then, if there
are filters, we remove the attributes from these copies.

: eClassWithItemsToHide.getEStructuralFeatures().remove(theAtt);

Then, if there are associations, we add EReferences to these copies:

#+BEGIN_SRC java
EReference theR = EcoreFactory.eINSTANCE.createEReference();
theR.setName(association.getName());
theR.setLowerBound(association.getLowerBound());
theR.setUpperBound(association.getUpperBound());
theR.setEType(theTargetEClass);
...
theSourceEClass.getEStructuralFeatures().add(theR);
#+END_SRC

So, is this different from how View/EView work?

** Investigating View/Eview                                        :emfviews:
Stepping through the code.  When we load an eview file, we trigger EView.doload.

First thing is to read the file, and create a Viewtype resource from the
compositionMetamodel line.  We are creating a whole new Viewtype (and copying
packages), just for the EView.  If a Viewtype is a virtual metamodel, we should
be able to locate it from the registry, and create it only if it does not exist.

I'm wondering if the EView/View split is the half-finished result of trying to
abstract the common parts of EView and Viewtype into a common abstract class.
But at the moment, EView is the sole subtype of View.

In EView, we then load the View.contributingMetamodels.  This merely register
the metamodels in the virtualResourceSet of View.  But this virtual resource set
is different from the one held by Viewtype.  At this point, the metamodels are
not modified.

Then we create a MetamodelManager.  This one populates a bunch of Maps.  A map
of composition classes keyed by their names; these are taken from the contents
of the constructed Viewtype.  Then a map of all the EClass of the contributing
metamodels, again keyed by their names; these are taken straight from the
classifiers of the contributing metamodels.

Then a map of concrete to virtual classes.  That's interesting:

#+BEGIN_SRC java
for (List<EClass> lcec : contributingClassesByName.values()) {
  for (EClass cec : lcec) {
    List<EClass> lvec = compositionClassesByName.get(cec.getName());
    for (EClass vec : lvec) {
      if (vec.getEPackage().getNsURI().equals(cec.getEPackage().getNsURI())) {
        this.concreteToVirtualClass.put(cec, vec);
        mapFeatures(cec, vec);
      }}}}
#+END_SRC

The "virtual EClasses" (vec) that are put into the map are pulled from
coompositionClassesByName, and used as values keyed by the corresponding class
in contributingClasses.

mapFeatures does the same mapping, but for structural features, recursively:

#+BEGIN_SRC java
private void mapFeatures(EClass concEC, EClass virtuEC) {
  for (EStructuralFeature feature : concEC.getEStructuralFeatures()) {
    EStructuralFeature vf = virtuEC.getEStructuralFeature(feature.getName());
    if (vf != null) {
      this.virtualToConcreteFeature.put(vf, feature);
      this.concreteToVirtualFeature.put(feature, vf);
    }}}
#+END_SRC

Now we have a bidirectional map.

Lastly, there may be additional features in the virtual classes (created by the
associations), so we also record them in a map of virtualAssociations, but only
if they were not present in virtualToConcreteFeatures:

#+BEGIN_SRC java
for (List<EClass> lec : compositionClassesByName.values()) {
  for (EClass ec : lec) {
    for (EStructuralFeature sf : ec.getEStructuralFeatures()) {
      if (virtualToConcreteFeature.get(sf) == null)
        if (virtualAssociations.get(sf.getName()) == null) {
          List<EStructuralFeature> sfs = new ArrayList<>();
          sfs.add(sf);
          virtualAssociations.put(sf.getName(), sfs);
        } else {
          virtualAssociations.get(sf.getName()).add(sf);
        }}}}
#+END_SRC

After that we are back in EView, and that's it for the metamodels.  Now we
loadContributingModels:

#+BEGIN_SRC java
protected void loadContributingModels(List<String> contributingModelsPaths) {

  for (String modelURI : contributingModelsPaths) {
    virtualResourceSet.getResource(URI.createPlatformResourceURI(modelURI, true), true);
  }

}
#+END_SRC

Which just seems to force the loading of each model, without doing anything with
the returned resource (why?).

If there is a correspondenceModelBase we... don't do anything with it (yet)?  We
get the correspondence XMI, create a VirtualLinksDelegator for the
correspondenceModelBase, and let the delegate create the links:

#+BEGIN_SRC java
if (properties.getProperty("correspondenceModelBase") != null) {
  IWorkspace workspace = ResourcesPlugin.getWorkspace();
  java.net.URI linksModelURI = workspace.getRoot()
      .findMember("/" + properties.getProperty("correspondenceModel")).getLocationURI();
  try {
    VirtualLinksDelegator vld =
        new VirtualLinksDelegator(properties.getProperty("correspondenceModelBase"));

    vld.createVirtualModelLinks(org.eclipse.emf.common.util.URI
        .createURI(linksModelURI.toString()), getContributingModels());
#+END_SRC

In this case, it creates an EclDelegate.  In
EclDelegate.createVirtualModelLinks, we open the ECL file and first parse the
aliases in the header.

Here is a sample ECL file from the examples:

#+BEGIN_EXAMPLE
//alias_ea=http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0
//alias_bpmn=http://www.omg.org/spec/BPMN/20100524/MODEL-XMI
//alias_reqif=http://www.omg.org/spec/ReqIF/20110401/reqif.xsd

rule detailedProcess
match s : ea!Process
with  t : bpmn!Process
...
#+END_EXAMPLE

I think the intent here is pretty clear: to define ~ea~, ~bpmn~ and ~reqif~ as
aliases for the metamodels in the header.  Still, it would be better to have ECL
support these kinds of declarations rather than hack a parser with indexOf
calls.

[H: usually you'll run ECL with a launch configuration file, specifying the
aliases.  Here it's inlined.  Maybe there is away to provide a launch
configuration at runtime, but it's not really important.]

In any case, we populate two maps keyed by the aliases: one to the resource of
the metamodel, and one to the package URI.  No provisions are made if we don't
find a corresponding resource.

After that, we close the ECL file because we let ECL parse the rest.  Then we
add instances of EmfModel to the model repository of the Ecl module.

Then, we executet the ECL module, and iterate on the resulting MatchTrace in
order to create virtual links for each matching trace:

#+BEGIN_SRC java
for (Match match : matches) {
  if (match.isMatching()) {
    EObject left = (EObject) match.getLeft();
    EObject right = (EObject) match.getRight();

    Association vAsso = vLinksFactory.createAssociation();
    vAsso.setName(match.getRule().getName());
    vAsso.setAssociationTypeName(match.getRule().getName());
    vAsso.setLowerBound(0);
    vAsso.setUpperBound(1);

    LinkedElement lSource = vLinksFactory.createLinkedElement();
    lSource.setModelRef(left.eClass().getEPackage().getNsURI());

    lSource.setElementRef(left.eResource().getURIFragment(left));
    vAsso.setSourceElement(lSource);

    LinkedElement lTarget = vLinksFactory.createLinkedElement();
    lTarget.setModelRef(right.eClass().getEPackage().getNsURI());
    lTarget.setElementRef(right.eResource().getURIFragment(right));
    vAsso.getTargetElements().add(lTarget);

    virtualLinks.getVirtualLinks().add(vAsso);
    virtualLinks.getLinkedElements().add(lSource);
    virtualLinks.getLinkedElements().add(lTarget);
  }
}
#+END_SRC

After that, we save the populated virtualLinks to the XMI file.

So, it seems we always recreate the XMI file from the ECL.

[H: that may not be ideal, but models can be updated, so you usually want your
view to synchronize with these changes by default.  Here we run the ECL query
again.]

Back in EView, we now create a VirtualLinkManager, given the correspondence
model URI (the XMI).  The manager merely holds a reference to both the EView and
the VirtualLinks instance from the XMI.

Then the VirtualLinkManager is initialized, which creates a LinksProjector.
There, for each Assocation in the XMI, we get a virtual element from the
VirtualLinkManager corresponding to the source element of the association, and
we link the target elements to it:

: vElement.setVirtualAssociation(virtualFeature, EStore.NO_INDEX, targetElements);

After that, we set the virtual contents of our EView resource, by translating
each package of the contributing models to virtual elements.  Creating virtual
element happens in VirtualLinkManager.getVirtualElement:

#+BEGIN_SRC java
public EObject getVirtualElement(EObject e) {
  VirtualElement vElem = virtualLinks.get(e);
  if (vElem == null) {
    vElem = new ReproduceElementImpl(virtualModel, e);
    virtualLinks.put(e, vElem);
  }
  return vElem;
}
#+END_SRC

and ReproduceElement uses a ReproduceRule, which implements an EStore... and
that's probably where the secret virtualization sauce lies.  But it already
looks like there is much more happening in EView/View concerning virtualization,
and I didn't see any copying taking place.

So my premature answer is: the Viewtype is not virtualized as the Views are.
Which was kind of the point of EMFViews.  That should be fixed in priority.

* [2017-05-16 mar.]
** Reading the EMF bible                                                :emf:
To get a clearer picture of the concepts at hand.

Questions still open after reading the relevant chapters:

- Can we read a UML model and access it using the
  EPackage/EClass/EAttribute/... interfaces?

- Is demand-loading and demand-creating for resources lazy, eager, or something
  else?  Specifically, the createResource and getResource methods accept a
  boolean argument: does it forces resolution or rather delays it?

- It seems, at least for references, that EMF already does some
  auto-proxification.  What is the mechanism we use in EMFViews
  (ReproduceRule?), and how does it compare?

  If we use "Dynamic EMF" as it's called in the book to create our view
  packages, would we not benefit from proxification?

And an observation:

EMFViews add copies of contributing model packages to a registry local to the
virtual resource set of a Viewtype.  But then, the EView does not tap into this
virtual resource set, so there's duplication here.

* [2017-05-17 mer.]
** EMFViews uses an EStore                                         :emfviews:
A VirtualElement inherits from an EStoreEObjectImpl, which is an EObject
implementation backed by an EStore.  Then, our translation rules are all
different EStore implementation.

From what I gather, this is where the actual magic for models happen (and this
was part of the initial implementation back in 2011).

When we load a model, the very last step of EView.doLoad is to set the virtual
contents:

#+BEGIN_SRC java
for (Resource r : contributingModels) {
  ArrayList<EObject> oneOftheSublists = new ArrayList<>();
  oneOftheSublists.add(translateToVirtualElement(r.getContents().get(0)));
  sublists.add(oneOftheSublists);
}

this.virtualContents = new VirtualContents<>(this, sublists);
#+END_SRC

This populates lists with virtual elements, which are obtained from the virtual
link manager:

#+BEGIN_SRC java
public EObject getVirtualElement(EObject e) {
  VirtualElement vElem = virtualLinks.get(e);
  if (vElem == null) {
    vElem = new ReproduceElementImpl(virtualModel, e);
    virtualLinks.put(e, vElem);
  }
  return vElem;
}
#+END_SRC

That's where reproduce elements are instantiated.  (And, interestingly, only
reproduce elements; MergeElement and FilterElement do not seem to be created
anywhere)

A reproduce element is a virtual element, so an EStoreEObjectImpl, and holds a
concrete EObject called the concrete element.  The idea is to pass through
access to the concrete element using the EStore interface.

At the end of creating a reproduce element, this is what happens in init:

#+BEGIN_SRC java
this.eProperties().setEResource(vModel);
this.concreteElement = concreteElement;
this.eSetClass(eClass);
this.eClass();
setTranslationRule(ReproduceRule.INSTANCE);
eSetStore(this.getTranslationRule());
#+END_SRC

We create a reproduce rule, which implements EStore, and will capture get/set
calls on this virtual object.  That's why, in ReproduceRule.get:

#+BEGIN_SRC java
public Object get(InternalEObject object, EStructuralFeature feature, int index) {
  ReproduceElementImpl vElement = (ReproduceElementImpl) object;

  View vModel = (View) vElement.eResource();
  if (vModel.getMetamodelManager().isVirtualAssociation(feature)) {
    return vElement.getVirtualAssociation(feature, index);
  }
  EStructuralFeature cFeature = vElement.getConcreteFeature(feature);
  Object value = vElement.getConcreteElement().eGet(cFeature);
  ...
  return value;
#+END_SRC

We ultimately return the concrete value.  But not in every case:

#+BEGIN_SRC java
if (feature instanceof EReference) {
  if (feature.isMany()) {
    value = new VirtualModelList<>(object, feature, Arrays.asList((List<EObject>) value));
    if (index != NO_INDEX) {
      value = ((VirtualModelList<EObject>) value).get(index);
    }
  } else {
    value = vModel.translateToVirtualElement((EObject) value);
    if (value instanceof FilterElement) {
      value = null;
    }
  }
}
#+END_SRC

If the requested structural feature is an ERef, and it's many, we return a
virtual list.  Ultimately, inside this virtual list, we will call
getVirtualElement.  If the ref has a single multiplicity, then we can directly
return the virtualElement.

In essence, we perpetuate the virtualization recursively.

It seems to be this part of the code is mixing concerns.  There is a test for
FilterElement here, to mask the value if it should be filtered.  But then we
also have the same test in the VirtualModelList.  Why does the virtual list
repeats this instead of delegating to single virtual elements?

Besides, it seems to me we should have a clear mapping from the Ecore model to
the virtual model, defined for all classifiers and features.

** Using a code coverage tool to find hot/cold code        :emfviews:eclipse:
Following T's recommendation, I used the EclEmma plugin, which is based on
JaCoCo.

Installation was painless.  The plugin supports coverage for running client
Eclipse application, which is my use case.

So now I can answer with certainty that, opening EView and EViewtype files with
a model browser and the viewtype editor, the following classes are never used:

- MergeRule, MergeElementImpl
- FilterElement

In other classes, besides what I already identified as unused, it seems we have
no examples using the sourceAttribute and targetAttribute of a Association.
Maybe there are superseded by sourceElement/targetElements.

* [2017-05-19 ven.]
** How are virtual model attributes filtered out?                  :emfviews:
H raised an interesting question: if an attribute is filtered out in the virtual
metamodel, it is also filtered out in the virtual model.  But how does that
happen?

Does EMF just disregard attributes that are not in the metamodel?  Do we also
need to filter the attributes from the model?

I'm guessing it's the former.  If I comment out the filtering attributes part in
the metamodel, they should appear on the model.

Yes, they do.

Hmm, when the attributes are present in the metamodel, we add them to the maps
of virtual to concrete features in MetamodelManager.  When the attributes are
absent, they are absent from the maps as well.  That's a hint.

* [2017-05-22 lun.]
** Writing tests for EMFViews before refactoring                   :emfviews:
I've got a couple of easy refactorings ahead, related to the EView and EViewtype
files.  But, before that, I want to write some tests to ensure I don't break any
functionality doing so (at least, any functionality we care about).

One problem with writing tests is the way Viewtype and View are written as
resources, you have to provide files through URI, otherwise you cannot construct
them properly.

We could refactor Viewtype and View so that the resource-specific code is
extracted, and calls into a model-specific part that does not have to deal with
files.  But that would be refactoring in order to write the tests for the
/other/ refactoring...

I'll try to write the tests passing files as URI first.

Okay, hit a snag: I'm using URI.createPlatformResourceURI to pass a
workspace-relative filename to the EViewtype file, and it doesn't work.
Presumably, because when I run the code there is no workspace!

So rather I should just use relative paths.  This works:

: URI.createURI("models/foo.eviewtype")

and this will look up the "models" directory in the current project, so it's
relative.  Hopefully that slash is portable as well.

Grmbl, now Viewtype tries to load the filters metamodel.  But it also uses
URI.createPlatformResourceURI, which in turn will use the resource factory
registry to find out how to create an Ecore.  But running in the tests, this
factory is empty:

: System.out.println(Resource.Factory.Registry.INSTANCE.getExtensionToFactoryMap().isEmpty());
: true

I guess I can populate it myself in the tests.

: Resource.Factory.Registry.INSTANCE.getExtensionToFactoryMap()
:     .put("ecore", new EcoreResourceFactoryImpl());

Now I have to find the correct path to set in the Eviewtype file so that it
loads my Ecore model from the right directory.

At the moment, it fails to find it.  I'm in
PlatformResourceURIHandlerImpl.createInputStream.

Amusingly, after prefixing my URI with 'platform:/resource', this method removes
the prefix

: String platformResourcePath = uri.toPlatformString(true);

Ultimately, it calls EcorePlugin.resolvePlatformResourcePath on this suffix,
which merely looks into its getPlatformResourceMap for the root project in order
to produce a platform-specific file URI...

Let's do this:

: EcorePlugin.getPlatformResourceMap().put("foo", URI
: .createURI("file:///home/fmdkdd/proj/emfviews/tests/fr.inria.atlanmod.emfviews.test/models"));

Yeah, it works!  Is there a way to make it relative at least?

In the end, the file URI calls new File(), passing everything to the right of
':'.  Ah, but that's only the URI for the base folder, and EMF uses it to
resolve the resource path below, and this cannot be relative:

#+BEGIN_SRC java
 public URI resolve(URI base, boolean preserveRootParents)
    {
      if (!base.isBase())
      {
        throw new IllegalArgumentException("resolve against non-hierarchical or relative base");
#+END_SRC

Hardcoded it is then.

Then:

: IllegalStateException: Workspace is closed.

Raaaah, we have code in Viewtype.loadCorrespondenceModel which queries the
workspace.  To construct absolute file URIs, again.  This time, to load the XMI
file of the correspondence model.

At this point, I have three options:

1. Fuck it, and not write tests before doing the changes.  That's not totally
   satisfactory; and I will need to write tests anyway for other changes down the
   line.
2. Make the slightest modifications to Viewtype so that it let us provide the
   proper URI
3. Run the tests as a plugin, so that a workspace is loaded


Now that I think of it, 3 would solve the previous problem as well.

Okay, that's better.  Now I can run the JUnit test using a headless Eclipse, but
still loading a workspace.  In fact, I did have to configure a "test" workspace
where I added the ECL, XMI and Ecore files needed by the viewtype to load.

I'd rather have the tests add these files to the test workspace... or even have the
Viewtype code to load them from anywhere.  But anyhow.

Managed to test the presence of features and absence of filtered features.  Now
to be a bit more thorough.

Hmm, hit a snag when trying to check the models.  All I get are
ReproduceElementImpl instances, so I can't cast them to EClass/EPackage to get
their contents or names.

I could cast to ReproduceElementImpl... but then I wouldn't be testing the
virtual access.

So maybe I'm missing something, and we should access these objects through the
EStore interface.  At least, EMF is able to construct a tree viewer from these
contents, so I should be able to inspect these as well.

*** DONE Fix the URI scheme in Eview/Eviewtype
CLOSED: [2017-06-07 mer. 17:26]
We mix platform URLs with http for finding packages of metamodels.  This is
confusing and complicates the code (there are couple instances of duplication
based solely on different URI schemes).

* [2017-05-23 mar.]
** How does the basic Ecore editor goes through our ReproduceElementImpl? :emfviews:
Because that's how I probably need to iterate on them as well.

In EcoreEditor.createModel, our reproduce rule is called by an iterator
resource.getAllContents(), which goes through all the properties.

The actual text is provided by label providers that are given by adapter
factories... EcoreItemProviderAdapterFactory is where the mapping is done from
Ecore objects (ERef, EClass, etc.) to the actual classes that do the work.

For EObjects, it uses the ReflectiveItemProvider.  Setting a breakpoint at
getText there and opening items in the tree confirms that this is the place.

#+BEGIN_SRC java
public String getText(Object object) {
  EObject eObject = (EObject)object;
  EClass eClass = eObject.eClass();
  String label = format(capName(eClass.getName()), ' ');

  EStructuralFeature feature = getLabelFeature(eClass);
  if (feature != null)
  {
    Object value = eObject.eGet(feature);
    if (value != null)
    {
      return label + " " + value.toString();
    }
  }
  return label;
}
#+END_SRC

It's just using eClass().getName().  Okay, let's try that.

It works!  I managed to test the presence of reproduced elements and virtual
associations, and the absence of filtered elements.  But somehow, I've gotten
some values from eClass.getName(), and some others from casting to an EReference
and using getName():

: assertEquals("ReqIF", l.get(1).eClass().getName());
: assertEquals(e.eClass().getName(), "Process");
: if (c instanceof EReference && ((EReference) c).getName().equals("detailedProcess"))

and I don't understand quite why I need to go to the eClass for some, but not
for others.  For the EReferences, eClass() returns EReference... which I guess
is expected.

In the model, I iterate over the /contents/ of the the BusinessArchitecture
object (presumably, a list of structural features).  For each, I can test:

: assertEquals(e.eClass().getName(), "Process");

This is what the Ecore reflective editor gives me: the name of the Eclass.  But
a "Process" in the model also has a name.  The editor gets it from
getLabelFeature and eGet above.

getLabelFeature search for a plausible feature to use as a label: if it's a
"name" attribute or if it's a String.

So I can do:

: e.eGet(e.eClass().getEStructuralFeature("name"))

to get the name of each Process instance.  Similarly, to get the detailedProcess
ref:

: e.eGet(e.eClass().getEStructuralFeature("detailedProcess"))

At first I was surprised with the results:

#+BEGIN_EXAMPLE
fr.inria.atlanmod.emfviews.elements.ReproduceElementImpl@72b10258 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@6113a26f (name: Process) (instanceClassName: null) (abstract: false, interface: false))
null
null
null
null
null
null
null
null
null
null
#+END_EXAMPLE

Only one reference went somewhere, the others null?

But then I opened the model in Modisco, and it turns out that, yes, only the
first process "Booking a trip" has a detailedProcess that leads somewhere.  All
the others are empty references.

Interestingly, even though it's a reference, we don't get an empty list when
there are no elements, or a list when there is only one element.  We get a list
only for two or more elements.

** Removing the correspondenceModelBase in the EView file          :emfviews:
This should be the simplest task on the list.

With the test written and the coverage tool, I can see that: 1) we never
actually do anything with the correspondenceModelBase in Viewtype (the code is
commented out), and 2) removing the correspondenceModelBase in Eview does not
fail the test.

That's because, if we don't specify a model base, we'll just use the existing
correspondence model.

On the other hand, if we do specify the model base, we rewrite the
correspondence model every time.  Except, when the file does not exist (?!).
Putting an empty file there works, which is a bit... meh.  The limitation is due
to getting the URI from finding the file first, rather than just constructing
the URI without looking if there's a file there.

Using createPlatformResourceURI fixes it.

** Getting filters from the virtual links XMI instead of the Ecore :emfviews:
This is slightly more involved.  At the moment, we filter the elements at the
metamodel level, getting the filters from an Ecore file.

For each contributing metamodel, we:

- copy it to our virtual resource set
- remove any feature matching a filter
- load the correspondence model and add associations

What we should do instead is to get the filters from the virtual links model,
and use them to remove features from the metamodels.

So, for each contributing metamodel, we should:

- copy it to our virtual resource set
- load the correspondence model
- remove any feature matching a filter
- add associations

Although, since we specify the elements to be filtered in a different format, we
must change the matching accordingly.  In the Ecore, we did the matching
structurally.  But in the virtual links metamodel, we have only 3 pieces of data
to match the filter element reference:

: <linkedElements elementRef="//Process" modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0" name="Process"/>

Clearly, we are losing the hierarchical component here.  Though, maybe
"elementRef" is actually intended to be XPath?  If so, I think it means
"any node named Process", which is not more information than "name", but at
least if it's used as XPath you could be more precise than that I guess.

It seems the element ref is used by the links projector in getReferencedObject:

: r.getEObject(elementRef);

So, no XPath then.  Well, regardless, I think I'll go with a pretty basic scheme
to begin with:

: <linkedElements elementRef="contentfwk.BusinessArchitecture.drivers"
:                 modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0"
:                 name="drivers"/>

This should give enough information to filter the correct element without ambiguity.

Writing the search was a bit more tricky than expected, due to it being a tree.
Using a queue did it.  Not the most readable code, but it works.

Test pass, elements are filtered on the metamodel and the model.

* [2017-05-29 lun.]
** Small morning refactorings                                      :emfviews:
Removing the unnecessary HashMap as arguments to load and save for a resource.
EMF handles null arguments just fine.

On a side note, there are multiple cases of calling load with an explicit input
stream, but the suggested way to load a resource is to first give it an URI,
then call load(null).

In fact, sometimes we call load with an explicit input stream, /and then/ set
the URI.

Now to rename a few things for better coherence with the paper:

- Viewtype to Viewpoint.  That was a pain, as we had also many example files
  with the eviewtype extension, and files that referred to them...  These
  examples might not be even working anymore for all I know, but hey, coherence.

- "Correspondence model base" to "Matching model".  I guess "correspondence" was
  alright, although different than the paper, but "matching" is shorter.  And we
  had many thing beginning with 'c' already, it was getting Confusing.

At this point I discover projectile-replace: much faster!  Though it doesn't
seem to save files automatically, there is projectile-save-project-buffers;
launching magit-status also prompts to save them individually.  Still leaving
the Java refactorings to Eclipse, since I have more faith in its correctness.

- "Correspondence model" to "Weaving model".  The correspondence model is
  actually just an instance of the virtual links metamodel.  But I suppose
  there's no reason to couple the two, so "weaving" will do (besides, it's
  shorter).

- "Composition metamodel" to "viewpoint", since that's what it is.

- "Contributing (meta)models" to "contributing".  Hmm, this one will wait for
  the unification of EView and Viewpoint, where we will have a single
  "contributingModel" line.  For coherence with the other properties in an
  EView/EViewpoint file, the suffix should stay, at least for the time being.


These morning refactorings went well in the afternoon I guess.

* [2017-05-30 mar.]
** Making Viewpoint a virtual metamodel                            :emfviews:
At the moment, to construct the Viewpoint, we merely clone the contributing
packages into a virtual resource set, then remove filtered attributes and add
references corresponding to virtual associations.

The idea is to use what we have in View already to construct a Viewpoint, by
feeding it Ecore as a metamodel.  First difficulty is that EView refers to a
Viewpoint.  If we use EView to represent a Viewpoint at the metamodel level,
then it would still need a Viewpoint.

What is the Viewpoint used for anyway?

In EView.doLoad, we load a full Viewpoint from the "viewpoint" property.  We
then use this viewpoint to get a reference to the matching model and the list of
contributing metamodels.

This list of contributing metamodels is used by View to populate the virtual
resource set of the View/EView (the attribute is declared by View, instantiated
by EView, and populated by View.loadContributingMetamodels).

It seems similar to what Viewpoint is doing, except we are /not/ copying the
packages we put in the virtual resource set of View.

So at this point, we have a virtual resource set with the original packages,
/and/ a Viewpoint with its own virtual resource set containing clones of the
exact same packages, albeit modified by virtual links.

How are both used?  First, the content of the virtual resource set of View is
only used by View.getContributingModels, that is: to produce a list of the
resources contained by the resource set (but we filter out Ecore resources for
some reason).

This list is used by other getters of View, and also in doSave.  Most
interestingly, its contents are passed unfiltered to the constructor of a
MetamodelManager in EView.doLoad, along with the viewpoint.  Another point of
use of interest is View.setVirtualContents: the (filtered) list is used to
populate the virtual contents with translated virtual elements.

The viewpoint of EView is /only/ used to pass to the MetamodelManager.  So it
seems this is where the link between concrete metamodels, virtual metamodels,
models and virtual models happen.

In fact, the third argument to the constructor of MetamodelManager takes a
reference to the EView instance that created it... the EView holds a reference
to the MetamodelManager, and that's the only class where the manager is
instantiated.  Seems to me they are rather coupled.

MetamodelManager holds maps of concrete to virtual features as I have [[*Investigating View/Eview][previously
covered]].

It uses the EView reference in only one place, this test:

#+BEGIN_SRC java
 if (virtualModel != null && virtualModel.getResourceSet() != null
        && virtualModel.getResourceSet().getPackageRegistry() != null
        && virtualModel.getResourceSet().getPackageRegistry().values() != null
        && virtualModel.getResourceSet().getPackageRegistry().values().size() > 0) {
      Collection<Object> listOfVirtualMMPackages =
          virtualModel.getResourceSet().getPackageRegistry().values();
#+END_SRC

Written in a rather defensive style, this list of virtual metamodel packages is
the same thing that we pass in the first argument to the constructor... which
the constructor collects into a list of EPackage: contributingMetamodels.

Now, coverage for the test I've written tells me that the test returns false
anyway, because getResourceSet() returns null.  So at the moment, we don't do
anything at all with the EView reference.

We do use the other two arguments: the list of (unaltered) contributing
metamodel packages is put into contributingMetamodels, and the viewpoint is used
to populate the compositionClassesByName, where we put the altered metamodel
classes.

Then, in buildMaps, we iterate over each EClass from the contributing
metamodels, and if we find an EClass of the same name, belonging to the same
package, in the map of composition classes (from the Viewpoint), then we add it
to the concreteToVirtualClass map, and iterate on their features.

It's the same thing for mapFeatures: for each concrete feature in the
contributing EClass, if it also exists (by name) in the virtual EClass (the
EClass from the viewpoint), then we add the feature to two maps:
virtualToConcreteFeature and concreteToVirtualFeature.

I'm puzzled by two things: why we use names for comparisons, and why we don't
just iterate on the virtual metamodel.

Using names is brittle, and leads to the redundant checks for classes that
belong to the same package.  Also, is there any guarantee of name uniqueness in
EMF?  It looks like there is: adding a feature or class with the name of an
existing one will fail the validation.  So that's a safe assumption.  We can use
names, but it might be best to have them qualified.

Iterating on the virtual metamodel: since we will only add classes and features
present in the virtual metamodel, and we will add all of them (save for
associations), it might make more sense to iterate on them to start with, and
just get the corresponding class/feature from the qualified name in the
contributing metamodels.

Or, do a parallel descent in the trees.

* [2017-05-31 mer.]
** Re: How are virtual model attributes filtered out?              :emfviews:
Coming back to [[*How are virtual model attributes filtered out?][How are virtual model attributes filtered out?]].  I've established
that when attributes are absent in the viewpoint, they will be filtered in the
models.  But where is the connection taking place?

Stepping into an eGet call to find out where it plugs into our code.

Interesting: an eGet(EStructuralFeature) call is delegated to another eGet,
which looks up the feature ID and delegate to an eGet(int).  But in that one,
the feature ID is turned into ... an EStructuralFeature!  This the exact same
object given to the first eGet call in my debug trace.

After a while, we end up in ReproduceRule.get, and since I'm testing a virtual
association feature, in ReproduceElementImpl.getVirtualAssociation.  In this
case, it's a single reference, so this just virtualizes the target element.

Note: we cache virtualized elements in a map, but EStore also has his own cache
(see isCaching).

In eGet, if the feature is absent from the metamodel (filtered out), then EMF
raises an exception.

When we iterate on the contents of BusinessArchitecture using eContents, we
iterate on the structural features of the eClass.  So this just looks up in the
Viewpoint.

Since EMF uses the structure of the metamodel to iterate on the actual values of
the model, when they are filtered at the metamodel level, they do not appear in
the virtual model.

However, does this mean that there is a way to access these values in the model
if you know the feature name?

* [2017-06-02 ven.]
** Writing a test for modifying models                             :emfviews:
Since we have a virtual model, it should reflect changes in the models, right?
I'm not sure we support that yet, but I figure that there's nothing in the code
that should prevent it.  Caching, maybe.

I've written a small test, and it looks like changing the model does /not/
propagate the changes to the virtual model.

What blocks it?

: vea_labels.get(0).eGet(label_name)

I would expect the first ~get~ to return a proxy to the concrete object, and the
eGet would be delegated to the concrete object.

What's happening: we end up in ReproduceRule.get, where we get the concrete
feature, and the concrete element:

#+BEGIN_SRC java
EStructuralFeature cFeature = vElement.getConcreteFeature(feature);
Object value = vElement.getConcreteElement().eGet(cFeature);
if (feature instanceof EReference) {
  if (feature.isMany()) {
    value = new VirtualModelList<>(object, feature, Arrays.asList((List<EObject>) value));
    if (index != NO_INDEX) {
      value = ((VirtualModelList<EObject>) value).get(index);
#+END_SRC

Since the concrete element is a reference with >1 multiplicity, we create a
virtual list.  Hmm, that means we create a /new/ virtual list every time the a
reference is requested.  Maybe that's how EMF does it as well, providing an
immutable list.  But that does not seem necessary, since it's just a proxy in
this case, we could instantiate it once and save it for further calls, since it
will only delegate to a concrete EList.  Anyway.

We create the virtual list, and if the index is ~> -1~, we return the correct
value, otherwise we return the whole list.

Inside the virtual list, we walk the sublists to get the concrete element:

#+BEGIN_SRC java
EObject concreteEO = (EObject) l.get(k);
EObject virtualEO = virtualModel.getVirtualLinkManager().getVirtualElement(concreteEO);
#+END_SRC

Here, my concrete element is the Label EClass, and the virtual element is a
ReproduceElement containing the concrete element.

Finally, we translate it (again?) to a virtual element before returning
it... hmm.

#+BEGIN_SRC java
return (E) virtualModel.translateToVirtualElement((EObject) l.get(index));
#+END_SRC

Oh, I see.  The first part of the code only wants to find out the true index of
the concrete element, since we can have filter element that should be hidden.
Then, once we have the index, we translate the concrete element to a virtual one
and return it.

So: the ~get(0)~ call returns the Label EClass wrapped in a ReproduceElement.
So far so good.  Except, the concrete element is not the same Label instance as
the one in the concrete model.

Which kind of make sense: to construct the virtual model, we loaded the
resource.  To construct the model, we also loaded the resource from XMI, a
second time.  There's no reason for the instances to be the same.

So what's happening is we are modifying a label instance in memory, but it's
completely disconnected from the instance kept in the virtual model.

The virtual model makes no guarantee to hook into every instance of the model to
watch for changes.  I guess we could use the notifying architecture of EMF..

Our view would be updated if we saved the changes to the model, and recreated
the view... but that's not really an update anymore.

But let's follow the ~eGet~ call.  We end up in EStoreEObjectImpl.dynamicGet,
where:

#+BEGIN_SRC java
Object result = eSettings[dynamicFeatureID];
if (result == null) {
  // actually get the result and cache it
}
return result;
#+END_SRC

Oh oh.  So it /is/ caching values for us.  Here it finds the "Software kind" in
its cache and returns it.  If we remove the cached value, it goes to
ReproduceRule.get, where... the concrete value is "Software Kind".

So, yeah.  The above.  We are dealing with separate instances: the virtual model
is completely disconnected from the model, since they are loaded as separate
resources.

I'm not even sure that the virtual model /should/ reflect changes in this way.
At the very least, I would expect that changes to the underlying concrete models
held by the virtual model are reflected in the virtual model.

But we need to access the contributing models.  Let's do that.

: java.lang.ClassCastException: org.eclipse.emf.ecore.impl.DynamicEObjectImpl cannot be cast to contentfwk.EnterpriseArchitecture

Hmm that's interesting, I could cast to concrete instances when loading the
model myself, but when they are loaded by EView, they are dynamic objects...

Okay, okay, let's make it all dynamic access.

: org.junit.ComparisonFailure: expected:<[foo]> but was:<[Software Kind]>

Of course.  I'm guessing the EStore caching is the culprit here.  If I bypass
it...  Yep!  The test passes.  The change is reflected to the virtual model.

And adding:

#+BEGIN_SRC java
protected boolean eIsCaching() {
  return false;
}
#+END_SRC

to our ReproduceElementImpl is sufficient to turn caching off definitely.

But I'm not sure in what scenario one would peek at the contributing models this
way, rather than taking them straight from the resource.

The notifying approach is more promising, /if/ you can subscribe to changes from
/every instances/ of the same model, which I don't think you easily can.

Maybe hooking into the resource factory or something.  But that's out of scope.

** Accessing a filtered feature in the models                      :emfviews:
Filtered features are removed from the metamodel, but they don't seem to affect
the models in any way.  There /is/ code for skipping instances of FilterElement
in the virtual model list, but we don't construct any instances of these at the
model level.

So, in theory, we should be able to access the content of a filtered feature.
But maybe EMF does not have any mechanism to let us do so.

Wrote a test.  If you give eGet a feature object, it will convert it to a
feature ID using the eAllStructuralFeatures array.  That array is built from the
metamodel, so again, it will fail to find the feature.

I'm not sure there's a way around it.  But I'm unclear on where the eClass for a
model is coming from.  When you load a model, how do we instruct EMF to use the
filtered metamodels?  More questions...

* [2017-06-06 mar.]
** Following the trail while it's hot                              :emfviews:
Picking up where I left things last time.

The eClass for our view is inside the eProperties of the ReproduceElementImpl.
That field comes from EStoreEObjectImpl, and the class is set in
ReproduceElementImpl.init:

:    this.eSetClass(eClass);

The init method is called by the two constructors, but one constructor is
seemingly unused.  So we are left with:

#+BEGIN_SRC java
public ReproduceElementImpl(View vModel, EObject concreteElement) {
  super();
  EClass tempEClass =
      vModel.getMetamodelManager().translateToVirtualEClass(concreteElement.eClass());
  this.init(vModel, concreteElement, tempEClass);
}
#+END_SRC

The eClass used by the reproduce element is looked up in the maps built by the
metamodel manager.  That's where we assign the virtual metamodel with the
filtered features to the virtual model.

Trying to add the feature to the eClass using:

: vba.eClass().getEStructuralFeatures().add(f);

I get a nice array index out of bounds exception, since the eSettings array used
to lookup the feature is not extended when we add the feature as above.

I'm not sure it's something you'd want to do anyway.  But it doesn't work.

So I'll assume that we cannot access features filtered by the virtual
metamodel.  Good thing.

On the other hand, following the code I was reminded of something interesting:
when we filter a reference, what happens to its opposite (it if exists?).  I'm
guessing: nothing, so EMF will probably complain if we try to reach the
opposite.

Let's try it.

Hmm, inconveniently, none of the features we already filter have opposites.
Let's make a new, minimal, test.

Created a minimal ECore metamodel.  Now I need a model.  Here is the code to
generate it:

#+BEGIN_SRC java
String mmURI = "/viewpoint-test/metamodels/minimalref.ecore";
EPackage p = (EPackage) (new ResourceSetImpl()
    .getResource(URI.createPlatformResourceURI(mmURI, true), true).getContents().get(0));

EFactory f = p.getEFactoryInstance();
EObject a = f.create((EClass) p.eContents().get(0));
EClass bClass = (EClass) p.eContents().get(1);
EObject b1 = f.create(bClass);
b1.eSet((EStructuralFeature) bClass.eContents().get(0), a);
EObject b2 = f.create(bClass);
b2.eSet((EStructuralFeature) bClass.eContents().get(0), a);

Resource r = (new ResourceSetImpl()).createResource(URI
    .createPlatformResourceURI("/viewpoint-test/models/minimal.xmi", true));
r.getContents().add(a);
r.getContents().add(b1);
r.getContents().add(b2);
r.save(null);
#+END_SRC

Now the eviewpoint and eview files.  Do I need multiple metamodels in the
eviewpoint?  I think I will trigger the extension part of the code in Viewpoint
if I don't.  But it doesn't matter for filters, since these are applied
regardless.

Ugghh, spent 10 minutes debugging a typo in the modelRef of a linkedElement from
the weaving XMI...  Some validation of these files could be helpful.

Now I need an ECL file.. even though I'm only using filters, so technically I
don't need it.  Wait.  I don't need the ECL file for the view... if it doesn't
exist we'll just skip it.  But I do need an XMI for the view as well... an empty
one will do.

Okay, I can load the view without errors.  Now, I just need to check that the
reference is filtered, that it's opposite is not, and then get the opposite of
the opposite to see what happens.

Oh, interesting.  If I filter out a containment reference: A contains a number
of B, then the view will only contain A.  Since there is no way to access the B
anymore, I cannot access the opposite ref.

Let's try a non-containment then.

Strangely, ~view.getContents()~ returns a list with only one reproduce element,
for the A class from the metamodel.  Even though I haven't filtered anything
yet!

Okay, in View.setVirtualContents, we do:

: oneOftheSublists.add(translateToVirtualElement(r.getContents().get(0)));

Except, with the files I have created for this example, r.getContents() returns
the list [A, B, B], and get(0) returns just the A instance.  So that's why only
A appears in the virtual model contents.

Now, in the working example, getContents returns [EnterpriseArchiteture].  This
is coherent with the model XMI, where everything is wrapped in an
EntrepriseArchitecture tag.  Same for the other ReqIf and BPMN model: they are
wrapped in ReqIf and BPMN tags.

Hmm.  Actually, they are wrapped because that's how the model are made: they
each contain a class with containment references where everything should go.

But that means the View code will only work with such models.  Why not take
everything contained by the resource rather than just the first object?

Seeing as we already have a VirtualContents class that takes sublists...

Okay, made the change.  It shouldn't affect the existing examples since the
behavior is the same for resources containing only one element.  Now we just
don't ignore the other ones.

Wrote a test.  The filtered reference is not available on the metamodel.  Its
opposite is still present.  I think that's acceptable, if we say that views are
"lightweight", that they do not enforce EMF invariants.

However, we can get a hold of the filtered reference by the getEOpposite method
on its opposite.  That's weird.  I would expect it to return null, given that
it's filtered at the metamodel level.  Where is this getEOpposite call looking
for it?  Maybe it's cached?

But more worrying, I would expect to be able to follow the opposite reference.
That currently does an NPE in EStructuralFeatureImpl.getSettingsDelegate.

#+BEGIN_SRC java
EReference eOpposite = getEOpposite();
if (eOpposite != null)
{
  eOpposite.getEContainingClass().getFeatureCount();
}
#+END_SRC

First of all, why is this code even there?  It accesses the feature count... and
does nothing with it.

Regardless, getEContainingClass returns null... but that's not even a containing
reference.  Weird.

* [2017-06-07 mer.]
** EOpposite is set when the model is loaded                   :emfviews:emf:
That's the first answer.  When loading the XMI, bidirectional references set
their opposites to each other.

So when we filter out one part of the reference, the other still has its
eOpposite field set.

Second problem was the null EContainingClass.  It should return the class
containing the feature.  But since the feature is filtered out, it has no
containing class anymore.

Actually, bypassing the code:

#+BEGIN_SRC java
if (eOpposite != null)
{
  eOpposite.getEContainingClass().getFeatureCount();
}
#+END_SRC

we do get access to the feature value, and the test succeeds.  So this bit is
problematic.

I really don't know why it's there.  I understand that this getter is memoized,
so calling it is a way to force the computation of whatever underlying data it
returns.  But if you need to force the computation, it's because you are peeking
under the sheets of the interface; ergo, doing something you shouldn't.  Or, you
don't really need to force the computation, and this code is useless.

Doing a bit of git spellhunking...

: http://git.eclipse.org/c/emf/org.eclipse.emf.git/
: git://git.eclipse.org/gitroot/emf/org.eclipse.emf.git

Found [[orgit-rev:~/proj/org.eclipse.emf/::22137e7][one commit]] from 2005 (!) where the code was updated, but the strange ~if~
was already there:

#+BEGIN_SRC diff
       if (eOpposite != null)
       {
-        eOpposite.getEContainingClass().getEAllStructuralFeatures();
+        eOpposite.getEContainingClass().getFeatureCount();
       }
#+END_SRC

Before that, I get the initial git commit from 2004 when the repo was created by
splitting from a previous CVS probably (there are .cvsignore files lying
around).  From what I can find, the CVS repository is now unavailable, so I
won't get any history beyond that.

** Cleaning up URI loading                                         :emfviews:
This was getting annoying to deal with a dummy workspace just to have the test
resources.

Asked G about it, he suggested I use createURI instead of
createPlatformResourceURI, to avoid being tied to the workspace.  We tried it
together, and using relative paths with createURI will load the files from the
current plugin.

Had to make changes in multiple places where we previously used platform URI, or
worse, findMember on the workspace.  Now it's more homogeneous.

He also suggested we pass URI to the EMFViews core instead of strings, so that
we leave the problem of creating and resolving them to the client.  I agree, and
would even go as far as passing resources directly.

*** Investigate duplication of model loading from XMI
Since in Viewpoint we pass around URI strings when we really want to deal with
EPackages, there may be some duplication where we load a package from the XMI
instead of getting an EPackage directly, or getting it from a registry.

That seems like unnecessary work, and a potential source of bugs (since we have
clones of models lying around, so strict equality wouldn't work).

* [2017-06-09 ven.]
** Trying out Eclim for controlling Eclipse from Emacs        :emacs:eclipse:
Out of the box I set the bar a little too high for Eclim, since I'm running
Eclipse 4.7 M6, and only 4.6 is supported at the moment.

There is a development branch for 4.7 on the Git.  I try it out, follow the
build from source guide.  But it fails to build on my Eclipse config, since I
have a separate configuration folder and platform folder.

Ok ok.  Maybe I should try a plain Eclipse to see if it's even worth the
trouble.  I'm afraid it doesn't have useful stuff like Javadoc on hover (maybe
using Eldoc?).  Let's see.

It installs with 4.6.  Now I run the eclimd daemon from inside Eclipse
(View->Eclimd).

Not that slow.  You can get Javadoc for a type, not on hover, but with a
binding.  Auto-completion seems to work, although you don't have the Javadoc for
completion items.

I think the way windows are created and (not) disposed for each function is more
annoying than helpful.  I'll keep my current setup.

** Using Eview for metamodels                                      :emfviews:
To use EView for the metamodel level, we would need to provide a viewpoint.  The
viewpoint is used to populate the maps in the metamodel manager; essentially,
its role is to assert what features are present on the viewpoint.

If the Eview is used for the metamodel, its viewpoint should be the Ecore
metamodel itself.  Maybe I can try building a test around that.

* [2017-06-12 lun.]
** Made a class diagram of emfviews.core                          :emfviews:
A bit hairy.  PlantUML uses GraphViz behind the scenes, so the layout engine
quickly shows its limits when you get a dozen of boxes.

Regardless, it helps to see the whole picture.

I think I want a sequence diagram of Viewpoint.doLoad, and most importantly,
EView.doLoad.  Probably an object diagram of everything created by
EView/Viewpoint for the minimal example.

* [2017-06-16 ven.]
** More diagramming                                                :emfviews:
I fleshed out the class diagram a bit, fixing the layout so it's more readable.
Dependency arrows are in a light color so they don't drown the rest of the
information.

I wrote a small JS bookmarklet to add interactive highlighting of the outgoing
edges from a node, so we can make sense of all the information that's in it.

** Review of tools for creating UML class diagrams                      :uml:
I tried other tools for UML diagrams; small tools like Dia or yEd give fine
control over the layout, but you have to do everything graphically.  yEd has
advanced layout and grouping features, with collapsing.

Can't easily export PlantUML output to something these tools eat, unfortunately.
PlantUML has XMI export, but it's only for the classes, not the arrows.

Large tools like Modelio/Papyrus/UML Designer are slow and cumbersome for
drawing just a class diagram if you don't need all their facilities for
generating code from it.  One of them froze when I tried to zoom out on the
nearly empty canvas.

I think yEd is decent enough for quickly whipping something up, and the
auto-layout features does a better job than GraphViz.  Too bad it's proprietary.
Though you can export to GraphML which is an open format.

Trying out the ObjectAid plugin for generating class diagrams directly from the
code.  It does a decent job at that, it can even show dependencies between
classes.  I think it's picking up constructor calls; but not casts.  The
auto-layout feature avoid nodes overlapping, but seems to largely ignore edges,
so it's overall useless.  Also, you cannot control what hide/show individual
attributes or links.  The diagram is serialized to XML by default, so it's
reusable, but there is no export to a common graph format, only images (and no
SVG).

** Exciting use case for EMFViews                              :emfviews:uml:
That gets me thinking.  The output of automated tools for generating class
diagrams will always be too rich, will contain too much information.  Usually,
you want to filter out this information to focus on a specific functionality, to
understand the project piece-wise.  That's why I started out by mapping the
project manually, because I knew that I wanted to do a partial representation of
the project, even with some simplifications.

So, usually, you want /views/, not the whole picture.  Using EMFViews to create
partial views of programs would be a terrific use case (and using it on itself
would be nice).  We might also want to aggregate info from multiple models: like
a model of which Java statetement was executed by some test (impact analysis),
combined with a MoDisCo model to create a view of a class diagram where you only
see the class/methods/attributes used by a specific test.

Interestingly, MoDisCo has entries for each cast and constructor invocation in a
project, but if you want to know that a specific type is used as argument to a
method or indirectly through the return value of a method (i.e.,
a.getB().foo()), it seems you have to extract it yourself.

* [2017-06-20 mar.]
** Converting PlantUML to GraphML                              :plantuml:uml:
I've finished this big object diagram, giving me a concrete view of what objects
are created when we call EView.load.

It's a bit cumbersome to navigate, since GraphViz made a bit of a mess of it.
It's about twice as large as the class diagrams, and it's only a /very/ simple
example (there are no virtual associations involved, and only one contributing
metamodel).

I was thinking of looking if yEd was able to get a better layout out of it.
Since this is the second diagram I made where I wish there was an easy way to
import PlantUML files into yEd, let's shop for solutions.

There is a [[https://github.com/Kesin11/plantuml_class_digram_parse][PlantUML parser there]].  It's in Perl, and doesn't seem to parse
much.  Class diagrams, classes and relationships.  But doesn't look like it
parses labels on relationships.  Also, I don't know Perl.

There is [[https://github.com/leungwensen/plantuml-parser][one in JS]].  This one looks rather complete.  There's a PEG grammar file
that looks exhaustive.  But it doesn't seem to work as-is.  Calling plantUMLParser.parse:

#+BEGIN_EXAMPLE
	      peg$startRuleFunctions = { start: peg$parsestart },
	                                        ^

ReferenceError: peg$parsestart is not defined
#+END_EXAMPLE

Apparently, the parser is lifted from [[https://github.com/bafolts/plantuml-code-generator][plantuml-code-generator]].  That project
looks more fleshed out (there's a README, at least).  And in fact, that's where
the PEG grammar is coming from.

Trying it out.. it looks like loading the parser generated by pegjs does the
trick.  On a simple string, it looks for the "@startuml" line, so that's a good
start.

On my object diagram though:

#+BEGIN_EXAMPLE
/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:2247
      if (peg$c91.test(input.charAt(peg$currPos))) {
                             ^

TypeError: input.charAt is not a function
    at peg$parsenoise (/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:2247:30)

#+END_EXAMPLE

:(

Hmm, wait a minute.  Maybe I'm not passing a String?  I was using fs.readFile
from node, and I forget to pass the encoding.

Haha, yes!

#+BEGIN_EXAMPLE
/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:3299
      throw peg$buildException(
      ^
SyntaxError: Expected "@startuml", [ \t], [\n], [\r\n] or end of input but "'" found.
    at peg$buildException (/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:361:14)
#+END_EXAMPLE

Doesn't support comments?  Looks like it does, but not before the ~@startuml~
tag.  PlantUML doesn't care... fixing.

#+BEGIN_EXAMPLE
/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:3317
      throw peg$buildException(
      ^
SyntaxError: Expected [^\r\n] but "\n" found.
    at peg$buildException (/home/fmdkdd/proj/plantuml-to-graphml/plantuml.js:361:14)
#+END_EXAMPLE

What?  Grmbl grmbl.  If you don't tell me /where/ in the input you failed to
match. that's going to be tedious.

There's a ~--trace~ option I can pass to pegjs.. but it's still not telling me
where it failed.

plantuml-code-generator uses pegjs 0.9, and there's a 0.10 with "improved error
messages".  Let's see.

Still doesn't tell me the location in the input where it failed to match...
Ahah!  Catching the syntax error in a try/catch, it does include location
information.  The default toString does not report it.

Okay, so it's not taking '/' or '.' in attribute names.  Pretty strict.  I guess
it's because the grammar is used to /generate/ code from the PlantUML file, so
you don't want anything funky in your identifiers.  But it ultimately depends on
the language, so...

After making it more lax with object names / members names, it appears it's not
parsing names of relationships either.

At this point, I know that I can use PegJS to make a more generic parser... or I
could write my own... or I could just use the PlantUML parser and add a GraphML
exporter in there.

I think I'd rather have it as a standalone tool than an addition to PlantUML.

[[http://graphml.graphdrawing.org/primer/graphml-primer.html#Graph][GraphML has a spec]], under CC-by.  Doesn't look too fancy, just XML.  A good POC
would just output nodes and edges, ideally with attributes (as a label inside
the node?  Just have to check out what yEd exports...)

#+BEGIN_EXAMPLE
    <node id="n0">
      <data key="d4"/>
      <data key="d5"/>
      <data key="d6">
        <y:UMLClassNode>
          <y:Geometry height="120.48000000000002" width="262.56000000000006" x="318.71999999999997" y="-10.240000000000009"/>
          <y:Fill color="#FFFFFF" transparent="false"/>
          <y:BorderStyle color="#C0C0C0" type="line" width="1.0"/>
          <y:NodeLabel alignment="center" autoSizePolicy="node_width" configuration="CroppingLabel" fontFamily="Dialog" fontSize="13" fontStyle="plain" hasBackgroundColor="false" hasLineColor="false" height="21.1328125" horizontalTextPosition="center" iconTextGap="4" modelName="internal" modelPosition="c" textColor="#000000" verticalTextPosition="bottom" visible="true" width="262.56000000000006" x="0.0" y="3.0">Viewpoint</y:NodeLabel>
          <y:UML clipContent="false" constraint="" omitDetails="false" stereotype="" use3DEffect="false">
            <y:AttributeLabel>-contributingEPackages: List&lt;EPackage&gt;</y:AttributeLabel>
            <y:MethodLabel>#doLoad()
#doSave()
+getContents()
+getResourceSet()</y:MethodLabel>
          </y:UML>
        </y:UMLClassNode>
      </data>
    </node>
#+END_EXAMPLE

Looks like yEd has its own additions to the GraphML format... That was more or
less expected, since the GraphML doesn't have much in it, and yEd adds a bunch
of information.

** Observations from the diagram                                   :emfviews:
The EPackage has three clones lying around.  One is the original, one is the
filtered copy, but then one is used by the VirtualLinkManager to map virtual
classes.  There's probably a better way to do it.

I'm not sure that have not duplicated other stuff as well.  Should redo the
experiment by noting the objects id to be sure.

* [2017-06-21 mer.]
** Is it possible to use neato instead of dot with PlantUML?       :plantuml:
Not out of the box.  There is an argument ~-graphvizdot~, but passing
~/usr/bin/neato~ has no effect.  There is also some "layout strategy" option in
the parser, but it's not connected to anything.

So, the PlantUML -> GraphML route still stands.

* [2017-06-22 jeu.]
** Getting a heap dump from Eclipse                            :eclipse:java:
If I wanted to generate an object diagram mechanically, I would first need to
get a heap dump.

Looks like there are at least [[https://stackoverflow.com/questions/25168490/java-eclipse-create-heap-dump-on-breakpoint][two ways]] to do that.  jvisualvm comes with Java,
and you can plug into an existing process.

So I put a breakpoint in Eclipse, and obtain a heap dump in the HPROF format.
JVisualVM allows me to browse this dump more or less like the Eclipse debugger
can (there's fewer "nice" short string format).

There's also ~jhat~, a bundled command, that creates a local server to browse an
HPROF dump.  It's not very useful for browsing through, since it doesn't show
attribute values.

Most tools dealing with heap dumps seem targeted to people who want to find
memory leaks, understandably.  Like [[http://www.eclipse.org/mat/][MAT]].

JVisualVM accepts plugins though, so we could imagine an export to DOT.

Another way to obtain an HPROF dumb, without jvisualvm:

: jmap -dump:format=b,file=/tmp/foo.hprof PROCESS-PID

This can then be opened in MAT for browsing.  Though I'm not seeing values for
inherited attribute in MAT... but unless JVisualVM was doing some peeking in the
runtime process when displaying the HPROF, the info is probably there.

[[https://web.archive.org/web/20121221115642/http://java.net/downloads/heap-snapshot/hprof-binary-format.html][Here's some documentation]] on the HPROF binary format.  But it might not be the
freshest info.  Looking at the source of jmap or jvisualvm is also an option.

** Some concerns about creating object diagrams mechanically       :emfviews:
First, heap dumps are huge, and you are concerned with only a fragment of it at
one time.  MAT reports nearly 500k objects in the heap for the small test I
built the object diagram from.  In the object diagram I made, there are ~50
objects.  Whitelisting interesting objects should be the default.

Second, heap dumps are instantaneous and cannot give any temporal information
individually.  That's relevant for keeping track of objects collected by the GC.
In the object diagram I made, an instance of LinksProjector is created by
VirtualLinkManager to setup virtual associations, but no reference to it is held
so it is collected when the method ends.  Depending on when the heap dump is
captured, you might or might not see this object.  Taking multiple dumps can
help, but is not guaranteed to be correct, unless you are able to register all
allocations.

In fact, the JVM can also perform escape analysis and decide to allocate objects
directly on the stack.  In that situation, I'm not sure the object would appear
in a heap dump at all.  So, again, heap dumps cannot give you a full list of
created objects.

Third, you might want to enrich the visualization of some types or values.  In a
heap dump, objects are just nodes that points to other objects.  But depending
on the type, you might want to make them distinguishable.  Lists, arrays and
hashmaps are easier to recognize as tables.  In the object diagram, I've made
simplifications for URI objects to just their string value.

* [2017-06-26 lun.]
** Wrote a test for virtual associations                           :emfviews:
Using minimal metamodels and models.  The main difference with the minimal
filters test is that this time we need a view ~weaving.xmi~ that's not empty.

Providing the viewpoint weaving.xmi is not enough.  It's used to construct the
metamodel of the virtual model, but not to populate it.  The weaving.xmi of the
view is used by the LinksProjector to create the virtual associations.

One difficulty to create this view weaving model was to find the correct
~elementRef~ values.  A first clue is in LinksProjector.getReferencedObject,
where this field is used:

: referencedElement = r.getEObject(elementRef);

It calls Resource.getEObject, which accepts an URIFragment from EMF.  Here are
examples of URI fragments from the three-model-composition test (where they are
generated by ECL):

#+BEGIN_EXAMPLE
  //@architectures.1/@processes.0
  _48wAUN6xEeCbzp_EHZybUg
  //@architectures.0/@strategicElements.0
  rmf-19428170-0b70-4b81-9fd2-0cdec5778a49
  //@architectures.0/@strategicElements.1
#+END_EXAMPLE

Some are "structured fragments", that reflect the path to follow in the
resource.  It's a mix of structural features names and indices for contents
lists.  Others are "IDs", which look like hashes.

To find the correct fragment, one can load the models in a resource, and call
~Resource.getURIFragment(eObject)~ on the EObject in question.

Turns out, with the simple models that I have, the fragment ~/0~ works.

Now, it's brittle to use resource-dependent indices; I'd rather use a qualified
name, but since this field is supposed to be created by ECL... maybe there's no
easy way to construct a qualified name there.

Hmm, using ~/~ as fragment also works in this case...  I cannot find
documentation on the URI scheme used by EMF.  All I found was a comment by Ed
Merks saying that it was "XPath-like", but not XPath.

Regardless, after discussing with H., I think we are aiming towards qualified
names for this field, as they are more readable.  Just have to check that ECL
can generate them.

* [2017-06-28 mer.]
** Rethinking the virtual links metamodel                          :emfviews:
We have some attributes that are never used, some attributes that are used in
bad ways, and things we cannot express.

The requirements are:
- We can have any number of contributing models
- We can transpose concepts and properties from contributing models in the view
  so they appear in the view
- We can filter concepts and properties from contributing models so they do not
  appear in the view
- We can create new concepts, properties and associations in the view that do
  not exist in the contributing models

Additionally, we can choose between "blacklist" and "whitelist" modes: blacklist
mode, the default (and current behavior), is when the view contains all the
concepts of the contributing models, and you can filter some concepts /out/
explicitly.  In whitelist mode, no concepts are included by default, and you
must filter them /in/ explicitly.

We could also want the same feature at the concept level, to filter out/in
properties for each concept separately.

After sketching a few alternatives and iterating with H., we converged [[file:doc/virtuallinks-metamodel3.svg][on one
design]] that ticks all the boxes, and should be a definite improvement over what
we had so far.

Some notes:
- It supports blacklisting/whitelisting at the view level, but not for
  individual concepts.  You don't lose expressive power, but only convenience
  and maybe performance by having to exclude or include a bunch of properties.

- The fact that synthetic elements (New*) are also instances of LinkedElement
  (through VirtualElement) lets use them as target for other synthetic
  elements.  So a NewProperty can be added to a NewConcept, rather than being
  locked to concepts belonging to the contributing metamodels.

  This is also means there is a risk of circular dependencies (if A and B are
  new elements, and A refers to B and B refers to A).  This can happen for,
  e.g., associations: Assoc A1 from A to B has opposite A2, A2 from B to A has
  opposite A1.  Cannot set the opposite fields before the two associations are
  created.

  We'll see how best to resolve that once we get to translate the metamodel to
  EMF code.  Using the order of elements from the resource looks like a decent
  first approach.

- The model is quite orthogonal, but lacks constraints for invalid situations.
  For instance, NewAssociation ~opposite~ field should target either
  NewAssociation (if VirtualElement) or have an FQN that points to an
  EReference.

  Likewise, a NewConcept can have sub- and super-concepts, but you can create
  non-sensical hierarchies like A < B and B < A.

* [2017-06-30 ven.]
** Switching to the new virtual links metamodel                    :emfviews:
Wrote the metamodel in Ecore, generated the code.  Errors everywhere.

Disregarding the UI and Editor plugins for now, to focus on the core and on the
tests.

Apart from renaming things to follow the new metamodel, the code is already
simpler in a few places, when fetching the new element from the metamodel or
model notably.

For now I'm just trying to get back the previous functionality, and disregarding
the additional functionality like creating associations between virtual
elements, and synthesizing new elements (for which I didn't have tests anyway).

One difficulty is that we cannot use fully-qualified names to target model
elements.  The code in EMFViewsUtil.findElement is not working for models
because it tries to get the "name" feature on the EClass, but model objects have
their metamodel class as EClass, and these don't necessarily have a name.  We
/could/ write a findModelElement function that first gets the structural feature
corresponding to the FQN, and then try to eGet this feature in the model.  That
wouldn't be sufficient if we wanted to target EClass instead... so the approach
has to be different.  Besides, one named feature on the metamodel may correspond
to multiple model objects, in the case of lists.

For the moment, I'm sticking to EMF URI fragments for the model level.  That's
one discrepancy between how we use the virtual links metamodel for viewpoints
and for views.

Currently passing 2 tests out of 5... the three-model-composition is larger, so
harder to fix.  It generates the weaving model for the view through ECL, so I
have to fix that as well.

Fixing ECL...  looks like it's still missing something.  Will investigate next
week.

* [2017-07-03 lun.]
** Installing Eclipse Oxygen                                        :eclipse:
Release version.  I was on milestone 6 previously.

As usual, since it's easier to add plugins than to remove them from Eclipse, and
a lower number of plugins makes for a healthier Eclipse, I went with the Oxygen
platform download:

http://download.eclipse.org/eclipse/downloads/drops4/R-4.7-201706120950/

Then, I added:

- JDT
- PDE
- EMF SDK (EMF is already included)

EMFViews requires also OCL, Epsilon and Epsilon EMF integration.

I used the update site for Epsilon 1.2, since migration to version 1.4 is still
a TODO.

After that, and after making sure the target platform and run configuration are
coherent, I was able to run the tests.

** Fixing tests for the new metamodel                              :emfviews:
We actually have 4/5!  Three-model-composition runs into an NPE.  Investigating.

We fail in EStructuralFeatureImpl:

#+BEGIN_SRC java
EClassifier eType = getEType();
Class<?> instanceClass = eType.getInstanceClass();
#+END_SRC

eType is null.  Since a feature is a typed element, it /shouldn't/ be null.

Found it: the setEType in Viewpoint is null... because targetElem is null.
That's because of a wrong path in the viewpoint weaving model (BPMN instead of
bpmn2).

Will have to make sure we find the element before creating associations...

Still, too bad EMF doesn't inform us that the EReference is invalid before...
That probably stems from the fact that we create the EReference piece-wise, so
we can violate invariants before we are done initializing it, and there's no way
to tell EMF we are done.  The builder pattern solves this.

Added some checks.  Found a bug in another concreteElement for reqif (reqif10 is
the name of the root), which was not tested.  Early errors pay off!

* [2017-07-04 mar.]
** Writing tests for adding concepts                               :emfviews:
Some unresolved questions.

Where do new concepts go?  If they subtype an existing concept from a
contributing package, they could go in that package.  But if they subtype none?
Or if they subtype two concepts from separate packages?

After discussing with H., we settled on putting all new concepts in a specific
package that has the name of the viewpoint.  Now the viewpoint must have a name.

In testing for this feature, there's a bit of non-determinism: the order of
packages in the virtual contents of the viewpoint is undefined.

Actually, the order stems from the order of the underlying hashtable used by the
package registry were we put these packages.

It would make sense to specify the order.  One order that seems obvious is to
take the order of the contributing models, plus the extra virtual package after
these.

I added support for new properties as well.  We now have basic functionality as
provided by the new metamodel.  I should go over what was possible in the
previous version to make sure we have not lost any expressive power.

* [2017-07-05 mer.]
** Handling errors in EMF models                                   :emfviews:
Wrote a small test.  EMF does not seem to do any validation of metamodels
created dynamically.  However, calling Diagnostician.INSTANCE.validate can give
you a list of diagnostics: if two attributes are the same name, then it's not
OK.

The code that does the actual validation is in ecore.util.EcoreValidator.

** Handling errors in Viewpoint                                    :emfviews:
There are many ways in which loading a weaving model and executing it can fail:

#+BEGIN_SRC java
EObject parent = tryGetEObject(p.getParent());
if (!(parent instanceof EClass)) throw new InvalidLinkedElementException(String
    .format("Parent of new property '%s' should be an EClass", p.getName()));
EClass parentClass = (EClass) parent;

String n = p.getName();
if (n == null) throw new ViewpointException("New property name is null");
if (!n.matches("[a-zA-Z][a-zA-Z0-9]*")) throw new ViewpointException(String
    .format("New property name '%s' should be non-empty, start with a letter, and contain only letters or digits",
            n));

for (EStructuralFeature f : parentClass.getEAllStructuralFeatures()) {
  if (n.equalsIgnoreCase(f.getName())) throw new ViewpointException(String
      .format("New property name '%s' is already taken in class '%s'", n,
              parentClass.getName()));
}
#+END_SRC

In many respect, the weaving model is a language, and Viewpoint.loadWeavingModel
is an interpreter.  These ViewpointException are thus semantic errors, stemming
from an invalid usage of the language.

Now, the problem is that mixing exceptional code with the happy path is hard to
read.

Solutions:

1. Do the validation in a separate class, before going down the happy path.

   That amounts to writing an interpreter that visits the whole model,
   simulating operations taken by the viewpoint, but not actually creating any
   side effects, just throwing exceptions if the invariants are not obeyed.

   Pros: happy path is totally separated from exceptional code.  All possible
   errors are treated on the side.

   Cons: duplication of visiting code, duplication of logic (to check if a
   NewConcept has a unique name, you have to collect all the new concepts),
   duplication of work (validation is interpreting once, and the happy path is
   interpreting a second time).

   Not sure if we can actually catch /all/ errors without creating the
   side-effects on Viewpoint.  So there might still be exceptional code in the
   happy path.

2. Keep the validation in the happy path, but as one-liners.

   E.g., call ~validateName()~ on the name before using it.  The code in
   validateName takes care of all exceptional cases, and is hidden away.

   Pros: exceptional code is kept to a minimum in the happy path.  No
   duplication of visiting code/logic/work.

   Cons: If we do any work optionally, then we may never raise an error for an
   invalid usage.  That's like every dynamic programming language, where code
   that is never executed is never checked.


Will think more about this on the way home.

* [2017-07-07 ven.]
** Dealing with exceptional cases in Viewpoint                     :emfviews:
I've adopted solution 2.  It's the simplest, and with an utility function like
this:

#+BEGIN_SRC java
  private ViewpointException EX(String msg, Object... args) {
    return new ViewpointException(msg, args);
  }
#+END_SRC

You can write:

#+BEGIN_SRC java
if (model == null)
        throw EX("Model '%s' of concrete element cannot be found in package registry", modelURI);
#+END_SRC

Which is minimal noise.

In concert with the Optional type, we can write this:

#+BEGIN_SRC java
EObject obj = EMFViewsUtil.findElement(model, path)
          .orElseThrow(() -> EX("ConcreteElement '%s' cannot be found in model '%s'", path,
                                modelURI));
#+END_SRC

I've thought about moving the different types of errors in ViewpointException,
like so:

#+BEGIN_SRC java
static ViewpointException INVALID_NAME(String msg, Object... args) {
  return new ViewpointException("Invalid name '%s'", String.format(msg, args));
}
#+END_SRC

But that's creating an interface that I have no use for at the moment.  Maybe
when I write tests for failures, that would be easier to check against an error
type (from an enum?) than the exact string message.

* [2017-07-10 lun.]
** Reviewing features cut in the new weaving metamodel             :emfviews:
From what the previous code did for the "Extension" case in Viewpoint.

| Previous          | Now    |
|-------------------+--------|
| refine            | yes    |
| generalize        | yes    |
| add property      | yes(1) |
| filter property   | yes(2) |
| filter class      | yes(2) |
| add constraint    | no     |
| filter constraint | no     |
| modify property   | yes(3) |
| add reference     | yes(4) |
| filter reference  | yes(2) |

1) we don't support all primitive types yet, but that's a matter of minutes.
2) superseded by ElementFilter
3) indirectly through filter+add, but are they really equivalent?
4) the previous code supported specifying containment reference

So we are not missing anything major.

Now, the most interesting aspect of the new weaving metamodel is the ability to
target virtual model for properties, concepts and associations.  Let's focus on
that.

The "VirtualLink"/"VirtualElement" objects that are in the weaving model can be
thought of as "instructions" or "construction orders": that's how they are used
by the Viewpoint.  From a NewConcept, we will create an EClass.  The two objects
are different, but the NewConcept stands in for the EClass, and there's a clear
mapping from one to the other.

So, we can collect the EObject created from a VirtualLink in a map, and look up
this map whenever we want to target a VirtualElement.

** Solving circularity in the new weaving metamodel                :emfviews:
As already noted, creating a NewAssociation R1 with an opposite R2, R2 has to
exist at the time R1 has its opposite set, otherwise it cannot work.

Currently, since new associations are created in the order given by the XMI,
this cannot work.

Solutions:

1. Delay setting the opposite value of new references until after all references
   are created.

   That fixes the circularity for opposites, but not for other cases.  Are there
   other cases?  I'm not sure.

2. Do two passes: one to create virtual elements and populate the mapping, and a
   second one to set their EMF fields.

   Solves all potential circular dependencies.  Also removes the order
   constraint of the XMI elements.  Slightly more code complexity.

3. A fully virtual metamodel would not have this issue, as it would be lazy
   anyway.  The value for the opposite would be resolved only when code queries
   it (e.g., the Diagnostician).

   Might be the solution we end up adopting anyway.


Circular references could happen for concepts if, e.g., C is new and has D as
subconcept, and D is new.  D effectively has C has superconcept, but we don't
need to repeat it.  If we did, then we would end up with a circular dependency.

I'll go with #2, in the interest of correctness.

Done.  Code complexity was not increased much.  A bit of additional implicit
control flow dependency between methods (have to populate the synthetic element
map first).  Might be mitigated by making the map an explicit argument of the
build* methods.

* [2017-07-11 mar.]
** Implementing whitelisting                                       :emfviews:
In blacklisting, when you filter an element, you are implicitly filtering every
element under it, since we are dealing with trees.

So it makes sense that in whitelisting, when you filter an element /in/, it
should implicitly include all the elements that are /above/ it in the tree, but
not the elements below.  Otherwise, you cannot access the element, and you would
have to explicitly filter /in/ everything above it.

In practice, we can delete everything that is not filtered.

Idea: go through all contributing packages and their contents, recursively, and
create a list of (path, objects) tuples, where path is the qualified name to
access the objects.  Then, remove all tuples from the list where path is a
prefix to to an element filter.  Then, delete all objects that remain.

But Java has no tuples.  Okay, I guess I can generate the list on the fly: for
each EObject, determine its path, if it's not a prefix of any element filter,
add the object to the list.  Delete all objects in the list.

If an EObject is not a prefix of an element filter, we can add it to the
elements to delete /and not descend to the children/.  But if it is a prefix, we
have to descend until it's a match, and add the children to the elements to
delete.

Well, no, actually we can't short-circuit, because one of the children may be
explicitly whitelisted as well.  So we can delete only objects whose path is not
a prefix of any element filter.  That simplifies the code, but increases time
complexity.

* [2017-07-12 mer.]
** Whitelisting complexity is slightly worse than blacklisting     :emfviews:
Whitelisting is O(len(model)*len(filters)), where len(model) is the total number
of elements in the model graph, across all contributing packages.

Blacklisting loops on the filters, but it calls findEObject, which calls
findElement, and that is O(len(models)) as well.  So the two complexities are
equal.

Except than in practice, findElement can shortcut, while whitelisting in
applyFilters never shortcuts.

But, whitelisting works now.  The better approach would certainly be to be fully
lazy.  Will think about that.

** Weaving metamodel variation                                     :emfviews:
In the last meeting, it has been brought up that the new weaving metamodel was a
bit confusing: new associations sources and targets point to linked elements,
but these can be new association, which does not make sense.

At the moment it's a runtime error, but it could be enforced by the metamodel.
We could use OCL constraints, but just having a separate type for valid targets
would work.

However, while we could do that for virtual elements, we cannot do that for
concrete elements, since we only have a path to link to them.

Unless it's possible to link directly to the concrete elements... by loading the
weaving model alongside the contributing models in the same resource set?

Wrote a test... it's definitely possible to add EObjects directly into the
weaving model, save and load that resource.  No need for findElement, and it
should work with any EObject, not just named objects.

Made [[file:doc/virtuallinks-metamodel6.graphml][another class diagram]].  But I'm not sure it's worth it, since it might tie
too much to Ecore.

Here is a [[file:doc/virtuallinks-metamodel7.graphml][slight variation]], where we only add "Concept" and "Association" and
remove "VirtualElement".  That way, we are sure that synthetic elements cannot
be bogus.  But we still have no clue for concrete elements, since we only have
the FQN string.

* [2017-07-18 mar.]
** Virtualizing the viewpoint                                      :emfviews:
Currently, Viewpoint is not truly virtual: we use the weaving model to build the
viewpoint at construction time, and it can never change.

The upside is that it's simple: you deal with stuff that's not changing.  And
it's probably more efficient that way: the virtual contents are built ahead of
time.

The downsides are that, for large metamodels, it might not be that efficient to
iterate over all of their features ahead of time, if only a few of them are ever
used.  And we lose the ability to mutate the viewpoint when the metamodels
change...

But how often to metamodels change?  And we can even subscribe to their changes?

Also, if an EAttribute changes name, or is deleted, but it was the target of a
NewAssociation in the weaving model, now the weaving model is invalid.  Should
the viewpoint subscribe to changes to the weaving model as well?

H. reminded me that the point of EMFViews is to have a /lightweight/ solution to
combine multiple models.  Not only to create new metamodels and models from
existing ones—model transformation tools can do that already—but to combine
huge models quickly.

Another concrete use case that surfaced is for NeoEMF: using EMFViews to control
the visibility of features for users with different access privileges.

*** Use case 1: lightweight combination of models
Now, for the first use case.  Let's say you have a few metamodels and want to
create a viewpoint.  You:

1. Create an .eviewpoint file
2. Specify the weaving model
3. Create the viewpoint

Now, let's assume the viewpoint contents are built at creation, and cannot be
updated.  That's the current state.

**** Updating a metamodel
You update the metamodels.  You remove a concept, or rename a concept.  The
viewpoint doesn't change.  You have to recreate it.

- Rebuild viewpoint

This discards the viewpoint and rebuilds it, using the .eviewpoint file and
weaving model once again.

If that concept was referenced by the weaving model and you did not propagate
the changes to the weaving model, then the viewpoint will emit an error.  Then
you need to:

- Update weaving model
- Rebuild viewpoint

Otherwise, the viewpoint will now reflect the new versions of the metamodels and
weaving model.

**** Updating the weaving model
Now you update the weaving model, by adding another contributing model.  The
viewpoint still does not pick up this change.  You have to:

- Rebuild viewpoint

Every time you change the weaving model.

*** Use case 2: access control
You define a viewpoint for access control on an existing metamodel:

1. Create an .eviewpoint file
2. Specify the weaving model (whitelist)
3. Create the viewpoint

It looks like the same thing.  Actually, in use case 1, the actions are probably
interactive, and ultimately map to actions the core API.  In use case 2, the
actions are probably direct calls to the API.

*** When the viewpoint is virtual
One approach is to make the viewpoint fully lazy.  Currently, the only entry
point to a Viewpoint is the ~getContents~ method of the resource.  And
currently, we return a virtual contents object that has been built at loading
time.

If, instead, we build the virtual contents object each time ~getContents~ is
called, then we are guaranteed to always reflect the latest states.

*** Let's focus on virtualizing the viewpoint without considering updates for now
After debating with H., we just want to have the Viewpoint emit virtual
elements, as is the case currently for EView.

How to handle updates in the viewpoint or weaving model is then a separate
concern that we might tackle later.

** Trying to wrap the objects returned by Viewpoint                :emfviews:
In the VirtualContents.  Questions abound.

First of all, most of the tests that deal with Viewpoint should be changed to
use the reflective EMF API.  Now, we know that we have EPackages, but we should
have VirtualElements that may or may not be packages.

But, do we need to wrap recursively the contents of EPackage?

* [2017-07-19 mer.]
** Virtualizing viewpoint: first approach                          :emfviews:
The point is to avoid copying the contributing models, and just proxy.

For each contributing package:

- create a new VirtualEPackage that delegates to the EPackage

That should be transparent right?

Looks like the Diagnostician is not happy, as it assumes it can convert to
InternalEObject... but these are not.

Too bad.  Let's toggle it off.

All my tests pass... though they shouldn't, since here I am modifying the
original metamodels.  But the tests never check for that.

Hmm, but this approach won't work.  Or at least, it works at the metamodel
level, but we should use the same architecture for the model level.  There, we
will have no other choice but to be a VirtualEObject.  If VirtualEPackage is a
subclass of VirtualEObject, then it works.

One of the disavdantage of this approach is that implementing EObject/EPackage
has a lot of methods.  To filter classifiers according to the blacklist for
instance, there are at least two relevant methods:

- getEClassifiers()
- getEClassifier(String)

But, one could also obtain the list of classifiers through the reflective API of
eInvoke, eGet, etc.  That's a lot of holes to patch.

The EStore approach has only two methods: get and set.  Easier to make sure it's
correct.

Otherwise, there's the DynamicEObject approach.

** Virtualizing viewpoint: using EStore                            :emfviews:
Running into weird exception of impossible casts from EPackageImpl$2 to
EObject...

That's an anonymous inner class to EPackageImpl, but where is it coming from?

#+BEGIN_SRC java
 public EList<EClassifier> getEClassifiers()
  {
    if (eClassifiers == null)
    {
      eClassifiers =
        new EObjectContainmentWithInverseEList.Resolving<EClassifier>
          (EClassifier.class, this, EcorePackage.EPACKAGE__ECLASSIFIERS, EcorePackage.ECLASSIFIER__EPACKAGE)
        {
          private static final long serialVersionUID = 1L;

          @Override
          protected void didChange()
          {
            eNameToEClassifierMap = null;
          }
        };
    }
    return eClassifiers;
  }
#+END_SRC

It's this newEObjectContainment thingy.

Oh wait, it's returning a /list/ and the EStore.get should return a lone
element.  Yes, that works.

Now I think I really need to update the tests to use the reflective API.... but
it's really verbose.  Or there is another way: I could just write an utility
method that would test if a Viewpoint matches an expected format.  We would just
descend on the TreeIterator given by Viewpoint.getAllContents, without having to
lookup features/classifiers by name.

** Adapting the tests                                              :emfviews:
Oh hey, Viewpoint.getAllContents() returns an empty array.

* [2017-07-20 jeu.]
** Adapting the tests                                              :emfviews:
Update on yesterday: Viewpoint.getAllContents() returns what I need.  But I
don't know what's the best way to test it.

It's a tree iterator.  I could check it against a simple Iterator, but that
would be checking against an infix walk of the contents, so you lose some
information.

Also, there's the matter of /how/ to describe the expected structure.  Using
only names is too restrictive.  It seems I need to be able to check, for each
level, the value of some feature.  So I need a tree of "feature: value".

I wish I was in Lisp... making and iterating over a tree would be trivial.

Using the reflective API is verbose, even with shortcuts.  Before I wrote this:

#+BEGIN_SRC java
EClass A = (EClass) ((EPackage) l.get(0)).getEClassifier("A");
assertEquals(0, A.getEStructuralFeatures().size());

EClass B = (EClass) ((EPackage) l.get(1)).getEClassifier("B");
assertNotNull(B.getEStructuralFeature("b"));
#+END_SRC

Now I have to write this:

#+BEGIN_SRC java
EObject A = (EObject) ecall(l.get(0), EcorePackage.EPACKAGE___GET_ECLASSIFIER__STRING, "A");
assertEquals(0, ((List) eget(A, "eStructuralFeatures")).size());

EObject B = (EObject) ecall(l.get(1), EcorePackage.EPACKAGE___GET_ECLASSIFIER__STRING, "B");
assertNotNull(ecall(B, EcorePackage.ECLASS___GET_ESTRUCTURAL_FEATURE__STRING, "b"));
#+END_SRC

When all I really want to do is to test the resource against an expected result
of:

#+BEGIN_EXAMPLE
- minimalA
  - A
- minimalB
  - B
    - b
#+END_EXAMPLE

* [2017-07-21 ven.]
** Adapting the tests for the reflective API on Viewpoint          :emfviews:
I went with a few helper methods to reduce the boilerplate, and now the tests
use the reflective API /and/ are more readable.

The "check an expected structure" seemed to cumbersome.

Here is yesterday's example:

#+BEGIN_SRC java
EObject A = getClassifier(l.get(0), "A");
assertEquals(0, getFeatures(A).size());

EObject B = getClassifier(l.get(1), "B");
assertNotNull(getFeature(B, "b"));
#+END_SRC

It made other places much neater:

#+BEGIN_SRC diff
-    @SuppressWarnings("unchecked")
-    EList<EObject> ea_labels =
-        (EList<EObject>) ea.eGet(ea.eClass().getEStructuralFeature("labels"));
-    @SuppressWarnings("unchecked")
-    EList<EObject> vea_labels =
-        (EList<EObject>) vea.eGet(vea.eClass().getEStructuralFeature("labels"));
+    EList<EObject> ea_labels = eList(ea, "labels");
+    EList<EObject> vea_labels = eList(vea, "labels");
#+END_SRC

Looking at the whole diff, all changes are as long or shorter than the previous
code.  Crucially, we don't have way fewer casts.  So I guess it's a win.

Now, does it help with the EStore backing for Viewpoint?

** Using EStore implementations for Viewpoint contents             :emfviews:
So the tests do not magically all pass using this reflective API, unfortunately.

Most of them fail trying to cast Boolean to EObject... That's weird.

: getClassifier(l.get(0), "A")

Okay, so that's because getClassifier calls o.eInvoke on an operation that we
got from o.eClass.  On regular EMF classes, that works, but on our virtual
element, the eInvoke call never goes back to our EStore implementation and
returns ~eIsProxy~ in EObjectImpl instead.

Does that mean that eInvoke does not work on EViews?  If so, that would probably
be a nail in the coffin for this approach.

Hmm, there are no operations on EViews.. for objects of the minimalref model.
Maybe it's because there is no generated code for this metamodel?

What about TOGAF?  Still empty.  eClass() always seems to be an EClassImpl, so
eOperations is a feature, but it's empty.

Hmm, I was under the impression that some operations were generated for
getter/setters of attribute, but it seems it's not the case.  Operations are a
separate type of element in the metamodel.  So the Ecore metamodel has
operations, but TOGAF doesn't seem to have any.

Okay, so the question remains: does eInvoke works for ReproduceElements created
by EView?  I could load Ecore as a model and try it out...

The nsURI is: http://www.eclipse.org/emf/2002/Ecore

Hmm, that's interesting.  No errors when creating the EView, but the contents
are empty.

As far as I can tell, in View.loadContributingModels, we do
virtualResourceSet.getResource() and as a side-effect the resources attributes
of virtualResourceSet contains the contributing models resources.

However, when given a model as HTTP, it /finds/ something and returns an
EResourceFactory (instead of, say, an XMIResourceImpl), but the resources
attributes remains empty.

Since this resources attribute is used to build the contents of the View, the
contents will be empty.

Getting the returned value and explicitly adding the resource to the
virtualResourceSet seems to fix it.

Finally: I do get a ReproduceElement around an EPackage.  Calling
eClass().getEOperations on this reproduceElem gives me...

: [org.eclipse.emf.ecore.impl.EOperationImpl@56c0a61e (name: getEClassifier) (ordered: true, unique: true, lowerBound: 0, upperBound: 1)]

But, using my getClassifier helper gives me the same Boolean to EObject class
cast exception.

So: it doesn't work on the EView ReproduceElement either.

I should write a self-contained test with an EStoreEObject backed by an EStore
and try an eInvoke on it.  But my guess is that it doesn't work out of the box,
and I don't know yet if there is a way to make it work.

* [2017-07-24 lun.]
** Finding out if EStore supports eInvoke or not               :emfviews:emf:
If it doesn't, I'll have to check DynamicEObject, or write our own EObject
implementation.

Writing simply:

#+BEGIN_EXAMPLE java
    EStoreEObjectImpl o = new EStoreEObjectImpl();
    o.eInvoke(EcorePackage.Literals.EPACKAGE___GET_ECLASSIFIER__STRING,
              ECollections.asEList("Foo"));
#+END_EXAMPLE

(I found a new way to get the EOperation)

Violates an assertion in BasicEObjectImpl: "The operation 'getEClassifier' is
not a valid operation".

Setting the class:

#+BEGIN_EXAMPLE java
    EStoreEObjectImpl o = new EStoreEObjectImpl();
    o.eSetClass(EcoreFactory.eINSTANCE.createEPackage().eClass());
    o.eInvoke(EcorePackage.Literals.EPACKAGE___GET_ECLASSIFIER__STRING,
              ECollections.asEList("Foo"));
#+END_EXAMPLE

returns ~false~.  A boolean.  Probably eIsProxy again.

After debugging, yes, we end up in EStoreEObjectImpl.eInvoke with the
operationID of 1, and it happens to be the ID of ~EOBJECT___EIS_PROXY~, so we
call that method and return false.

Am I using this wrong?  It looks like using eInvoke on EStoreEObject is used to
call /EObject operations/.  And I want it to /delegate/ eInvoke on a backing
object.  But EStoreEObject has no notion of a backing object.

It /does/, however, delegate attributes get and set to the backing store.

Using eGet on the EStoreEObject ends up calling dynamicGet(featureID), which
delegates to eStore().get().

Hmm.  But we could extend EStoreEObjectImpl to delegate eInvoke to the backing
store... but we would have to extend the store interface as well.  And,
ultimately, it seems that extending EStoreEObject is not the proper solution: an
EStoreEObject /delegates/ to a an EStore, but a VirtualElement aims to be
/transparent/.

Is DynamicEObject a better fit?

** Exploring DynamicEObject                                    :emfviews:emf:
Doing:

#+BEGIN_SRC java
DynamicEObjectImpl o = new DynamicEObjectImpl();
o.eSetClass(EcoreFactory.eINSTANCE.createEPackage().eClass());
o.eInvoke(EcorePackage.Literals.EPACKAGE___GET_ECLASSIFIER__STRING,
          ECollections.asEList("Foo"));
#+END_SRC

throws UnsupportedOperationEx "eInvoke not implemented for getEClassifier"

Promising!  We end up in BasicInvocationDelegate.dynamicInvoke, which will only
invoke the given operations if it is an EObject operation:

#+BEGIN_SRC java
 if (eOperation.getEContainingClass() == EcorePackage.Literals.EOBJECT)
 {
   switch (eOperation.getEContainingClass().getEAllOperations().indexOf(eOperation))
   {
     case EcorePackage.EOBJECT___ECLASS:
       return target.eClass();
     case EcorePackage.EOBJECT___EIS_PROXY:
       return target.eIsProxy();
 ...
#+END_SRC

Otherwise, it throws.

So it looks like we need to define an InvocationDelegate that does something
else.

An invocation delegate is a property /of an operation/.  It's a class that tells
the operation how it should execute itself given the arguments.  So we go from:

: obj.eInvoke(operation, args)

to:

#+BEGIN_EXAMPLE
eInvocationDelegate(operation).dynamicInvoke(obj, args)
BasicInvocationDelegate.dynamicInvoke(obj, args)
switch (operation id)
  ECLASS => obj.eClass()
  ECONTAINER => obj.eContainer()
  ...
#+END_EXAMPLE

It's a bit convoluted.

Invocation delegates are created through annotations... or we can set them
directly on the operation.

But I don't want to set them per operation.  I just want to delegate the eInvoke
call to a concrete object, which will know how to handle it.

So it looks like we'll have to build our own EObject implementation.  However,
DynamicEObject can serve as a reference of what is actually useful in there.
There is very little actual logic in that class, so it should serve as a guide.

I think we could have a DelegatingEObject class that just delegates to a
concrete element.  Then we could extend this Delegating class as VirtualEObject
which adds additional control related to views (potentially filtered, etc.).

* [2017-07-25 mar.]
** Using a DelegateEObject for virtualizing Viewpoint              :emfviews:
Have to make some adjustments.

We used a ResourceSet to hold the cloned and modified packages, and got them
back through registry.getEPackage.  However, getEPackage returns null when the
objects we put there are not instances of EPackage.

When using a DelegateEObject instead of cloning the EPackages, this cannot
work.  Instead, a simple Map from the package URI to the package object
(actually, a delegate) works.

Now, most of the tests pass; there is the issue that applyFilters just deletes
stuff from the original packages through the delegate.  We can't do that
anymore.

Instead, we should /hide/ elements.  Having a VirtualEObject class that extends
DelegateEObject and has a ~filtered~ field would work.  However, at the moment
we use DelegateEObject only at the package level, but we should make sure that
every object inside this delegated package is also delegated.

One way would be to iterate on the contents of each EPackage at first, and wrap
them in DelegateEObject.  Another would be to do it lazily at runtime, using
membranes.

Let's try to do it at construction time.

Hmm, I need the original structure of the package to guide me.  What if cloned
the packages, but then replaced every object inside by a delegate to itself?

ArrayStoreException

Argh, seems I can't just store anything I want here.  Okay, fine, let's go with
the membrane approach then.

First hole to plug is eContents: this gives access to non-Delegate object, and
we should change that.

Defining a MembraneEObject (for lack of a better name), that constructs a
MembraneEList and wraps objects in the get(index) method.

Objects are saved in a Map to avoid creating duplicate wrappers (and to help
preserve reference equalify).

Problem: calling EcoreUtil.delete on a MembraneEObject doesn't work, because
they are casted as InternalEObject.

Well, good thing we don't need actually want to delete these objects then.  But
wait, filters don't work, that I understand, but creating new elements should
work.

Hmm, that's because we are casting to EClass in order to be able to access and
modify getESuperTypes.  Can't we use the reflective API?

: ((EList<EClass>) sub.eGet(EcorePackage.Literals.ECLASS__ESUPER_TYPES)).add(klass);

It's not pretty, but we can.

Hmm, wait.  The addSubConcept is more interesting.

#+BEGIN_SRC java
EObject sup = findEObject(e, registry);
if (!(sup instanceof EClass))
  throw EX("Superconcept '%s' of new concept '%s' should be an EClass", e, c.getName());
klass.getESuperTypes().add((EClass) sup);
#+END_SRC

If sup is a MembraneObject, then we can't cast it to EClass obviously.  We could
use his delegate object... but should we?

It seems we have to, because we can't add anything other than an EClass a super
type.  MembraneEObject does not implements EClass, and if we start duplicating
Membranes to include MembraneEClass, MembreEReference, etc., then we are not
sharing code with the View level anymore.

What happens if we use the delegate?  It means we mix virtual classes and
original classes.  And it adds a way to get to original classes from synthetic
elements in the virtual package.

Hmm I think I see a solution:

     delegates to
 D_1 ------------> C_1
                   ^
                   |
 D_2 ------------> C_2

C_1 is the original concept, C_2 is a new subconcept.  Since we deal with
delegates, we can't subclass D_1 with C_2 directly.  However, we can subclass C_1
with C_2, and then expose a delegate D_2 to C_2.

That also solves the question of whether to expose synthetic elements directly
or through delegates.

* [2017-07-26 mer.]
** On yesterday's solution to the subconcept problem               :emfviews:
There's one downside: if the inheritance link is added to the concrete elements,
then we are modifying the existing model, rather than modifying the view.

The alternative is then to create the inheritance link between the delegates:

     delegates to
 D_1 ------------> C_1
 ^
 |
 D_2 ------------> C_2

But then, the delegates need to hold extra information.  Basically, we need to
have a VirtualClass object that implements EClass.

Trying the VirtualClass/VirtualProperty approach.  First VirtualProperty:

#+BEGIN_SRC java
public class VirtualEAttribute implements EAttribute {

  protected VirtualProperty virtualProperty;
  protected EAttribute backing;
#+END_SRC

It implements EAttribute to be transparent for EMF.  But it holds the
VirtualProperty instance it is supposed to represent.  The backing EAttribute is
used to hold all the relevant EAttribute fields, rather than duplicating them.

But now, this object cannot be cast to InternalEObject when doing:

: parentClass.getEStructuralFeatures().add(attr);

Well, we don't want to do that anymore anyway.  The VirtualEAttribute already
has a parent that is held by its VirtualProperty.  The more interesting question
is what happens when we interrogate our VirtualEAttribute?

We fail at:

#+BEGIN_SRC java
   EObject f = getFeature(A, "newProperty");
   assertNotNull(f);
#+END_SRC

~f~ is null, because we can't find the feature on A.  So in order to make this
work, we have to implement VirtualEClass as well, and create these.

Similar problem with VirtualEClass:

: virtualPackage.getEClassifiers().add(klass);

Cannot cast to InternalEObject.  Seems EMF doesn't want us to mix our homebrewed
virtual EObjects with regular EPackage.

Have to implement VirtualEPackage then.

Or maybe we can work around this restriction, since the only thing that we do
with our new concepts is to expose them in our VirtualContents.  If instead of
providing a package, we provide a list EClass, it could work.

* [2017-08-01 mar.]
** Picking up on VirtualEClass                                     :emfviews:
VirtualEClass.getName() does return the name of the backing virtual concept or
EClass, but toString doesn't.

Oh, that's why.  Here is ENamedElementImpl:

#+BEGIN_SRC java
public String toString() {
  if (eIsProxy()) return super.toString();

  StringBuffer result = new StringBuffer(super.toString());
  result.append(" (name: ");
  result.append(name);
  result.append(')');
  return result.toString();
}
#+END_SRC

It uses the name attribute directly, instead of using the getter.  If we want
toString to be transparent, we have to change the attribute as well then.

But that's again an issue: are there other such attributes that are used
internally without going through the accessors?

I'm dreading what happens on equals...

Hmm, okay, looks like we end up in Object.equals, which uses reference
equality.  I was wondering whether Object.equals was an equivalence, and the
documentation says it is.  Good.

Now, do we need to implement equals on VirtualEClass?

Hmm, even if we did, it wouldn't be symmetric:

: x.equals(y)

would work when X is a VirtualEClass, but not when X is an EClass and Y is
virtual, because X would juste reference equality.

So I guess this is a nail in the coffin of the "completely transparent"
objective.  Hmm.  We could always tell a virtual EClass from its backing class
using object reference directly though.  So I guess what's still missing is a
definition of what "transparent" means here.

In any case, maybe the tests are the one that need to change here.

Hmm, actually, the issue here is that we test:

: assertEquals(getClassifier(l.get(0), "A"), sups.get(0));

In words: the super type "A" of our new virtual concept "C" should be equal to
the class "A" we obtain from the first contributing package in the viewpoint.

Given the equals implementation on EClass, equality here means that they should
be /the same object/.

I think the test is correct in expecting both to be the same objects.  It's
related to issue #1: What happens to classes of a contributing package that are
not referenced.

But here the case is pretty clear I think: the virtual C references the concrete
A, so we must lift A into the virtual world.  That the test fail is a leak in our
virtual world abstraction.

So, that means that the virtual contents should lift everything it contains.
How do we do that?  That's issue #5: how to make sure that the virtual contents
are always virtual objects?

To start with, I'll wrap all the EClass of the contributing packages into a
VirtualEClass.

Now all the addConcept tests pass.  But surely, it does not stop here as we only
delegate the /name/ of the EClass in our VirtualEClass, and nothing else.

* [2017-08-02 mer.]
** New plan for the virtual metamodel                              :emfviews:
First, try to see if we can trick EMF into taking VirtualEClass by implementing
InternalEObject.  Maybe it's feasible, maybe it's a hassle.  Maybe we have to
add so many attributes that are too similar to the reference EClassImpl
implementation that it makes little sense.

The main benefit of implementing InternalEObject would be to be lightweight by
having less attributes than an EClass.  If we end up with too many attributes,
then it's probably not worth it.

** Different ways of handling filters                              :emfviews:
There are two ways of using the filters in the weaving model.

First, we can use them statically, at the creation of the virtual metamodel: we
create only the VirtualEClass that are not filtered.  This is equivalent with
what we have now.

Or, we use the filters dynamically.  VirtualEClass (or rather, VirtualEObject)
has a list of filters to apply, and whenever we ask for the contents of
VirtualEClass, we only return the ones that are non-filtered.

Again, there are two ways of doing that.

We could populate the VirtualEClass, at creation time, with proxies for all its
potential contents.  When asked for its contents, it will just return those that
are not filtered out.

Or, we could be fully lazy, and just keep a list of created proxies so far.
Whenever we get asked for the contents, we populate a list with the proxies of
unfiltered classifiers, and if a proxy does not exist, we create it on the fly.

* [2017-08-03 jeu.]
** Trying out implementing InternalEObject                         :emfviews:
Doesn't seem to make much sense.  Right now it's asking me for:

: public NotificationChain eInverseAdd(InternalEObject otherEnd, int featureID, Class<?> baseClass,
                                       NotificationChain notifications) {

To be implemented.  But, first it really looks like it deals with internal
matters of EMF, so it might be a very bad idea.  Second, I actually have no clue
on how to implement that.

However, maybe we can inherit from BasicEObjectImpl instead of EClass, and
implement EClass on top of that.

** Extending BasicEObjectImpl                                      :emfviews:
Haha.  I get an UnsupportedOpEx, not in my VirtualEClass, but in
BasicEObjectImpl itself:

#+BEGIN_SRC java
protected EPropertiesHolder eBasicProperties()
{
  throw new UnsupportedOperationException();
  // return eProperties;
}
#+END_SRC

Even though BasicEObjectImpl is not abstract, it's not a class you can use
without overriding methods.  Trying this:

#+BEGIN_SRC java
EPropertiesHolder eProperties;

@Override
protected EPropertiesHolder eProperties() {
  if (eProperties == null) {
    eProperties = new EPropertiesHolderImpl();
  }
  return eProperties;
}

@Override
protected EPropertiesHolder eBasicProperties() {
  return eProperties;
}
#+END_SRC

Doesn't work, because the EPropertiesHolderImpl constructor is not visible, even
though the class is protected.

Hmm.  Protected should be available to subclasses, but for some reason it
doesn't work here.  Maybe the /constructor/, being implicit, has the default
visibility.

Hmm, doing:

#+BEGIN_SRC java
public class TestVisibility {
  protected static class A {
    protected A() {}
  }
}
#+END_SRC

and:

#+BEGIN_SRC java
public class Foo extends TestVisibility {
  public void foo() {
    A a = new A();
  }
}
#+END_SRC

in another package, still doesn't work.  Changing the constructor A to public is
the only way to make it accessible.

Is it that way for non-inner classes as well?

#+BEGIN_SRC java
public class TestVisibility {
  protected TestVisibility() {}
}
#+END_SRC

#+BEGIN_SRC java
public class Foo extends TestVisibility {
  public Foo() {
    super();
  }
  public static void main() {
    TestVisibility t = new TestVisibility();
  }
}

#+END_SRC

Here, the explicit call to ~new TestVisibility()~ is failing because the
constructor is not visible.  But the call to ~super~ is okay, even though we use
the same constructor: because the constructor is available to subclasses.

If however we remove the ~protected~ on the TestVisibility constructor, then the
~super~ call is illegal.

Okay, coherent.

Now, for the inner class, ~protected~ makes the constructor only available to
subclasses of /that inner class/, and not to subclasses of its parent class.

And since I don't see any constructor, I'm guessing a ~protected~ inner class
has a default constructor with ~protected~ visibility.

One trick would then be to extend the inner class, just to be able to
instantiate it:

#+BEGIN_SRC java
public class Foo extends TestVisibility {
  protected static class MyA extends A {}
  public void foo() {
    A a = new MyA();
  }
#+END_SRC

And this works.  It's a tad stupid looking, because it's just saying: "ok,
please let me construct this class", and usually the visibility is controlled by
the class that defines it, not the class that uses it.  Meh.

Found two relevant SO threads:
- https://stackoverflow.com/q/11605388
- https://stackoverflow.com/a/17610709

In both, the accepted answer is to make the inner class constructor public.  But
what if it's not code you can modify?  In the second link, someone suggests to
extend the class like I did here.

Let's try that on BasicEObject then.  Yes, I can construct MyEPropertiesHolder.

Now it doesn't work yet because... I need to implement getStaticClass().

Okay, done.

Now, another method that is unsupported but not abstract:

#+BEGIN_SRC java
public InternalEObject eInternalContainer()
{
  throw new UnsupportedOperationException();
  //return eContainer;
}

public int eContainerFeatureID()
{
  throw new UnsupportedOperationException();
  // return eContainerFeatureID;
}
#+END_SRC

I do notice that at some point it was implemented, maybe?

At this point, it might make more sense to directly extend EObjectImpl, since
I'm lifting code from it anyway.

** Extending EObjectImpl                                           :emfviews:
Oh, wow.  The addConcept test passes, all the other stack overflow.

For the first test addProperty, I've isolated the stack overflow to
buildNewProperties.findEObject.  Then in EMFViews.findElement.

Then in this:

: return dynamicFeatureID < 0 ?
      eGet(eFeature, resolve) /* backward compatibility with old generated overrides */

And that's where we loop, because that ~eGet~ will call the ~eGet~ on the same
BasicEObjectImpl.

So it looks like we have to override eGet to get out of this loop.

Or, that comment seems to indicate that maybe we shouldn't go through this
branch.

Hmm, implementing eGet is not enough, as it looks like we need eIsSet as well.
And probably eSet and eUnset.  Crapshoot.

Or maybe we shouldn't pass as /the/ EClass class in eStaticClass.

Trying to override eStaticFeature count to 0 so always go through the dynamicGet
method... we then go through eSettings[featureID] instead, but this array is
full of nulls.

When is it populated?  Looks like neither BasicEObject or EObject populates it,
so... no wonder it's empty.

Out of curiosity, extending MinimalEObjectImpl instead of EObjectImpl makes no
difference.  From the docstring, the Minimal variant is "space-compact", but it
doesn't say if its inner workings are different.

Let's try the eGet route one more time.

Copying the eGet/eIsSet methods of EClassImpl.  Get a bunch of errors because
these sometimes refer to attributes that exist in EClassImpl, not merely
accessors.

Replacing with UnspportedOpEx, we end up in:

#+BEGIN_SRC java
  public boolean eIsSet(int featureID) {
    switch (featureID) {
    case EcorePackage.ECLASS__EANNOTATIONS:
#+END_SRC

Replacing with ~return false~ then (let's say VirtualEClass does not support
Annotations currently).

Same for ~ETYPE_PARAMETERS~.  EOPERATIONS.  ~ESTRUCTURAL_FEATURES~.
~EGENERIC_SUPER_TYPES~.

Then, overriding getESuperTypes like this:

#+BEGIN_SRC java
@Override
public EList<EClass> getESuperTypes() {
  if (virtualConcept != null) {
    List<EClass> l = new ArrayList<>();
    for (Concept c : virtualConcept.getSuperConcepts()) {
      l.add((EClass) viewpoint.findEObject(c));
    }
    return ECollections.asEList(l);
  } else {
    return eClass.getESuperTypes();
  }
}
#+END_SRC

makes the addSubConcept test pass.

However, the addSuperConcept has a worrying ClassCastException.  We'll see
tomorrow.

* [2017-08-04 ven.]
** ESuperAdapter class cast exception                              :emfviews:
Okay, so EClassImpl actually implements ESuperAdapter.Holder in addition to
EClass.

That's getting tiring.  There's only two methods in there, but it's still yet
other code that has no bearing on VirtualEClass.

I feel I've exhausted this path at this point.

I'll go back to extending EClassImpl.

But before that, I want to check whether it's possible to use the reflective API
of EMF in Viewpoint.

** Using the reflective API in Viewpoint                           :emfviews:
Since I rewrote the tests using the reflective API to avoid casting, there might
also be a way to rewrite the code in Viewpoint the same way.

And then, maybe we don't even have to extend EClass, but just use EStore, maybe?

I think I just need to test whether you can add an EObject as super type through
the reflective API to start with.

When trying this:

#+BEGIN_SRC java
EObject C = EcoreFactory.eINSTANCE.createEObject();
EList<EObject> sups = (EList<EObject>) A.eGet(EcorePackage.Literals.ECLASS__ESUPER_TYPES);
sups.add(C);
#+END_SRC

: ArrayStoreException

That's because the feature ESuperTypes is typed to contain only EClass, and even
though the reflective API allows you to send any EObject, there is still a
runtime check for the type.  In DelegatingEcoreList.validate:

#+BEGIN_SRC java
if (object != null && !isInstance(object))
{
  throw new ArrayStoreException();
}
#+END_SRC

And isInstance ends up doing:

: getEStructuralFeature().getEType().isInstance(object);

So, no dice.

Back to extending EClass then.

** Extending EClassImpl                                            :emfviews:
VirtualEPackage, VirtualEClass, VirtualEAttribute, ...

If I turn of the Ecore validation, all tests pass except the
filterBidirectionalReference.

We can still access the parentA feature through eOpposite.  I'm guessing now
that we partly copy stuff and partly proxy them, we have some dangling links.

For instance here, I have parentA that's a feature in the ProxyEClass for B, but
its eOpposite field is the manyB feature in the concrete class A.

So we have mixed concrete and virtual elements.

** Summary of the different solutions to make the metamodel virtual :emfviews:
Note that we are really talking about the /metamodel/ level here, and not the
model level.  The model level is already virtual with ReproduceElement and other
elements, so for instance updates on the contributing models are propagated to
the view without any difficulty.

So, we wanted to make the metamodel (Viewpoint) virtual in the same way.

*** Previous behavior: cloning everything
Previously, for the metamodel level was simply cloned each of the contributing
metamodels into a "virtual" resource set.

After that, we could simply delete the cloned elements (classes/features) that
were filtered out.  Then add any virtual elements
(concepts/properties/associations) to these cloned and filtered packages.

What are the downsides with the cloning approach?  Mainly, that it's not
virtual, so we lose the ability to react to changes to the contributing
metamodels.  Also, it's static: the contributing metamodels are cloned at the
construction of the Viewpoint, so we cannot adapt to change in the weaving model
either.  There is a slight memory hit as well, as ideally the metamodel level
would contain only lightweight proxies to the contributing elements of the
metamodel, and not full EPackage/EClass/EAttribute instances.  Finally, it would
have been neater to have some symmetry between the metamodel level and the model
level, as it was announced in the EMFViews paper.

So, now what are our options for making the metamodel level virtual?

*** Using EStore
The first one is using EStore, as this is what is used at the model level.  At
the model level, our proxies are EStoreEObjectImpl objects, that use singleton
EStore instances (e.g., ReproduceRule) to capture eGet/eSet calls.

Why can't we use EStore at the metamodel level?  In the viewpoint, we can add
new properties or new concepts.  To add a property, we create an EAttribute and
we add it to a parent concept using:

: concept.getEStructuralFeatures().add(attr)

But in order for that to work, ~concept~ must be an ~EClass~, and ~attr~ must be
an EStructuralFeature.  An EStoreEObject is neither of those.

Can't we subclass EStoreEObject and implement EClass?  Well, first of all,
implementing EClass is far from trivial.  There are many methods, and it's not
all clear how we would define them, apart from lifting code from EClassImpl.
But more importantly, EClassImpl implements two additional, /internal/
interfaces InternalEObject and ESuperAdapter.Holder.  If we don't implement
these, our EStoreEObject won't be able to pass off as a regular EClass and we'll
get a ClassCastException.  Again, implementing InternalEObject and
ESuperAdapter.Holder could be done in theory, but in practice I have no idea
what to put in these methods that is not already defined by EClassImpl itself.

So, it seems the only practical solution is to reuse an implementation like
EClassImpl and to override the right methods.

However, we could also reuse a more generic implementation, like
BasicEObjectImpl and work from there.

*** Extending BasicEObjectImpl
BasicEObjectImpl is nearly at the top of the hierarchy of Ecore.  We could
create:

: VirtualEObject extends BasicEObjectImpl

Then:

: VirtualEClass extends VirtualEObject implements EClass

This way we would be able to pass off as a proper EObject with internal
interfaces, satisying EMF, but we would still neatly implement only interfaces,
in order to have less coupling with EMF in the subclasses of VirtualEObject.

Why doesn't this work?  Because BasicEObjectImlp, as the name might have
implied, is not complete: it has methods that throw UnsupporteOperationEx.  Even
though the class is not abstract, you cannot use instances of it without
overriding some methods like eProperties, eBasicProperties, eContainer,
eInternalContainer...

We can go down in the hierarchy and try EObjectImpl.

*** Extending EObjectImpl
EObjectImpl basically overrides the methods that BasicEObjectImpl left throwing
UnsupportedOperationEx, and not much else.

Why doesn't this work?  Because EClassImpl has an additional internal interface,
ESuperAdapter.Holder, so we face the same issue as with InternalEObject.  A
VirtualEClass, being an EObjectImpl, cannot be cast as yet another internal
interface.  Though, ESuperAdapter.Holder contains only two methods, but one of
them is to return a new ESuperAdapter, and again I have no idea how to create
one other than lifting the code from EClassImpl.

So, again, we end up with extending EClassImpl as being the only practical
solution for a VirtualEClass.

*** Foreseen challenges in extending EClassImpl
So, let's see where are at: we wanted lightweight proxies by avoiding the
creation of a full EObject/EClass/EAttribute as that was the case in the cloning
approach.  But now, we are proposing to have VirtualEClass, VirtualEAttribute,
etc., and each one would /be/ an instance of EClass or EAttribute.  So we
wouldn't be any more lightweight in this case.

Also, the step after the virtualization of the metamodel is to use the same
architecture for the model level, unifying the two.  For that, a VirtualEObject
seems indicated.  If we had VirtualEClass as a subclass of VirtualEObject, then
the whole thing would have make much sense.  But we can't have that if
VirtualEClass is already a subclass of EClassImpl.  That's a bummer.

However, we would be able to be more dynamic, so it's still a gain in this
respect.

The main challenges of this approach is that, while cloning was rather
straightforward, now we have proxies to the elements of the contributing
metamodels, and we have to make sure the assembled virtual metamodel is
coherent, with respect to the many pointers between bidirectional references,
containers, and the like.

It's also somewhat harder to be sure that we don't modify the contributing
metamodels.  In the cloning case, well we had full clones, so we trust EMF to do
the right thing.  But here, our proxies have to use the data from the underlying
metamodel elements, without giving direct access to them or accidentally
modifying them.

*** An unexplored solution with EStore
Writing this, I realize there's a trail I have left unexplored.

I've said that EStore was insufficient, because we couldn't cast an
EStoreEObject to an EClass.  But that restriction stems from the fact that we
are /populating/ the virtual metamodel with actual instances of
EClass/EAttribute etc.

It seems to me that, at least in theory, we could make the virtual layer lazy,
and "just" intercept interesting features through eGet/eSet in EStore, in order
to make the relationships described by the weaving model "appear" real to the
callers, even though the instances would be short-lived.

Or, we can memoize the instances.  Shouldn't make much of a difference.

* [2017-08-21 lun.]
** Exploring the alternative EStore solution                       :emfviews:
As a way to refresh my mind on how this all works.

I think using EStore for proxifying contributing classes should work fine.  At
least at the top level, for exposing packages.  But then, I guess it's not
sufficient if we want to make sure that the contents of this virtual package are
also virtual objects.

Let's see.

Trying to use ReproduceElementImpl directly as my EStore backing to see how if
it can be used directly on Viewpoint as-is.  Looks like no, because
ReproduceRule will cast the resource of the element to a View in order to get
the MetamodelManager and access to translateToVirtualElement.

Let's try to implement EStore ourselves.

Implementing EStore.get like this:

#+BEGIN_SRC java
public Object get(InternalEObject object, EStructuralFeature feature, int index) {
  Object value = concreteElement.eGet(feature);
  if (index != NO_INDEX) {
    List<Object> list = (List<Object>) value;
    return list.get(index);
  } else {
    return value;
  }
}
#+END_SRC

is enough to fool eGet(o, "name").  But then I run into [[*Using%20EStore%20implementations%20for%20Viewpoint%20contents][the same issue I had
with getClassifier]], namely that calling eInvoke on EStoreEObject does not
delegate to the EStore, like eGet does.

Okay, getClassifiers() works because it returns the eClassifiers /feature/, so
that is delegated to the EStore.  But getClassifier(String) actually looks up
the classifier by name using the getEClassifier(String) operation on the
EPackage class, through eInvoke.  The latter is not delegated to the EStore and
thus calls the wrong method.

Well, if we reimplement getClassifier(String) to not use eInvoke, we should be
good.

Yep, that's enough.

So it looks like this could work.  The major hurdle I encountered previously
wasn't really one.  I was confused, and did not think of using the reflective
API to its full extent.

The main difference with extending EClassImpl is that we are not an EClass, but
merely an EObject.  Consumers would be restricted to use the reflective API to
list classifiers etc., whereas they could just cast to
EPackage/EClass/EAttribute in the other solution.

Both solutions have the same challenges: making sure that elements returned by
our proxies are also proxified.  Although, in the EStore case, we have less
methods to worry about (many of the EStore methods are defined in
TranslationRule in terms of a core set including ~get~, ~isSet~...).

Ultimately, the EStore solution has the advantage of being much simpler /and/
would allow us to share most of the code between the model and metamodel levels.

Tomorrow: see how to add a virtual concept.

* [2017-08-22 mar.]
** Virtualizing all objects                                        :emfviews:
I'm not /sure/ it virtualizes everything, but I based the logic off
ReproduceRule, and it's a start.

The tricky bit is that EStore.get can return EObject as well as basic Java
objects (depending on the feature).  And it also can return a whole list, or an
individual element, depending on the index argument.  All these cases are munged
together in this method.

And when we return a list, we have to make sure that accessing an element from
it doesn't leak a non-virtual object.

Adding a virtual concept works the same, for the time being, since virtual
concepts are put into a new virtual package (that is actually not virtual at
all, it's just an EPackage instance).

Adding a property, as well as filtering, modifies the original metamodel.  The
reason for that is that's we actually do in Viewpoint right now: we create a new
EAttribute and add it to the /original/ classes.  Then in getContents we return
a proxy to this class, but it's already modified.

What we should do instead is, when we list the features of A, we answer with a
list made of its concrete features /plus/ its virtual features.  We can
intercept that in EStore.get.

Yep, that works.  And this may hint at a specifity of the metamodel
virtualization: we have to add specific logic for features of EcorePackage if we
want to disguise our virtual objects as EPackage, EClass, and so on.  Whereas,
at the model layer, we don't need this special handling code.

In fact, it might make more sense to have this logic be in separate class.
Singletons, since we only need one instance of each type
(EPackage/EClass/EAttribute) to redefine the EStore methods.

Tomorrow: assocations and filtering.

* [2017-08-23 mer.]
** That Eclipse bug about the disappearing cursor                   :eclipse:
is really irritating.

I can reproduce reliably: hover on a warning, click on quickfix: invisible
caret.  I can still type and text will appear where the caret was, but not all
bindings work (like undo).

Moving the mouse to the window title bar restores the caret.

Tried in Unity: caret doesn't disappear.

Tried with compiling latest i3 (4.13): caret disappears.

Tried to get a log of i3, but didn't see anything.  Here is a timeline of events
that seem relevant:

#+BEGIN_EXAMPLE
23/08/2017 13:15:16 - focused now = 0xea2110 / foo.java - Eclipse Platform
...
23/08/2017 13:15:16 - x.c:x_push_changes:1116 - Updating focus (focused: 0xea2110 / foo.java - Eclipse Platform ) to X11 window 0x01c000ce
23/08/2017 13:15:16 - ipc.c:ipc_send_window_event:1279 - Issue IPC window focus event (con = 0xea2110, window = 0x01c000ce)
...
23/08/2017 13:15:18 - ClientMessage for window 0x01c0497f
23/08/2017 13:15:18 - handlers.c:handle_client_message:656 - Unknown atom in clientmessage of type 367
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 33, xkb_base 85
23/08/2017 13:15:19 - ClientMessage for window 0x01c0565d
23/08/2017 13:15:19 - handlers.c:handle_client_message:656 - Unknown atom in clientmessage of type 367
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 18, xkb_base 85
23/08/2017 13:15:19 - handlers.c:handle_unmap_notify_event:446 - UnmapNotify for 0x01c0497f (received from 0x000000fb), serial 3997
23/08/2017 13:15:19 - Not a managed window, ignoring UnmapNotify event
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 85, xkb_base 85
23/08/2017 13:15:19 - handlers.c:handle_event:1378 - xkb event, need to handle it.
23/08/2017 13:15:19 - handlers.c:handle_event:1404 - xkb state group = 0
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 10, xkb_base 85
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 28, xkb_base 85
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 85, xkb_base 85
23/08/2017 13:15:19 - handlers.c:handle_event:1378 - xkb event, need to handle it.
23/08/2017 13:15:19 - handlers.c:handle_event:1404 - xkb state group = 0
23/08/2017 13:15:19 - handlers.c:handle_event:1369 - event type 33, xkb_base 85
23/08/2017 13:15:19 - ClientMessage for window 0x01c000ce
23/08/2017 13:15:19 - handlers.c:handle_client_message:705 - _NET_ACTIVE_WINDOW: Window 0x01c000ce should be activated
23/08/2017 13:15:19 - workspace visible? fs = 0xea1f20, ws = 0xea1f20
23/08/2017 13:15:19 - handlers.c:handle_client_message:744 - Focusing con = 0xea2110
23/08/2017 13:15:19 - workspace.c:_workspace_show:384 - Not switching, already there.
23/08/2017 13:15:19 - con.c:con_focus:199 - con_focus = 0xea2110
23/08/2017 13:15:19 - con.c:con_focus:199 - con_focus = 0xea1f20
23/08/2017 13:15:19 - con.c:con_focus:199 - con_focus = 0xea1d50
23/08/2017 13:15:19 - con.c:con_focus:199 - con_focus = 0xea0ee0
23/08/2017 13:15:19 - con.c:con_focus:199 - con_focus = 0xe96270
#+END_EXAMPLE

Might try to ask on IRC when I have more time.

** Adding associations with EStore                                 :emfviews:
Memoizing the virtual objects created to ensure reference equality works is
enough to pass this test.

But now I need to do the same trick as for properties, and not modify the
original metamodels.

Interesting thing: when we create a new association, it's an EReference. It
needs an EType, and that must be an EClassifier, so we cannot wrap the argument
in a virtual object at this point.  However, we need to make sure that whenever
someone asks for eType on this EReference, it returns a VirtualEObject wrapping
the eType.

We can wrap the EReference itself for that, and VirtualEObject will take care of
mapping to the corresponding virtual object when asked for the eType.  So, in
the end we have:

1. EClass "B" containing feature 2
2. EReference "assoc" with EType 1
3. VirtualEObject wrapping 1
4. VirtualEObject wrapping 2

Asking for eType on 3 will return 2.

** Adding virtual concepts with EStore                             :emfviews:
Another interesting situation: new concepts are added to the virtual package.
New concepts are plain, unwrapped EClasses.  When we add C as a super type to A,
a contributing class, we don't touch the original A, but C will appear in the
eSuperTypes feature of the virtual object standing in for A.  However, C will be
wrapped automatically, and we will get the virtual object standing in for C, not
the C EClass.

That's a slight inconsistency.  It means we should probably wrap the synthetic
objects that are exposed in the virtual package.  We can do that when building
the virtual contents.

Other thing: virtual objects have to know about their potential (virtual) super
types.  The easiest way to do that is hold a list of them in VirtualEObject, and
populate it when building the viewpoint.  If we wanted to add a super type
dynamically, we would just add it to this list, and it would be reflected on the
next call to eSuperTypes.

Same thing with virtual features.

That leads to an interesting specialization: all virtual objects do not need
these lists of super types and features, only the virtual objects that stand in
for a virtual class do.  We can thus have a VirtualEClass class that handles
these extra concerns.

** Fixing filtering for EStore                                     :emfviews:
Tackling filters now... instead of deleting the metamodel objects from the
copied package, we should just do as is the filtered elements do not exist.  We
can add a ~filtered~ flag on VirtualEObject to keep track of filtered objects.
In VirtualEList, we just ignore filtered elements.

That makes the blacklist and whitelist tests pass, without having to modify the
Viewpoint code extensively.

Next time: the remaining failing tests are NullPointerExceptions due to the View
layer not liking our changes. Investigate.

* [2017-08-24 jeu.]
** Fixing the View layer                                           :emfviews:
NullPointerException happen in MetamodelManager.buildMaps, because
compositionClasses is empty.  The culprit is this cast:

#+BEGIN_SRC java
for (Iterator<EObject> i = viewpoint.getAllContents(); i.hasNext();) {
  EObject obj = i.next();
  if (obj instanceof EClass) {
#+END_SRC

since we now have VirtualEObject and not EClass.  I ought to rewrite this code
at some point anyway.  But right now, using the reflective API to test the
instance will do.

Argh, actually, most of the code here in there assumes we have EClass or
EStructuralFeature instances.  But now we have VirtualEObjects.  Should we only
deal with these objects using the reflective API, or should we bypass the
virtual layer and deal with the underlying concrete objects?

At some point, we /have/ to produce concrete objects.  For instance, in
ReproduceRule.getContainingFeature:

#+BEGIN_SRC java
public EStructuralFeature getContainingFeature(InternalEObject object) {
  View vModel = (View) object.eResource();
  EObject cElement = ((ReproduceElementImpl) object).getConcreteElement();
  EStructuralFeature vFeature = vModel.getMetamodelManager()
      .translateToVirtualFeature(object, cElement.eContainingFeature());

  return vFeature;
}
#+END_SRC

We have to return an EStructuralFeature, so we cannot return a VirtualEObject.
We have no choice but returning the concrete feature behind the virtual object.
But where does it go?  If it's used internally by EMF, it may cause confusion
since the virtual object will also be flying around.

Okay, maybe this is not really used.  Let's throw in this method for now and
we'll see about doing the correct thing later.

Other place where it matters, ReproduceElement.init:

#+BEGIN_SRC java
private void init(View vModel, EObject concreteElement, EClass eClass) {
  this.eProperties().setEResource(vModel);
  this.concreteElement = concreteElement;
  this.eSetClass(eClass);
#+END_SRC

Here we need to pass an EClass instance, but the metamodel has only virtual
objects.  Here we need to use the underlying concrete EClass.

It might not cause confusion if the concrete elements are used behind the
scenes, as long as the interface exposes virtual objects.

Grmbl, all this code is too tied up to the previous way of doing things.

I'll try a clean approach of rewriting EView with my own VirtualViewEObject to
see what's really needed.

Arg, still not working.  The crux of the issue seems to be that the virtual
objects at the view level need an EClass.  That EClass is used to know which
features the object possess.  When we request a virtual feature on a virtual
view object, EMF uses the EClass to compute the feature ID, then find out the
feature object, then ultimately will call EStore.get with the feature object.

So ideally, what should happen is: I request the virtual feature "assoc", it
exists on the metaclass of the virtual view object; in fact, it's a virtual
object wrapping an EReference.  Then, EMF should call EStore.get on the virtual
view object with that virtual feature object, and we could do the correct
mapping.

Instead, what happens is that EMF does not find the feature "assoc" on the
metaclass of the virtual view object, since its EClass is the /concrete/ "A"
class from the contributing metamodels, and /not/ the virtual class containing
that virtual feature.

I tried to call eGet with the virtual feature directly:

#+BEGIN_SRC java
EObject virtualFeature = getFeature(v.viewpoint.getVirtual(A.eClass()), "assoc").get();
assertEquals(B, A.eGet((EStructuralFeature) ((VirtualEObject) virtualFeature).concreteElement));
#+END_SRC

but this fails because the feature is not passed to EStore.get directly, as EMF
first finds its ID by looking up the metaclass, again.

And as far as I can tell, there is no way to fool EMF, since eClass must return
an EClass.

If we have to return an EClass, I guess we could return one that delegates to
a VirtualEObject, so we can masquerade that object.  Although it would, in the
end, be very similar to extending EClassImpl directly to implement
VirtualEObjects that represent EClasses.  Except that, maybe that way we could
preserve a hierarchy of Virtual* objects, and have an EClass be a simple bridge
to fool EMF.

* [2017-08-28 lun.]
** Using an EClass bridge between the virtual model and metamodel  :emfviews:
So, the problem is: what is the eClass of a virtual view object?  If we put the
/concrete/ eClass there, the virtual view object won't have any virtual
features, features won't be filtered, etc.  Basically, it's useless, it's the
wrong answer.

We cannot put the virtual object that corresponds to the concrete class because
setEClass requires an EClass.  And eClass is not a feature, but an operation, so
we cannot use the reflective API to fool it.

So, I tried to pass a VirtualEClass object that contains a reference to the
virtual object representing the concrete eclass.  That works, of course.  And we
can now override the getEStructuralFeature() to something like this:

#+BEGIN_SRC java
public EStructuralFeature getEStructuralFeature(String name) {
  for (EObject c : virtualClass.getFeatures()) {
    if (name.equals(eGet(c, "name"))) {
      return (EStructuralFeature)c; // <- problem: the cast fails
    }
  }
  return null;
}
#+END_SRC

But now we have another problem: we have to return an EStructralFeature here,
but the features of the virtual object are VirtualEObjects, again.  That's
basically the same issue as with eClass(EClass).

We could again, create an EStructralFeature bridge.  But now it's trickier,
because I don't know what methods in that bridge would be called.  And, more
importantly, we would then return a bridge, and that bridge would /not be the
same/ object as the virtual object representing the feature.  It was already
hard to have to deal with virtual objects and concrete objects, but if we add
bridges to the mix... it becomes chaotic.

What would be great would be to have a hierarchy under EStoreEObject:
EStoreEClass, EStoreEReference, etc.  That way we could use these objects as
EClass/EStructuralFeature where EMF expects them, but they would also delegate
all their lookups to the EStore, so we could capture all relevant methods /and/
keep a clean hierarchy.

Ultimately, that's a lot like a DelegateEObject/DelegateEClass situation... it
seems at the metamodel level we have no choice but implement EClass/EReference
in order to mesh with the existing EMF infrastructure.

* [2017-08-29 mar.]
** Summarizing the roadblocks with EStore                          :emfviews:
I've used an EStore to represent the virtual metamodel objects.  That worked
until I had to bind these virtual metaobjects to the virtual model objects.  The
virtual model objects use an EStore, so it needs an eClass, and that eClass must
be an instance of EClass.  But the metaclass of that virtual model object is
represented by an EStoreEObjectImpl; we can't pass the EClass from the
contributing metamodel that EStore object contains, since it won't contain
virtual features, and won't have any filters, etc.

To solve this eClass problem, I've tried to use a dummy EClass to use as that
eClass value, which delegates to the virtual metamodel object.  But this is not
enough, because now I would also need to add bridges for structural features,
and probably all the objects from the virtual metamodel.

Now, maybe the problem stems from the fact that we are using EStoreEObject at
the view level, which refuses to work with a virtual metaclass.  If the view
layer used the reflexive API to access its metaclass, that would work fine
(albeit slowly).  We could implement an EObject, like a DelegateEObject or
whatever, to behave as such.  But ultimately, eClass: EClass is a method on the
EObject interface, so at some point we have to give a proper EClass back to EMF.
And once that EClass is out, we must take care of preserving referential
equality.

And, since it seems we /have/ to have an EClass, we might as well use it to
represent directly the virtual metaobject, rather than putting the logic
separately in an EStore.  It's better for referential equality, and just simpler
to deal with fewer classes and objects.

** Getting the goods into master                                   :emfviews:
Commits to cherry-pick into master from the EStore branch:
- 610db2b72869f86ea78573b87f819453bd214daf
- 25bfd11eefe73e9725b1448eb78f3b9f5629d033
- ad84a7604fd94c9810e492e8b9c5d7e38110d641
- 95fdff7067f55479b5a3596b33839ffa66984664
- 5523c1834c44fc2befd3c4e834e72d8647e90c4d
- bf9a7c56b489582f74e078077ff853eecc61aea0

- part of 59e3a237fb6632a72f38733f6306f950d6c01eb4

Discovered that I could jut log a specific branch (l o) in Magit, then do (A A) or
(A a) to either cherry pick the commit directly, or apply its changes to the
working tree, thus letting me select what I want from it.  Very convenient.

** Using DynamicEObject in lieu of EStore                          :emfviews:
I've looked previously at DynamicEObject when searching for a solution to the
invoke() problem.

DynamicEObject has a simpler implementation than EStoreEObject.  I wonder if I
can use it as a base.  Does it funnel all feature access to a single method like
EStoreEObject?  There's a ~dynamicGet(int feature)~.  Doing:

#+BEGIN_SRC java
EObject o = new DynamicEObjectImpl(EcorePackage.Literals.ECLASS) {
  @Override
  public Object dynamicGet(int featureID) {
    System.out.println("dynamicGet: " + featureID);
    return "foo";
  }
};
#+END_SRC

It is indeed called for features that all the features that exist on the
metaclass.  DynamicEObjectImpl has zero static features, that's how everything
is routed through the dynamic* methods.

So it looks like DynamicEObject could serve just as well as EStoreEObject.  In
fact, EStoreEObject does work that we end up duplicating in EStore.get:

#+BEGIN_SRC java
public Object dynamicGet(int dynamicFeatureID)
{
  Object result = eSettings[dynamicFeatureID];
  if (result == null)
  {
    EStructuralFeature eStructuralFeature = eDynamicFeature(dynamicFeatureID);
    if (!eStructuralFeature.isTransient())
    {
      if (FeatureMapUtil.isFeatureMap(eStructuralFeature))
      {
        eSettings[dynamicFeatureID] = result = createFeatureMap(eStructuralFeature);
      }
      else if (eStructuralFeature.isMany())
      {
        eSettings[dynamicFeatureID] = result = createList(eStructuralFeature);
      }
      else
      {
        result = eStore().get(this, eStructuralFeature, InternalEObject.EStore.NO_INDEX);
        if (eIsCaching())
        {
          eSettings[dynamicFeatureID] = result;
        }
      }
    }
  }
  return result;
}
#+END_SRC

Here it already dispatches to different code depending on the structural feature
type.  But ~createList~ creates a list that will end up calling back into
eStore.get.

EStoreEObject also caches values by default, which we do not want.

I believe DynamicEObject would be a better base.

However it does not solve the main issue: we need a DynamicEClass, and assorted
family of classes.  Say we use DynamicEObject.  It still needs an EClass as
metaclass, and we want to use a Dynamic object for that.  We can't have a
DynamicEClass that extends DynamicEObject and EClassImpl, because we don't have
multiple inheritance.

We have two solutions:
1. DynamicEClass must extend EClassImpl first, and then implement
   DynamicValueHolder to funnel all calls to dynamicGet.  If we can capture
   calls to eStructuralFeatures that way, it would greatly simplify the
   implementation.  Although, we pay the price of inheriting from the large
   EClassImpl, with many methods we will never use.

2. DnyamicEClass extends DynamicEObject and implements EClass and associated
   interfaces.  It's lighter, and it's the conceptually cleaner way.  But one
   issue is that we may have a bunch of interface methods which we have no clue
   how to fill.  That's especially true for associated interfaces, because "one
   does not simply implements EClass".

I'll try #2 first because it's the proper way; the additional control from
implementing all methods ourselves will also help in ensuring we do not leak any
non-virtual object.

** Virtual values in BasicEObjectImpl                          :emf:emfviews:
In BasicEObjectImpl, there is code relating to "virtual values".  It looks like
dead code, since the core methods to set and retrieve virtual values throw:

#+BEGIN_SRC java
protected Object[] eVirtualValues()
{
  // return eVirtualValues;
  throw new UnsupportedOperationException();
}

protected void eSetVirtualValues(Object[] newValues)
{
  // eVirtualValues = newValues;
  throw new UnsupportedOperationException();
}
#+END_SRC

Though the previous code is still commented out... I have no idea if this is
used anywhere, but basically, it looks like an array of Object that you could
set and get.

Nothing related to what EMFViews is trying to do; and nothing usable.  Red
herring.

* [2017-08-30 mer.]
** Trying to implement EClass for DynamicEClass                    :emfviews:
Wrote a simple standalone implementation for now, to avoid interactions with the
existing code.  I want to make sure we can link the model and metamodel layers
without any hiccups.

And here's the first one: "b" is a virtual feature on the virtual class VA, and I
create a virtual object VO with VA as its metaclass.  When I access "b" on VO, I
get a null pointer exception because the feature "b" (EAttribute in VA) has no
eContainingClass.

The thing is, eStructuralFeatures is a bidirectional reference in Ecore, with
eContainingClass as its opposite.  When you add stuff to eStructuralFeatures,
EMF makes sure to update the opposite as well.  But here, I'm holding the
virtual features in a separate (plain) list, and the eContainingClass opposite
is never updated.

I could update the opposite myself.  Or I could use a VirtualEAttribute and
override eContainingClass.

* [2017-09-01 ven.]
** Setting the bidirectional reference                             :emfviews:
I can't seem to set eContainingClass using eSet on the EAttribute.  Because
eContainingClass is not a proper feature of EAttribute, strangely.

What happens when we add a feature to getEStructuralFeatures on a basic EClass?

1. getEStructuralFeatures() returns an EObjectContainmentWithInverseEList
2. Then we call add() on that list, which proceeds into addUnique()
3. It does doAddUnique, then inverseAdd()
4. Which calls eInverseAdd() on the EAttribute(a) (the /added/ attribute), and
   passes the EClass A (where it is added) and the feature ID of the opposite
   end of the EReference.

   Getting the feature ID, it casts the structural feature into an EReference.
5. This ends up in inverseAdd on EStructuralFeatureImpl, which does:

   #+BEGIN_SRC java
   case EcorePackage.ESTRUCTURAL_FEATURE__ECONTAINING_CLASS:
     if (eInternalContainer() != null)
       msgs = eBasicRemoveFromContainer(msgs);
     return eBasicSetContainer(otherEnd, EcorePackage.ESTRUCTURAL_FEATURE__ECONTAINING_CLASS, msgs);
   #+END_SRC

   Which ultimately sets the container of the EAttribute to the EClass, and also
   sets the feature ID corresponding to the containment.

And when we add the virtual feature on the virtual class, none of that happens.

Why can't I add the virtual attribute to the actual structural features of the
virtual EClass?  Oh right, our VirtualEClass does not have an actual list of
structural features, it just implements the EClass interface, by answering to
the getEStructuralFeatures() method.  The only list of structural features that
exists is the one in the concrete EClass, and we certainly don't want to modify
that one.

But maybe we could lie about our containing class?

Ok, so I created VirtualEAttribute that implements EAttribute, but it also has
to implement EStructuralFeature.Internal, since BasicEObject needs the feature
to cast into that.

Then I need to return a SettingDelegate in getSettingDelegate... which is a
615-lines method in EStructuralFeature!  Argh.

* [2017-09-04 lun.]
** Stubbing ESetttingsDelegate                                     :emfviews:
Doing this:

#+BEGIN_SRC java
@Override
public SettingDelegate getSettingDelegate() {
  SettingDelegate.Factory f = EcoreUtil.getSettingDelegateFactory(this);
  return f.createSettingDelegate(this);
}
#+END_SRC

and EcoreUtil walks up the hierarchy and asks for the eContainingClass of the
VirtualEAttribute, and the EPackage of the VirtualEClass.

... and ultimately returns null.  Grmbl.  Okay so it was looking for existing
setting delegates, but it seems I have none.

And SettingDelegate is an interface.  When I instantiate a ~new
SettingsDelegate()~, its dynamicGet() method is called... this is a bit
confusing, since I already have a dynamicGet on VirtualEAttribute.

Debugging with G, we managed to make the example working.  The SettingDelegate
just calls back into the DynamicValueHolder... a bit dumb, but it works.

So now I can actually create a VirtualEObject with a VirtualEClass as metaclass,
and I can set/get virtual features on this VirtualEObject without affecting the
original object.

I'm not sure what happens if that feature is an EReference though.

But I guess I could start using these virtual objects for the Viewpoint and
EView now.

* [2017-09-05 mar.]
** Expanding on VirtualClass                                       :emfviews:
Okay so my plan would be to write a new suite of tests that create virtual
objects directly, rather than using Viewpoint.  This way I can make sure I have
basic functionality of adding properties, reference, etc.  Even testing that it
works at the model level.

Then, I can go back to Viewpoint and EView and integrate these changes.

Okay so I'm trying to test adding a virtual reference.  What should eGet return?
An EList, preferably one we can add and remove from.

I think I've got the basics, except filtering.

Just adding a filtered field on virtual objects should do it.  But then the list
of virtual features should take these filtered objects into account, like I did
in the EStore implementation.

* [2017-09-06 mer.]
** Filtering elements                                              :emfviews:
It stands to reason that all elements of the metamodels can be filtered.  I
don't know if it makes sense to filter a VirtualEObject directly, but it
wouldn't be difficult to do so.

If the "filtered" attribute is held by virtual elements, then to be able to say
that a feature "a" on class "A" is filtered, we need to set the attribute on the
virtual element that wraps this feature.  So when asking for a feature on a
virtual class, it should wrap its contents.

Moreover, when asking for the list of features, we want the virtual class to
report only the non-filtered features.  For that to work, the virtual class
needs to be able to interrogate the filtered status; it can do that if it holds
the virtual elements that wrap the concrete features directly.

There are at least two ways to implement that, and I'm not sure which is better
for our purpose.  The first one would be to have VirtualEClass simply hold a
list of structural features, and when constructing the VirtualEClass, we would
wrap features before adding them to the class.  That way, VirtualEClass does not
need to know which features map to concrete objects and which are purely
virtual.  And it can report the non-filtered features, since every feature has a
"filtered" attribute.

The second way to implement it would be to keep a reference to the concrete
EClass and a list of virtual features, but when we report the list of features,
we wrap it in a virtual one.  And we keep track of the mapping from concrete
features to virtual ones.  That way, we can still report non-filtered features,
but we only wrap objects on demand.  It can also allow us to respond to changes
in the contributing metamodels, though we don't know if that would often be
useful in practice.

So, if we go the first route, then I would have trouble discerning that from the
previous state of affairs: we would construct the Viewpoint in the same way, but
wrapping everything instead of copying.

The second route is more lazy, so closer to the "lightweight proxies" idea.
Besides, the point is to have a symmetry between model and metamodel, and
wrapping objects on the fly is what already happens at the model layer, so...
Second route it is.

Okay so it works now.  I created a VirtualFeature object to hold the filtered
attribute to start with.  I'm sure I can lift that higher, as classifiers should
be able to be filtered from a package as well.

Haha!  Interesting complication:

#+BEGIN_SRC java
EObject o = EcoreUtil.create(A);
o.eSet(a, 1);
o.eSet(a2, 2);
VirtualEObject Vo = new VirtualEObject(o, VA);

assertEquals(2, eGet(Vo, "a2"));
#+END_SRC

On the class VA, the feature "a" is filtered out.  But we should still be able
to access "a2", right?  We do!  But, we return 1, instead of 2.

Why?  Because we end up calling VirtualEObject.dynamicGet(0), 0 being the
dynamicFeatureID since "a2" is now the first feature on the meta class.  But
VirtualEObject is oblivious to the filtered feature and gets the value of the
feature 0 in the concrete object.

So oviously we have to instruct VirtualEObject of the filtered features.

For the same reason, the following let us access the value of feature "a":

: Vo.eGet(0, false, false);

because we also end up in dynamicGet(0).

* [2017-09-08 ven.]
** Fixing feature ID with filtered features                        :emfviews:
Given the class A with features "a" and "a2", with respective feature IDs of 0
and 1.  If we filter "a", what should be the ID of "a2"?

Currently, EMF returns 0, and that explains the bugs from last time.  If a2
kepts its ID of 1, it would fix the first bug, but not the second: calling
eGet(0) would still give us access to the filtered feature "a".

What we need is to be able to map the virtual ID back to a concrete ID.  In this
case, ID 0 is feature "a2", so we to look for that feature and get its ID.

When I do eGet(o, "a2"), here is what happens:

- a2 is looked up in the features of the VirtualEClass, so we get the
  VirtualEAttribute "a2"
- eGet then calls eDerivedFeatureID which calls
  VirtualEClass.getFeatureID(feature), which returns the ID among filtered
  features: 0
- eGet then gets the feature object back from the VirtualEClass, so we get again
  the VirtualEAttribute "a2"
- eGet gets the setting delegate for this feature, and calls dynamicGet on it,
  with its feature ID (0)
- which calls VirtualEObject.dynamicGet(0)

So if we want to know which feature was called from the original eGet, we can
get it back from the VirtualEClass (again!).

In the end, I went with adding a getFeatureAbsoluteID(feature) on VirtualEClass,
which goes through all (filtered and non-filtered) features to give the ID.
This ID can then be used to query the concrete EClass and compute the offset in
the array of values in VirtualEObject.

I think I have all I need to implement back into Viewpoint.  At last!

* [2017-09-11 lun.]
** Implementing Viewpoint with VirtualEClass and co.               :emfviews:
Forgot VirtualEPackage.  It's basically the same thing as VirtualEClass: it
holds classifiers instead of features.

And at this point, I should also make sure that referential equality holds
between created virtual objects, using a common object to manage the map of
concrete to virtual objects.

Can't seem to use EcoreUtil.create() on a virtual class that does not belong to
a package... and that package also needs a factory.  Well, I'm not sure we will
create many objects at runtime through the virtual API anyway, so I'll just use
a dummy EPackage to create this instance and wrap it in a VirtualEObject.

Or, I guess the other way is to create a dynamic object ourselves and set its
metaclass.

I was a bit surprised that this bit worked:

: DynamicEObjectImpl Vo = new DynamicEObjectImpl(Vc);

where Vc is a VirtualEClass instance.

I don't have to wrap the dynamic object in a VirtualEObject in order to eGet or
eSet its features...  The reason it works is because here the Virtual class is a
simple proxy, and I only interact with a concrete feature existing on the
concrete class.  A DynamicEObject is oblivious to virtual features and filtered
features.

Hmm, actually, a DynamicEObject is perfectly capable of handling virtual
features and filtered features, as long as the metaclass /does not change/
dynamically.  Does that mean that a VirtualEObject can handle changes?

Yep, it does.  I made it even more flexible by storing the values in a map from
features to object, as the indexed array was too messy with filtered features
changing IDs and so on.  It's probably eating more memory though, but we'll
worry about that later.

Hmm, interesting!  In VirtualEObject.dynamicGet:

: return concreteEObject.eGet(concreteFeature);

fails because at some point, EAttribute looks up for the settingDelegate of its
containing class's /package/.  If the containing class is not part of the
package, null pointer exception.  So it looks like I need to have a concrete
EPackage on top of synthetic EClass even.

* [2017-09-12 mar.]
** Recapitulating tradeoffs for the new metamodel                  :emfviews:
Here is a class diagram of the new elements I've created so far:

[[file:doc/emfviews-new-class-diagram.svg]]

Rather straightforward: we have Virtual* classes that wrap concrete EMF objects
and delegate to them, but also support filtering and virtual features.

*** Why DynamicEObjectImpl and not, say, EStore, or implement EObject?
Implementing EObject seemed like a waste of time, since we could reuse existing
implementations.  Also, the docstring of EObject advises against it:

#+BEGIN_QUOTE
Implementations of EObject should extend BasicEObjectImpl or one of its derived
classes because methods can and will be added to this API.
#+END_QUOTE

(Also, while EObject has only a few methods, you really need to implement
InternalEObject to do anything with EMF, which has many more methods that are
not strictly relevant to our virtual layer)

For EStore, I've looked into the implementation, and I didn't see anything it
did more than DynamicEObjectImpl that could be useful.  The eStore.get API is
cumbersome: you get feature and an index into it, which leads to an overly
complex implementation to deal the different cases.  It's simpler to just
intercept dynamicGet, so we might as well extend DynamicEObjectImpl directly
rather than taking cruft.

The point is to have lightweight proxies.  We could probably even shed
DynamicEObjectImpl and extend BasicEObject and implement DynamicValueHolder
directly.  But this extending DynamicEObjectImpl was easy enough to start with.

*** Why do you need as VirtualEClass separate from VirtualEObject?
We need to control the metaclass (eClass) of VirtualEObject instances.  Since
a VirtualEObject is a DynamicEObjectImpl, we use eSetClass(EClass).  That
requires an EClass instance!

In fact, the ~EClass eClass()~ method is part of the EObject interface, so
there's no getting around it: we need an actual EClass implementation for the
metaclass.

VirtualEClass also holds a list of extra (virtual) features that do not exist on
the  concrete backing EClass.

*** Why do you need VirtualFeature?
A VirtualFeature is more than an EStructuralFeature: it can be filtered out, so
we need to keep track of that flag somewhere.  We could keep it in
VirtualEClass, along side the list of features, or we could keep it in a
"MetamodelManager" class (essentially, the Viewpoint).

But there's another reason to implement EStructuralFeature: EMF
(BasicEObjectImpl) uses the settingsDelegate of a feature in the reflexive
eGet/eSet calls to an EObject.  So, in order to capture the eGet calls to a
virtual object, we need to control the settingsDelegate of its features.  Hence,
we need to implement EStructuralFeature.Internal.

*** Why do you need VirtualEPackage?
We need a place to store pure virtual classes: those that are not backed up by
any concrete EClass from the contributing metamodels.

Also, since, virtual classes can be filtered out, having VirtualEPackage lets us
implement getEClassifiers() to return the list of non-filtered classifiers.

*** Why VirtualEAttribute and VirtualEReference?
I'm not sure we actually need those.  At the moment, it looks like we could move
their functionality to VirtualFeature and everything would work.

But while I haven't finished plugging this model back into Viewpoint and EView,
I don't want to prematurely factorize.

*** Why isn't VirtualEObject a parent for the others?
It could, possibly; I try to avoid prematurely factoring.  After I plug this
into Viewpoint/Eview, I will look into refactoring.

Currently, I think there's no benefit, apart from making a pretty class diagram,
to making VirtualEClass inherit from VirtualEObject:

- We don't want to inherit the dynamicGet/Set implementation of VirtualEObject,
  since they are specific to the model layer.
- We don't need to treat a collection of VirtualEClass as VirtualEObject.  If we
  put the filtered attribute on VirtualEObject, then it could be interesting.

*** Why does VirtualEClass need to wrap all its contents in virtual objects?
That is, when you ask for the features of VirtualEClass, you will get all the
concrete features of the backing EClass /wrapped in VirtualEFeature/ (same thing
for VirtualEPackage/VirtualEClass).  Is that necessary?  Why not give the
original feature back?

I think currently wrapping features in VirtualFeature is just a way to be able
to filter them.  Since the filtered attribute is held by a VirtualFeature, I
chose to create a VirtualFeature for each concrete feature in an EClass.
Another solution would be to have another object to ask whether a feature is
filtered, and where we would set the filters.

We still need VirtualFeature for purely virtual features, to catch the
settingsDelegate though.

*** Things to investigate later
- Referential equality does not hold; need a repository of virtual objects.
  This might get obsoleted if we simply do not wrap existing objects.  If the
  filtered bit for features is held by VirtualEClass for instance, then we not
  need to map concrete features to virtual features anymore, so referential
  equality holds.

  Otherwise, we need to keep track of the mapping between concrete and virtual
  objects.  Maybe on a virtual class scope, maybe on a viewpoint scope.

- Lot of stub methods.  Some might not make sense on a "virtual" object (so we
  can let them throw unsupported), but some do, and we have to make a decision
  about what they should answer.

  Also, the dynamicGet methods are supposed to work with all methods of the
  metaclass.

- VirtualEClass, VirtualEObject, etc. should be interfaces.  To mimic EMF class
  diagram, and so we could see what they add to EClass, EObject.

  Currently, there are really three differences: VirtualEClass has virtual
  features, VirtualEPackage has virtual classes, and all (including non-virtual)
  features/classes can be filtered.

* [2017-09-13 mer.]
** Factorizing into VirtualEFeature                                :emfviews:
Changed my mind about waiting for factorizing that, because it was an easy thing
to do, and I don't think I will need to revert it:  VirtualEFeature implements
EStructuralFeature.Internal, and now the EAttribute/EReference-specific methods
are more visible in VirtualEAttribute and VirtualEReference.

** Plugging back into Viewpoint                                    :emfviews:
Wrapping the contributing packages in VirtualEPackage.  All tests fail.  Yeah!

The validator is asking for an eFactoryInstance.  We don't have that on the
Viewpoint.  Turning off validation I'm afraid.

Easiest thing to do would be to plug back the filters.  Interestingly, we now
need a hold on the parent element to be able to filter something in the
metamodel.  Specifically, the Virtual parent.  It means that, in the Viewpoint,
we need to turn at least the EClass into VirtualEClass if we want to be able to
filter features.

Seems VirtualEPackage.getEClassifiers() cannot return an unmodified EList, as
EStructuralFeature.dynamicIsSet casts the return value to
EStructuralFeature.Setting!

#+BEGIN_SRC java
Object setting = settings.dynamicGet(index);
if (setting == null)
{
  return false;
}
else
{
  return ((EStructuralFeature.Setting)setting).isSet();
}
#+END_SRC

Hmmmmmm.  So EcoreEList$UnmodifiableEList implements EStructuralFeature.Setting,
but ECollections$UnmodifiableEList does not.  Sigh.

Have to use the former, which is a bit awkward.

Looks like I can't use the debugger to "Run to line" in a lambda.  Sad.  Back to
loops instead of forEach then.

AAArgh.  So blacklisting works, but whitelisting doesn't.  Everything is
filtered out when whitelisting.  Why?  Because EMFViewsUtil.getEObjectPath does
not return a full path, but only the name of object ("Element" instead of
"contentfwk.Element").  That's because we build the path by going up the
container hierarchy:

#+BEGIN_SRC java
    while (o != null) {
      comps.add(((ENamedElement) o).getName());
      o = o.eContainer();
    }
#+END_SRC

But for virtual objects, eContainer is null.  Probably have to fix that, and/or
find another way to build the path.

* [2017-09-15 ven.]
** Fixing empty eContainer                                         :emfviews:
eContainer is a method on the EObject interface.  According to the docs:

#+BEGIN_QUOTE
An object is contained by another object if it appears in the {@link #eContents
contents} of that object.  The object will be contained by a {@link
#eContainmentFeature containment feature} of the containing object.
#+END_QUOTE

Since a VirtualEPackage's contents return VirtualEClasses, the eContainer of the
VirtualEClass should return the VirtualEPackage.  I should /also/ implement
eContainmentFeature to return the ID of the containment feature of the
eContainer.

Overriding eContainer to return the container from the concrete feature, but
virtualized, works.

At this point however, I wonder if I should just not simply return to the
DelegatedEObject implementation strategy.

Hit an interesting Java problem when trying to be a little more strict in
Viewpoint.  Summed up my thoughts [[file:emfviews-test/src/another/MyMap.java][here]].

* [2017-09-18 lun.]
** Adding superTypes to a VirtualClass                             :emfviews:
Seems I did not anticipate this scenario in my previous tests.  Doing:

: klass.getESuperTypes().add((EClass) sup);

where ~sup~ is a VirtualEClass fails because the VirtualEClass cannot be cast to
an ESuperAdapter.Holder.  I guess we can delegate this call to the concrete
EClass.

Yep that works.  Although, I also need to keep a list of virtual supertypes,
i.e., super types that only exist on the virtual metamodel.

Damned.  Can supertypes be filtered?  I guess they could.  Did not take that
into account.  If filters on classifiers are held by the package... we would
have to ask the package to know what to answer in VirtualEClass.getESuperTypes.

Similar issues arise with creating associations: the eOpposite feature should be
set on the virtual feature, but what happens if one end is filtered?

Updated the tests to work with a mock viewpoint (really, an interface to keep
track of virtualized objects).  How filters behave on supertypes is an
interesting problem.  Might not be solved right away, but it's a good thing to
register it.

Tomorrow: resolve the eOpposite issue.

* [2017-09-19 mar.]
** Resolving the eOpposite issue                                   :emfviews:
When we add a bidirectional reference, it's only after we first create a
synthetic EReference.  That synthetic reference can be altered (it's part of the
virtual package).  However, it can point to a synthetic EReference, or it can
point to a concrete EReference.  In both cases, the eOpposite link should only
exist virtually and not alter the concrete metamodel elements.

That means, that we have to add a virtualEOpposite feature on EReference.  Or,
setting the eOpposite on a VirtualEReference does not set it on the concrete
ERef.

Okay, that works.  Went with the first option, as having an explit
setVirtualOpposite is less confusing for the moment.

Now all viewpoint tests pass.  On to EView.

** Converting EView to use VirtualEObject                          :emfviews:
When "projecting" virtual links in EView:

Trying to set VirtualERef 184 (-> ERef detailedProcess 196)
-> dynamicSet with featureID = 16
absoluteID = 16  (VirtualERef 184)

But 29 features on the concrete EClass, not 15.

Using getEStructuralFeature(int) on EClassImpl will look up the feature among
/all/ structural features, local and inherited.  While my lookup for absolute ID
only accounts for local features.

Okay, implemented EAllStructuralFeatures.

Now I need to override VirtualEObject.eContents to virtualize objects from
containment references.

Need to implement EAllContainments... which uses EAllReferences...

Now VirtualEObject needs a virtualizer.. which is the EView.

And that's it!  It works!  All tests pass!

Tomorrow: make sure that the constructed viewpoint/view are all virtualized, and
add tests for cases where they are not.

* [2017-09-20 mer.]
** Double-checking correctness of the new class diagram            :emfviews:
A note about correctness of the virtualization: looking at getAllContents of a
viewpoint, the objects that are not virtualized mostly seem to be:

- EAnnotationImpl
- EGenericTypeImpl
- EStringToStringMapEntryImpl

All model elements can have annotations.  Since it's a containment reference, an
EAnnotation has an eContainer attribute pointing to the containing EClass, say.
Not the virtual one.  You should be able, however, to iterate over annotations
of a VirtualEClass.  The containment link is just broken in the other way.

I fear it's the same for other containment links; we don't take extra care of
maintaining consistency for these currently.  How hard would it be, in practice?
I think it's just a matter of wrapping EAnnotationImpl, override eContainer(),
and return the corresponding VirtualEClass.

So, not really hard to do if we find out that it's something we need further
down the road.

Samething goes for EGenericType.  The StringToString map are contained by
annotations.. so if annotations are virtualized, these map entries should also
point to the virtualized container.

Found a few more:

- EEnumLiteralImpl
- EEnumImpl

Same remarks: we can obtain the concrete versions from getAllContents on a
virtualized package.  Going up the eContainer reference, we'll end up on the
concrete metamodel.

Hmm.  Calling getAllContents on an EView raises an NPE.  There's an eGet in
VirtualEObject.eContents that returns null.  Should it?  Can it?  It looks as if
the TreeIterator is not happy about it in any case, because it tries to get the
contents of null.

Maybe I should just not add a null value to the eContents list.  Yeah, it looks
like calling getAllContents on the original model does not produce any null.

But now, EMF wants to cast a VirtualEReference to
an... EStructuralFeatureExtendedMetaData.Holder.  Yuck.

But this only happens because we end up in BasicEObjectImpl.eOpenGet, because
the featureID is -1.

The reference is reqif10.Identifiable.alternativeId.  It's not found on the
structural features of the virtual EClass, hence the -1.

If it was filtered, it shouldn't have appeared in the getAllContents in the
first place.  So it's not filtered.  But then, if it's not filtered, why does it
appear in the getEStructuralFeatures list?

So actually, we are looking for the feature ID of 'alternativeID' on the EClass
'DatatypeDefinitionStringImpl', which is a subtype of Indentifiable.  And the
feature is on the parent, so we miss it.

Well, I guess getFeatureID should look into getAllEStructuralFeatures and take
inherited features into account.  That's what EClassImpl does.

Same thing for getEStructuralFeature(int) and getEStructuralFeature(String):
they both look up into the /all/ structural features, including inherited.

Hmmmm.  eGet in eContents returns a boolean.  Shouldn't we always have EObjects
in features?

Oh, okay.  in VirtualEObject.dynamicGet, we return a completely wrong feature.
(Damn you, feature IDs!).

dynamicFeatureID = 17
feature is the VirtualERef for the 'monitoring' ERef
absoluteFeatureID = 17
concreteFeature = 'isExecutable' EAttribute <-- wrong

'monitoring' is the feature of index 3 in the eStructuralFeatures list of
Process.  And feature of index 13 in eAllStructuralFeatures.

Something is clearly very wrong here.  But these IDs are getting on my nerves,
so I will simply lookup the feature by name in the concrete class.  Feature
names are unique anyway.

Yeah!  Tests pass.  And the eAllContents of my objects are all VirtualEObjects
in front of DynamicEObjectImpl or instances of generated classes.

Next time: make a class diagram of the ways things work now.  Also make diagrams
for on a couple of examples of what is created and what the links look like when
we have a viewpoint and a view.

* [2017-09-22 ven.]
** Notes on the new class diagram                                  :emfviews:
[[file:doc/emfviews-new-class-diagram3.svg]]

I tried to simplify the original architecture while keeping its functionality
intact, and bringing it closer to the original idea.

The main idea is to mirror EMF classes to virtual counterparts.  So we have
VirtualEObject, VirtualEPackage, VirtualEClass, etc.

The point of these virtual classes is twofold.  First, they act as proxies to
the objects in the contributing models and metamodels.  We can decide whether to
write back changes to the original objects, or make the proxies read-only.  We
can intercept any method call, any feature set, and change its behavior.
Second, the virtual classes allow us to /filter/ and /extend/ the contributing
metamodels without modifying them.

Any classifier in a VirtualEPackage can be filtered, any feature in a
VirtualEClass can be filtered.  Since a VirtualEObject has a VirtualEClass as
metaclass, the filtered features are reflected on the VirtualEObject as well.
These filters are dynamic: we can filter or unfilter a feature and see the
changes on the next call to getEStructuralFeatures, without the need to
reconstruct the virtual metamodel.

Following the weaving model, we can also add features to existing concepts: a
VirtualEClass has a list of such virtual features.  A virtual feature is part of
the VirtualEClass eStructuralFeatures feature, but does not affect the backing
concrete class.  All virtual links specified by the weaving model exist in this
new virtual layer (virtualFeatures, virtualClasses, virtualSuperTypes,
virtualOpposite): these links exist solely between the virtual objects, without
modifying the concrete metamodels underneath.

The Virtualizer is needed to maintain consistency between objects; it maps a
concrete object to its virtual counter part.  For instance, a VirtualEPackage
contains classifiers.  These classifiers are VirtualEClass instances.  When we
ask for the super type of a VirtualEClass, these are classifiers from the same
package, hence, the super types should be the /same VirtualEClass instances/
found in the list of classifiers from the VirtualEPackage.  The VirtualEPackage
and VirtualEClass objects need to communicate somehow to make sure these
instances are the same: that's the role of the Virtualizer.

In the previous architecture, this role was filled by the VirtualLinkManager and
MetamodelManager.  They managed the maps between concrete and virtual objects,
for the model and metamodel layers respectively.  The MetamodelManager made
distinctions between the types of objects, and a larger API surface as a result.
The Virtualizer is much simpler, conceptually and implementation-wise, and is
used the same way by both layers.

** Advantages over the the previous architecture                   :emfviews:
Mostly, the previous architecture suffered from growing organically, in the face
of new requirements.  It was baroque, and in need of a good cleaning.  Dead
code, duplicated code, coupling between classes, and many questionable,
and crucially undocumented, decisions.

In rethinking the whole thing, we have shed a lot of weight, to obtain something
that's conceptually clearer and leaner.

We also gained some flexibility.  The main defect of the previous architecture
was in the Viewpoint, where it duplicated all the contributing metamodels
elements.  This had a upfront cost when loading the Viewpoint resource, both in
time and memory.  More importantly, it meant we didn't have a symmetry between
the implementations of the virtual model and virtual metamodel.

Now, instead of duplicating contributing metamodel objects, we simply wrap them,
but lazily.  When we load the Viewpoint resource, we simply wrap the
contributing metamodel packages in VirtualEPackage.  That's all we do with the
contributing metamodels.  We don't virtualize the contents of these package
until they are actually requested.  So, when we call getEClassifiers on
VirtualEPackage, that's when we virtualize the classifiers to provide the list.

(And ideally, we could provide a lazy list, which would only virtualize the
classifier when one is accessed.  This is useful in case only one element in the
list is accessed, or if the list is actually never used!).

So, instead of having the full contributing metamodels duplicated, in practice,
we only build what's used.  Furthermore, even if we end up building virtual
objects to stand in for every object in the contributing metamodels, these
virtual objects still have a smaller memory footprint than the default EMF one,
since they contain less information.  The virtual objects can delegate most of
their knowledge to the backing concrete object.

For the model layer, the previous architecture was already using
ReproduceElement instances as proxies for concrete model objects.  I simplified
the implementation by using only View and VirtualEObject, whereas before we had
View, EView, VirtualElement, ReproduceElementImpl, ReproduceRule,
TranslationRule, and VirtualAssociation (without mentioning the unused
MergeElementImpl and FilterElementImpl).

** Rationale for cutting classes from the previous architecture    :emfviews:
I'm referring to [[file:doc/emfviews-class-diagram.svg][this diagram of the previous architecture]].

- LinksProjector.  This was easy, it's only job was to populate the contents of
  virtual features at the model level.  When virtual features are created on the
  viewpoint, the weaving model of the model tells us what model objects to put
  into them.  The LinksProjector did that.  It was a one-time thing, when the
  View is loaded.

  I turned it into 25 lines in View.doLoad.

- MetamodelManager.  I'm not quite sure why we needed to separate features and
  classes in these maps.  Or why we needed this class at all.  We built these
  maps ahead of time, which made them inflexible.  It seemed to me we didn't
  need to keep track of all this; the View only has to use the Viewpoint as
  metamodel.

  In fact, in VirtualEObject, it's quite easy to find out if a feature is
  virtual or not without these maps.  And we could put the information into
  Viewpoint itself.

- View/EView.  I merged them into View, since it was really a split class, with
  View being intended to act as a superclass for Viewpoint, I think.  But this
  was never the case.

- VirtualContents.  These was an awkward list implementation that allowed
  multiple list to behave as one.  Unnecessary, since we had to build the
  sublists anyway, we might as well flatten them and put all the objects
  directly into a plain list.

- VirtualModelList.  This was one was more interesting.  It was a kind of lazy
  list that virtualized its contents.  Used by ReproduceRule to turn the
  contents of a reference into ReproduceElementImpl instances.

  We can build this list ahead of time without any change in functionality.  But
  I may resuscitate a similar "delayed" list for virtualizing only objects that
  are accessed if we find that premature virtualization has impacts performance.

- TranslationRule, VirtualElement, ReproduceRule, ReproduceElementImpl,
  VirtualAssociation.  All these are replaced by the single VirtualEObject
  class, which is not very complex.  The Rule/Element split was needed because
  that's how EStore works.  Other causes were unncessary abstraction, and
  duplicated code.

* [2017-09-25 lun.]
** Writing more tests for virtual objects                          :emfviews:
I reluctantly added a mock virtualizer to the virtual objects, since at first I
didn't need one to construct the tests.  However, the virtualizer is necessary
to maintain consistency in the design.  When writing a new test for inherited
virtual features for instance, if I create the VirtualEClass instances in the
tests (to add attributes to them), then they won't be registered by the
virtualizer, and the virtual features will never be seen by the virtual class.

So, the virtualizer is integral to the design.  Something to keep in mind when
writing tests.

Hmm, in fact, it turns out my mock virtualizer was too complex: it actually
/did/ virtualize objects, while this was not necessary for most of the tests I
had already written.

Instead, it can just return its argument.  For tests that require a virtualizer
that does actuall creation of virtual objects, then I can use Viewpoint and View
directly, instead of testing my duplicate implementation in MockVirtualizer.

I added the tests for the cases I encountered while rewriting Viewpoint/View.
I'm thinking of adding a few more tests, one for each feature of the EMF class
diagram.

** Filtering classifiers in getESuperTypes                         :emfviews:
So, the list of filtered classifiers is held by the virtual package, since it
allows us to filter any classifier, not just EClass, without having to define a
VirtualEClassifier class.

However, we can ask to filter any classifier, including:

1. classifiers that are not even part of the package, and
2. virtual counterparts for classifiers that are part of the package (and
   vice-versa).

The first is easy to solve: just check the classifier is in the package.  The
second...  Conceptually, when you ask for the classifiers of a VirtualEPackage,
you get virtual elements.  Well, a mix of virtual elements and concrete elements
that are not virtualized (EDataType).  So the question is really: when we
filter an EClass A, should its virtual counterpart be filtered as well?

Maybe, to be consistent and not too lenient, we should just be able the
classifiers that are returned by getEClassifiers.  That way, it's predictible.

Ah, now it seems the mock virtualizer is not enough.  Most of the tests fail
because they lack the internal consistency brought by the viewpoint/view
virtualizers.  Too bad.

But, otherwise, it works.  Except that classifiers are now required to have a
package, although conceptually that was already the case in EMF anyway.

** Interesting property of getVirtual                              :emfviews:
For methods that return an EObject, getVirtual has the following property:

: getVirtual(concreteEClass.getEPackage()) == getVirtual(concreteEClass).getEPackage()
: f(g(c)) = g(f(c))

* [2017-09-26 mar.]
** Adding tests for all proper features of the EMF diagram         :emfviews:
Most of this is straightforward.  Just a bit tedious to write.

Tried to add a reference via getEReferences(), to see if it would work.  It
does, but EMF outputs on stderr:

#+BEGIN_SRC java
public boolean add(EReference object)
{
  System.err.println("Please fix your code to add using EClass.getEStructuralFeatures() instead of EClass.getEReferences()");
  return getEStructuralFeatures().add(object);
}
#+END_SRC

"I will add the reference, but please don't do that".  I'm not sure what's the
effectiveness of such a statement.  But I guess there's no way to deprecate an
override... so, better than nothing.

* [2017-09-27 mer.]
** More tests                                                      :emfviews:
Finishing the tests for each Virtual* component I reimplemented.

** EOpposite troubles                                              :emfviews:
A thorny issue arises once again with EOpposite.  Consider the situation where R
and R2 are two concrete references, opposite of each other, and VR and VR2 are
their respective virtual counterparts.

Clearly, VR and VR2 are opposite of each other.  The concrete opposite link is
reflected at the virtual level.

Now, consider the situation where R is a concrete reference, and R2 is created
as part of a new association, and has R as opposite.  The opposite link then
only exists at the virtual level, not the concrete one.  Hence, it must be
materialized, and that's why I added a virtualEOpposite attribute.

But now, what should VR2.getEOpposite() return, in general?  The value of the
virtual opposite, or the value of the concrete one?

It seems strange to me that this is the only place where this problem arises.
But I guess it's also the only feature of arity 0..1 that's reflected at the
virtual level.

For now, returning the virtual opposite if present and falling back on the
concrete one seems the most natural solution to me.

** Another snag with bidirectional references                      :emfviews:
When adding a virtual feature to a VirtualEClass, we do not set the
eContainingClass of the feature propertly.

Problem: how do we actually set the eContainingClass feature?  There is no
setter, and eSet says it "is not a changeable feature", even though, indirectly,
it is.

I should probably trace how EMF effectively changes the feature value, and hack
it into VirtualEClass.addVirtualFeature.

** Next time                                                       :emfviews:
- Solve the bidirectional reference issue
- Compute how many virtual objects are created when loading the viewpoint on a
  large model/metamodel like TOGAF
- Add javadoc for core methods/classes
- Update README
- Update copyright notices (and close TODO)
- Merge back in master

* [2017-09-29 ven.]
** Solving the bidirectional reference issue                       :emfviews:
When we do A.getEStructuralFeatures().add(r), we end up in r.eInverseAdd(A, 17),
where 17 is the feature ID of eContainingClass.

Ultimately, that sets eContainer to A, and eContainerFeatureID to 17.

Yep, calling eInverseAdd works.  We don't want to do that in
VirtualEClass.addVirtualFeature though, since we could potentially modify a
contributing metamodel that way.  Instead, I do it in the Viewpoint, since there
I know the structural feature is synthetic and can be modified.

The only other place where we would have the same issues is the
eClassifiers/ePackage containment reference.  But there, we actually add the
VirtualEClass to the virtual package using getEClassifiers().add(), because we
can modify the virtual package.

* [2017-10-02 lun.]
** Working through Xtext tutorial                                  :emfviews:
[[http://www.eclipse.org/Xtext/documentation/102_domainmodelwalkthrough.html][There]].  Xtext is a language engineering platform (or "language workbench", as
others have called it).   Given a grammar, it will generate a bunch of code for
parsing, syntax highlighting, serialization...  It will infer an EMF model based
on the grammar, or you can use an existing one.

It's tailored to define your own DSLs inside Eclipse.  And it seems it's a
low-friction way to do so.

That's exactly what we use it for in EMFViews: it for our two DSLs.

** Next time                                                       :emfviews:
Make our SQL2Views DSL work with the new weaving model

* [2017-10-03 mar.]
** Exploring VPDL                                                  :emfviews:
ViewPoint Description Language: our DSL for creating a viewpoint using a
SQL-like language instead of writing Eviewpoint files and weaving models by
hand.

In the VPDL file, like this one:

#+BEGIN_EXAMPLE
create view myEAviewpoint on
'http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' as togaf,
'http://www.omg.org/spec/BPMN/20100524/MODEL-XMI' as bpmn,
'http://www.omg.org/spec/ReqIF/20110401/reqif.xsd' as reqif
select togaf.EnterpriseArchitecture.architectures, togaf.StrategicArchitecture.strategicElements,
  togaf.BusinessArchitecture.processes, togaf.Process.processCritiality, togaf.Process.isAutomated,
  togaf.Requirement.statementOfRequirement, togaf.Requirement.rationale, togaf.Requirement.acceptanceCriteria,
  bpmn.Process.isClosed, bpmn.Process.isExecutable, bpmn.Process.processType
from togaf.Process join bpmn.Process as detailedProcess,
  togaf.Requirement join reqif.SpecObject as detailedRequirement
where togaf.Process.name=bpmn.Process.name and
 togaf.Process.isAutomated = 'false'
#+END_EXAMPLE

It lists the contributing metamodels, so we can put that into the eviewpoint.

It lists the features that should be visible (via 'select'), and that
should go into the weaving model for the viewpoint.

It also tells us how we should merge the contributing models, and that should go
into the ECL file.

(Sidenote: Cheng remarked that the syntax for comparison in the ~where~ could be
more expressive, using OCL expressions.  Looking at the grammar, it looks like
we accept arbitrary ECL expressions, in the form of strings).

Looking at what we have, beside the grammar, there is a generator that writes
the Eviewpoint file and the ECL file.  However, the ECL generation is hardcoded
to output only the ECL for the three model composition...

If there is a metamodel for ECL, we should preferably use that in the generator.

And lastly, there is a SQL2VirtualLinks ATL transformation that should create a
weaving model from the VPDL.  There is Java code to run the transformation, but
it's not plugged in the generator in any way.

Regarding the grammar, we could define the metamodel for the parsed language
ourselves, as currently it generates a lot of useless nodes that are needed by
the grammar, but not by the end model.

Alternatively, we could map to WeavingModel directly, but I don't think that's a
good idea, since it's clear now that one VPDL maps to 3 differents models:
EViewpoint, ECL, and weaving model.

** Xtend font troubles                                        :eclipse:xtext:
The Xtend plugin (in addition to having its own syntax coloring scheme, separate
from the base Java one) was stuck using Monospace-10, not picking up my default
editor font.  There was a promising setting under General->Appearance under
"Xtend editor font", but changing it had no effect.  In fact, it resets when I
load the preferences panel again (!).

Curiously, each syntax class under Xtext->Editor->Syntax coloring /also/ has the
possibility to set the font.  By default, it's set to Dina-Regular-8.  But it
has no effect (!!).

However, /changing/ the value from the default does have an effect.  And
luckily, Dina 7pt and 8pt are exactly the same, since it's a bitmap font with
only three actual different sizes.  Changing every syntax category to
Dina-Regular-7 solves the problem.

Except!  Javadoc-style comments (beginning with ~/**~) still use the default
Monospace-10 font, and there's no syntax class to change it (!!!).  Removing the
second star changes it into a regular multi-line comment, which has syntax class
set to Dina.

And people shrug off Emacs...

* [2017-10-04 mer.]
** Syntax tryouts for VPDL                                         :emfviews:
Trying to feel natural, without redundant information.

In this one we move the contributing metamodels to the FROM, and allow a
shortcut syntax with brackets to select multiple attributes from the same
concept.  New associations are also moved to SELECT.

#+BEGIN_EXAMPLE
create view myEAviewpoint as

select togaf.EnterpriseArchitecture.*, togaf.StrategicArchitecture.strategicElements,
  togaf.BusinessArchitecture.processes, togaf.Process[processCritiality, isAutomated],
  togaf.Requirement.statementOfRequirement, togaf.Requirement.rationale, togaf.Requirement.acceptanceCriteria,
  bpmn.Process[isClosed, isExecutable, processType],

  togaf.Process join bpmn.Process as detailedProcess,
  togaf.Requirement join reqif.SpecObject as detailedRequirement

from 'http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' as togaf,
'http://www.omg.org/spec/BPMN/20100524/MODEL-XMI' as bpmn,
'http://www.omg.org/spec/ReqIF/20110401/reqif.xsd' as reqif

where togaf.Process.name=bpmn.Process.name and
 togaf.Process.isAutomated = 'false'
#+END_EXAMPLE

Here we declare concepts in FROM, metamodels in ON, and select individual
attributes in SELECT.

#+BEGIN_EXAMPLE
create view myEAviewpoint on
'http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' as togaf,
'http://www.omg.org/spec/BPMN/20100524/MODEL-XMI' as bpmn,
'http://www.omg.org/spec/ReqIF/20110401/reqif.xsd' as reqif

select tEA.architectures, tSA.strategicElements,
  tBA.processes, tP.processCritiality, tP.isAutomated,
  tR.statementOfRequirement, tR.rationale, tR.acceptanceCriteria,
  bP.isClosed, bP.isExecutable, bP.processType,

  tP join bP as detailedProcess,
  tR join rS as detailedRequirement

from togaf take
       Process as tP,
       EnterpriseArchitecture as tEA,
       StrategicArchitecture as tSA
       BusinessArchitecture as tBA,
       Requirement as tR
     and
     bpmn take Process as bP
     and
     reqif take SpecObject as rS

/* optional */
where tP.name=bP.name and tP.isAutomated = 'false'
#+END_EXAMPLE

Turns out, declaring the concepts is redundant, and using labels is less
readable.  So we go back to the bracket solution, but allow you to declare new
associations inside the brackets as well.

Labels could still be useful in WHERE, so we let you use AS there:

#+BEGIN_EXAMPLE
create view myEAviewpoint as

select togaf.EnterpriseArchitecture.architectures,
       togaf.StrategicArchitecture.strategicElements,
       togaf.BusinessArchitecture.processes,
       togaf.Process[processCritiality, isAutomated, join bpmn.Process as detailedProcess],
       togaf.Requirement[statementOfRequirement, rationale, acceptanceCriteria],
       bpmn.Process[isClosed, isExecutable, processType]
       togaf.Requirement join reqif.SpecObject as detailedRequirement

from
  'http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' as togaf,
  'http://www.omg.org/spec/BPMN/20100524/MODEL-XMI' as bpmn,
  'http://www.omg.org/spec/ReqIF/20110401/reqif.xsd' as reqif

/* optional */
where togaf.Process as tP and
      tP.name=bpmn.Process.name and
      tP.isAutomated = 'false'
#+END_EXAMPLE

** Next time                                                       :emfviews:
We should already be able to load an EViewpoint file in the Sample Ecore editor
and see the viewpoint.  Why is this not working yet?

Generate the weaving model from the ATL transformation.

Generating the matching model can wait.

* [2017-10-06 ven.]
** Loading an Eviewpoint in Ecore editor                           :emfviews:
Throws a NullPointerException because getContents returns virtualContents, which
at this point is null.

The sample editor does not try to load the resource before listing its contents,
strangely.

Ah, no.  It does attempt to load the Viewpoint first, but doLoad throws an
exception that is caught by EMF, which continues happily after that.

The exception is thrown because the TOGAF metamodel cannot be found.  Forgot to
open the TOGAF project!

When that is fixed, doLoad still fails because the weaving model is empty, which
is expected.

** Calling the ATL transformation in the code generation           :emfviews:
Was not too complicated (though ceremonious):

#+BEGIN_SRC java
var injector = new EMFInjector()
var factory = new EMFModelFactory()

var sourceMM = factory.newReferenceModel()
injector.inject(sourceMM, "http://www.inria.fr/atlanmod/emfviews/vpdl")

var targetMM = factory.newReferenceModel()
injector.inject(targetMM, "http://inria.fr/virtualLinks")

var sourceModel = factory.newModel(sourceMM)
injector.inject(sourceModel, r)

var targetModel = factory.newModel(targetMM)

var launcher = new EMFVMLauncher();
launcher.initialize(null)
launcher.addInModel(sourceModel, "IN", "VPDL")
launcher.addOutModel(targetModel, "OUT", "VL")
launcher.launch(ILauncher.RUN_MODE, new NullProgressMonitor(), new HashMap(),
  new URL("platform:/plugin/fr.inria.atlanmod.emfviews.vpdl/transformation/SQL2VirtualLinks.asm").openStream)

var extractor = new EMFExtractor()
// FIXME: return an outputstream or a string instead of hardcoding the path here
extractor.extract(targetModel, "platform:/resource/test-vpdl/src-gen/" + viewpointName(r) + ".xmi")
#+END_SRC

The hardest part was getting the path right... which I didn't solve yet.

But, Hugo suggested I use [[https://wiki.eclipse.org/ATL/EMFTVM][EMFTVM]] instead.

** Using EMFTVM                                                    :emfviews:
Apparently, I had a plugin for EMFTVM that came with the ATL install from the
regular Eclipse update site, but, after adding the line:

: -- @atlcompiler emftvm

to the top of the ATL file, I get the error:

"No compiler found for ATL emftvm.  You may need to install a compiler plugin"

So I tried using the snapshot version on the marketplace, with this update site:

: https://hudson.eclipse.org/shared/job/mmt-atl-master/lastSuccessfulBuild/artifact/releng/org.eclipse.m2m.atl.update/target/repository/

And there was an additional "ATL EMFTVM" feature.  I also have an "ATL EMFTVM
Compiler" plugin, and a bunch of other stuff.

After that, it compiled the ATL file to EMFTVM instead of ASM.

The ceremony to invoke the transformation is different this time:

#+BEGIN_SRC java
var factory = EmftvmFactory.eINSTANCE
var rs = new ResourceSetImpl()

var env = factory.createExecEnv();

// Load metamodels
var sourceMM = factory.createMetamodel()
sourceMM.resource = rs.getResource(URI.createURI("http://www.inria.fr/atlanmod/emfviews/vpdl"), true)
env.registerMetaModel("VPDL", sourceMM)

var targetMM = factory.createMetamodel()
targetMM.resource = rs.getResource(URI.createURI("http://inria.fr/virtualLinks"), true)
env.registerMetaModel("VL", targetMM)

// Load models
var sourceModel = factory.createModel()
sourceModel.resource = r
env.registerInputModel("IN", sourceModel)

var targetModel = factory.createModel()
targetModel.resource = rs.createResource(URI.createFileURI("platform:/resource/test-vpdl/src-gen/" + viewpointName(r) + ".xmi"))
env.registerOutputModel("OUT", targetModel)

// Run the transformation
var mr = new DefaultModuleResolver("platform:/plugin/fr.inria.atlanmod.emfviews.vpdl/transformation/",
  new ResourceSetImpl())

var timing = new TimingData()
env.loadModule(mr, "SQL2VirtualLinks")
timing.finishLoading
env.run(timing)
timing.finish

targetModel.resource.save(null)
#+END_SRC

But, unfortunately, even though the ~targetModel~ resource has been successfully
created in memory, the ~save~ call does not write the XMI file!

** Next time                                                       :emfviews:
Find out why the output model is not written.

Update the ATL transformation to get all the information from the VPDL.

* [2017-10-09 lun.]
** Writing the output model with EMFTVM                            :emfviews:
So, I'm calling:

: targetModel.resource.save(null)

And I've checked that the targetModel actually contains what I want.  It might
be an issue with the path of the file?

Well, I tried to trace the call, and it didn't seem to raise any error.

But then I don't even want to save to a file at this point, because I'd rather
use FileSystemAccess in doGenerate to write the file for me.  I just need to
write the model to a string:

#+BEGIN_SRC java
var out = new ByteArrayOutputStream()
targetModel.resource.save(out, null)
return new String(out.toByteArray())
#+END_SRC

which I found [[https://www.eclipse.org/forums/index.php/t/1070698/][here]].

** Updating the ATL transformation                                 :emfviews:
Fighting with ATL syntax to find out how to write what I want.  But I'm a
beginner, so that's expected.

References:
- https://www.eclipse.org/atl/atlTransformations/
- http://wiki.eclipse.org/ATL/User_Guide_-_The_ATL_Language

I've managed to generate the elements to be filtered, but now I've got to put
them in the WeavingModel class proper.

Unless I'm mistaken, it seems that ATL happily generates model that do not
conform to the specified target metamodel at all.  That there is no static check
for this, I understand, but no runtime checks as well?

** Next time                                                       :emfviews:
Complete ATL transformation

* [2017-10-10 mar.]
** Working on ATL transformation and grammar                       :emfviews:
Interesting point: when adding a new relation between A and B, both A and B
concepts must be included in the view, and not be filtered out, otherwise the
viewpoint creation fails.

Does it make sense?  It seems best that all concepts used by the viewpoint are
actually present in there, otherwise the view cannot conform to the viewpoint.

But does the user have to actually spell out explicitly which attributes they
want out of the concept?

Also, by default, it seems I have opted for the whitelisting mode, since it's
the most intuitive with the ~select~ syntax.  There could be syntax to reverse
it on a concept basis.

** Xtext goodies                                             :emfviews:xtext:
Tried to implement auto completion for classes, since we already have metamodels
and their namespace URI.  For some reason, this only works if I put the ~from~
section before the ~select~: then the metamodels are defined before we attempt
to look up things in them.  Otherwise, the metamodel reference in a
SelectFeature is a proxy that I can't seem to resolve, and the nsURI is null.

I also tried to implement a ScopeProvider for that (thinking that
auto-completion and validation would both come from implementing the scope
provider correctly).  But I would need to return EClasses, so I think I have to
change the grammar to make references to actual EClass, not my ad-hoc 'class'
thing.

** Fixing an exception when reloading the viewpoint in sample editor :emfviews:
I got UnsupportedOperationEx after clicking in the sample Ecore editor on the
viewpoint resource after the viewpoint file has been updated by the VPDL
generator.

Why?  Because it the editor calls Viewpoin.doUnload, which calls
getContents.clear(), which is unsupported.  Implementing it to clear our
virtualContents, and to rebuild them lazily in getContents does the job.

We can now refresh the contents in the sample editor with right click->Refresh.
This works fine for renaming stuff, but it seems the editor is confused when we
add/remove children.  We may have to build our own viewer in the end.

One feature that would be nice would be to have different colors for virtual
associations when loading a Viewpoint in the sample Ecore editor.  Maybe this is
feasible by providing a custom label provider or something?

** Next time                                                       :emfviews:
Try to get the validation/completion working by tweaking the grammar.  If
unsuccesful, ask around.

* [2017-10-11 mer.]
** Validation and completion with Xtext                      :emfviews:xtext:
So, I'm trying to use [[http://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html#scoping][scoping]] for that.  It seems the default implementation is
useful.  E.g., for the metamodels in the From clause:

#+BEGIN_EXAMPLE
from
  'http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' as togaf,
  'http://www.omg.org/spec/BPMN/20100524/MODEL-XMI' as bpmn,
  'http://www.omg.org/spec/ReqIF/20110401/reqif.xsd' as reqif,
#+END_EXAMPLE

If I do:

: select tof.Bar.none,

then it will:

1. Recognize ~tof~ as invalid, because it's supposed to be one the Metamodel
   from the ~From~ clause.
2. Suggest as quick-fixes to use either ~togaf~, ~bpmn~, or ~reqif~, which is
   exactly what I want.
3. Autocompletion also works outside of the box, as it only suggests the
   metamodels declared in the ~From~ clause.

Stepping through the code, the quick-fix suggestions are gathered from a default
ScopeProvider implementation.  Curiously, it only works if there are 5 or fewer
suggestions:

#+BEGIN_SRC java
if (discardedDescriptions.size() + addedDescriptions <= 5) {
  for(IEObjectDescription referableElement: discardedDescriptions) {
    createResolution(issueString, referableElement, ruleName, keyword, caseInsensitive);
  }
}
#+END_SRC

The discarded descriptions are those that are not similar enough.  So if I have
6 contributing metamodels, then I get no quick-fix suggestion anymore.
Auto-completion stills suggests the right things though.

Okay, so after input from Massimo, it turns out that auto-completion works when
we remove the two alternatives in this rule:

#+BEGIN_EXAMPLE
SelectFeature: metamodel=[Metamodel|ID] '.' class=ID '.' features+=Attribute
  | metamodel=[Metamodel|ID] '.' class=ID features+=Relation
  | metamodel=[Metamodel|ID] '.' class=ID '[' features+=Feature (',' features+=Feature)* ','? ']';
#+END_EXAMPLE

The issue seems to be that Xtext is confused somehow by the fact the same
reference feature appears in multiple variants.  Or the ambiguity of rule is
enough to throw Xtext off the rails?

Strangely, this parses just fine, and the model builds without any issue.

Factoring the commong prefix:

#+BEGIN_EXAMPLE
SelectFeature: metamodel=[Metamodel] '.' class=[ecore::EClass] rest=SelectFeatureRest;

SelectFeatureRest: '.' features+=Attribute
  | features+=Relation
  | '[' features+=Feature (',' features+=Feature)* ','? ']';
#+END_EXAMPLE

makes completion works.  Sort of.

I actually just implemented the ScopeProvider, and auto-completion appears to
work automatically from the default generated code.

When I type:

: togaf.|

and trigger auto-completion, then I get nothing.  However, if I do:

: togaf.a|

then I get a bunch of classifiers, beginning with 'A'.

If I now put the cursor back:

: togaf.|a

then I get all the classifiers in the TOGAF metamodel.

Auto-completion works for metamodel names, which do not benefit from my own
version of ScopeProvider.

Maybe I need to override the default auto-completion behavior to capture just
these cases?

** Next time                                                       :emfviews:
Make auto-completion work perfectly.

After that, wildcards?  I would need to go back on the weaving model though...

Or take a look at generating a proper ECL file.

* [2017-10-13 ven.]
** Creating a View from a VPDL-generated viewpoint                 :emfviews:
I should just have to create an eview file, give it the viewpoint and three
models, and it should work, right?

First ordeal: relative paths do not work here, although they work in the tests.

Second ordeal: the sample reflexive editor cannot cast VirtualEClass to
EClassifierExtendedMetaData.Holder.

Then VirtualEReference cannot be cast to
... EStructuralFeatureExtendedMetadata.Holder!

After that, it loads.  Hmm except I'm still struggling with paths for loading
the ECL.

Hardcoding it to see what we get...  Yep, the View loads, but there are lots of
unforeseen consequences of filtering.

The editor throws a bunch of UnsupportedOperationException due to things I've
not implemented in VirtualEClass/VirtualFeature...  implementing now.

Strange thing: attributes have no name, because presumably the name feature is
an inherited one, and not filtered in.  Even when filtering in the feature from
the parent class, the name does not appear in the editor picked up.

References to objects cannot be followed, as the objects do not appear if their
containers are not filtered in, and recursively.

I'm not sure if we should solve the problem by including the container
implicitly... No, that's almost always the wrong approach.

Rather, the user should include the attributes themselves.  However, doing that
seems to have no effect.

** Next time                                                       :emfviews:
Resolve the filepath issue with the ECL delegate.

Figure out how the sample Ecore editor determines a name for something?  Because
maybe we could provide our own label editor rather than rely on the default one.

The bigger issue to resolve is: how to make an inherited attribute appear in the
sample Ecore editor?

And/or, how to filter it in using VPDL?

* [2017-10-16 lun.]
** Fixing paths in ECL delegate                                    :emfviews:
So, I've got a string supposedly pointing to a matching model file, as a
'platform:/resource' URI.  Then, I want to open that file using the java.io.File
API.  How hard can that be?

Seems EMF has no issues opening resources when an EMF URI is created using this
platform URI scheme.

Okay, so I got it with:

#+BEGIN_SRC java
IContainer wsroot = ResourcesPlugin.getWorkspace().getRoot();
IFile ifile = wsroot.getFile(new Path(URI.createURI(filePath).toPlatformString(true)));
File f = new File(ifile.getLocationURI());
#+END_SRC

That's a lot of objects, but whatever.

I'm wondering though, it seems this assumes that an EView file will always
contain platform URI?  What if we want to specify any kind of URI, and
especially, ~file:~ directly?

Looking into URIConverter and what EMF does when I try to load a resource from a
relative URI:

: new ResourceSetImpl().getResource(URI.createURI("foo.xmi"), true)

getResource is supposed to look in the already loaded resources for the resource
set and return it.  If not, it creates and loads the resource.

To find the resource, it normalizes the URI using the URIConverter.

I got an ExtensibleURIConverterImpl instance for the resource set used by
Viewpoint.  Here is what it does on a relative URI:

#+BEGIN_SRC java
if (scheme == null)
    {
      if (workspaceRoot != null)
      {
        if (result.hasAbsolutePath())
        {
          result = URI.createPlatformResourceURI(result.toString(), false);
        }
      }
      else
      {
        if (result.hasAbsolutePath())
        {
          result = URI.createURI("file:" + result);
        }
        else
        {
          result = URI.createFileURI(new File(result.toString()).getAbsolutePath());
        }
      }
    }
#+END_SRC

It constructs a file URI only if there is no workspace root, i.e., we are not
running inside Eclipse.  Otherwise, it constructs a platform resource URI, but
/only/ if it's absolute, i.e., begins with ~/~.

If it's relative and you are inside Eclipse... tough luck.  It returns the URI
as-is.

I think the intent is clear: in the Eviewpoint file, if the path is relative, it
is relative to the location of the EViewpoint file on the file system.
Otherwise... let EMF handle it.

Hmm, but if do that, and resolve relative paths in the Eviewpoint and Eview
files with the Viewpoint/View as a base, the test fails.

Because in the tests, I give relative paths for the Viewpoint and View
resources.  And EMF is happy to construct them.  But they can't be used to
resolve other URIs.  In fact, the docstring to Resource.getURI states that the
URI should be hierarchical and absolute.

So maybe I have to fix my tests... but that is very convenient to be able to
pass a project-relative path as URI for the resource.

Easiest fix would be to test if the resource URI is in fact hierarchical and
absolute.  This works without needing to change the tests.

But then, if I use a relative path inside an Eviewpoint, it cannot be resolved.
That's dumb.

So the issue is to find the actual, absolute location of the Resource, and
resolve relative paths from that.  If there is no absolute location for the
resource, then we cannot resolve relative paths.  Simple as that?

** Next time                                                       :emfviews:
Solve out this paths issue.

* [2017-10-17 mar.]
** Constructing a VPDL for a coherent model                        :emfviews:
The current VPDL example I'm using is incoherent: targets of references point to
nowhere, because we haven't included them in the metamodel.

We could include such targets implicitly, as syntactic sugar.  Or we could catch
such errors in the validation phase for the VPDL and have the user write them
out.

But first of all, I should be able to manually build a VPDL that gives us a
coherent view.

First mystery: where are the BPMN instances?  I see ReqIF and TOGAF, but not
BPMN.

Although, there is a strange annotation.  Could that be it?  When I open the
BPMN model, it has custom icons in the TreeViewer... it may be related.

I traced the creation of the labels in the Sample Reflective Editor to
org.eclipse.emf.edit.ui.provider.DecoratingColumLabelProvider.

Which calls org.emf.edit.ui.provider.AdapterFactoryLabelProvider.getText.

With a BPMN object (DefinitionsImpl), it fails to adapt to a label provider, and
just uses toString.  On ReqIF and TOGAF instances, it gets a
ReflectiveItemProvider which prints the EClass name followed by the "label"
feature, which is determined by the following code:

#+BEGIN_SRC java
protected EStructuralFeature getLabelFeature(EClass eClass)
 {
   EAttribute result = null;
   for (EAttribute eAttribute : eClass.getEAllAttributes())
   {
     if (!eAttribute.isMany() && eAttribute.getEType().getInstanceClass() != FeatureMap.Entry.class)
     {
       if ("name".equalsIgnoreCase(eAttribute.getName()))
       {
         result = eAttribute;
         break;
       }
       else if (result == null)
       {
         result = eAttribute;
       }
       else if (eAttribute.getEAttributeType().getInstanceClass() == String.class &&
                result.getEAttributeType().getInstanceClass() != String.class)
       {
         result = eAttribute;
       }
     }
   }
   return result;
 }
#+END_SRC

A "name" feature, or the latest feature of type String, or the latest feature.

When I open the BPMN model in the sample editor, then the adapter factory finds
a DefinitionsLabelProvider.

So, how does that factory works?

In adapt(DefinitionsImpl), the delegateAdapterFactory is
Bpmn2ItemProviderAdapterFactory.  Then it calls this factory to adapt the
DefinitionsImpl into a DefinitionsItemProvider.

Now, when opening the view, the delegateAdapterFactory is still
Bpmn2ItemProviderAdapterFactory.  And this time it returns null.  But I don't
have the code -_-

But I think what's going on is that the adapter factory tests checks for
instances of metamodel objects, and VirtualEObject isn't one of them.

Indeed, when stepping, we end up in the default case:

#+BEGIN_SRC java
public Adapter createEObjectAdapter() {
    return null;
}
#+END_SRC

Since the adapter factory has already been chosen, it won't fall back on the
ReflectiveAdapterFactory, and we have a dumb toString.

So one solution is to force it to use the ReflectiveAdapterFactory.

I tried to add the ReflectiveItemProvider to the adapters of virtual objects,
and it works if I cheat a bit:

#+BEGIN_SRC java
eAdapters().add(new ReflectiveItemProvider(null) {
  @Override
  public boolean isAdapterForType(Object type) {
    return true;
  }
});
#+END_SRC

this forces the ReflectiveItemProvider to be used in lieu of the Bmpn2 adapter.
That way I can load the BPMN model elements just fine.

This is not the proper way to fix this however, because forcing an adapter for
the Ecore editor has nothing to do in the core of EMFViews.

It seems we have to define our own editor for views, which could just use the
stuff that's already implemented and available from EMF.edit.

* [2017-10-18 mer.]
** Virtual objects and switches generated by EMF                   :emfviews:
The trouble with that BPMN item provider seems to stem from the default BPMN
switch implementation which does not recognize virtual objects.

When we fall into the switch, it's because we didn't find any adapter that
matched in the adapter factory.  Then the generated switch implementation is:

#+BEGIN_SRC java
protected T doSwitch(EClass theEClass, EObject theEObject) {
    if (theEClass.eContainer() == modelPackage) {
        return doSwitch(theEClass.getClassifierID(), theEObject);
    } else {
        List<EClass> eSuperTypes = theEClass.getESuperTypes();
        return eSuperTypes.isEmpty() ? defaultCase(theEObject) : doSwitch(eSuperTypes.get(0),
                theEObject);
    }
}
#+END_SRC

The first test fails, because our virtual objects are in a virtual package,
which is not the BPMN2 package.

Somehow, EMF has all these patterns about making things ultra-modular and
flexible, but they use reference equality which we cannot override through
subclassing.

So virtual objects cannot be used by switches in the default implementation,
as-is.  I'm not sure there's a nice way to make them compatible.  Using AspectJ
would work...

Anyway, I think I need to implement our own viewer in any case.  Since hacking
VirtualEObject to work the BPMN2 case is not a good idea.  And I would like to
have instant refresh of views/viewpoints when the resources changes as well.

But for now, I want to fix the tests so that relative paths work.

** Fixing relative paths in tests                                  :emfviews:
And making sure they work with VPDL.

I think the issue is that, when resolving the relative paths with the Viewpoint
URI as base, I'm assuming the Viewpoint URI is absolute.  This is not the case
in the test.  However according to the docstring, this is an abuse on my part.

But since EMF doesn't actually enforces this restriction, maybe the more robust
solution is to find out where the Viewpoint is actually located on the
filesystem (since it has been opened, after all).

But maybe that wouldn't work with other kinds of URIs?

Okaaaay.  I think I got it right this time.  I gave absolute paths to Viewpoint
and View in the tests, and I think I accepted relative paths anywhere relevant.
Still have to write tests though.

Added tests.  Found bugs.  Moving on.

** Next time                                                       :emfviews:
Need to write my own TreeViewer for View/Viewpoint.  We may have some code in
the ui plugin already.

* [2017-10-20 ven.]
** Writing our custom viewer                                       :emfviews:
I've got a basic editor going on.  At least it shows us BPMN instances out of
the box.  No icons, no thrills.

- should reload dynamically when the file changes

I may have found how the BPMN adapter factory registers itself to EMF: the
extension point

: org.eclipse.emf.edit.item.itemProviderAdapterFactories

This may allow us to give an adapter factory for VirtualEObjects.  Need to
check.

Spent a long time figuring out how to get the properties working... for some
reason.  In the end I'm not quite sure what I did wrong.  I fiddled with it
until, somehow, it worked.

** Next time                                                       :emfviews:
Make a coherent VPDL file.

See if we can plug our own adapter factory for VirtualEPackage/VirtualEObject.

* [2017-10-23 lun.]
** Making a coherent VPL                                           :emfviews:
There are indeed a bunch of stuff we have to explicitly include if we want to
see anything in the view.  And finding out what to include is not an easy
process.

An "auto" mode that implicitly includes containers for instance would be great.

I managed to build a coherent VPDL.  There are still some references missing,
but I guess they shouldn't even be in the view to begin with.

** Next time                                                       :emfviews:
Investigate why including one attribute from a parent actually displays /all/
features in the subtypes.

Look into using the adapter factory mechanism for EMF.

* [2017-10-24 mar.]
** First day                                                       :megamart:
*** TEK use case
Ultra-wide band positioning.

Use hardware emulators for testing.  They want to not have to write the
emulators in order to create the tests.

Issue with team collaboration when changing models used by other models.

*** IKER use case
Product: smart warehouse supervision system.

Problems: physical and logical failures.

Use modelling and want to use modelling for code generation, versioning, and
tracking model changes.

*** NOK use case
Product: Nokia Pico Base Station.

Want continuous feedback in their development process.  300-400 persons working
on the same project.

Want: versioning of models (branches, delta view for traceability of features)

Want: Feedback in model, as in integrating runtime data back into models.

Focus on real-time UML modeling.  (UML RT is a UML profile tailored to real-time
and embedded systems).

*** Bombardier use case
Train producer.

Need coordination between different types of trains (electric, high-speed,
local, ...) and over distributed teams.

Current workflow: functional requirements, UML/SysUML models. then test, then
generation to C code, and more tests.  These are done by different teams,
different persons.  Opportunities for loss of signal.

Ideally, they want to refine models between each steps.  E.g., refine software
requirements refined from the functional requirements, rather than writing the
former by eyeballing the latter.

Technos: Simulink, SysML, SIL2.

*** CSY use case
Coppilot platform screen door control.  Screen doors like in the M14 line in
Paris: they are the doors on the train platform, not the doors of the train.

They must open when the train doors open, close when the train doors close, etc.

The safety-critical parts were created with a B model, and are not modifiable
anymore, apparently.

They have troubles with keeping track of logs, especially for network usage.
They want to aggregate logs at runtime whenever nodes are idling.

*** AINA use case
Product: SMS gateway.

Want: methods and tools for run-time analysis, to find out root causes.  (Is
that realstic?)

*** Volvo use case
Specifically: Volvo Construction Equipment branch, which manufactures machines
for construction.

Need traceability from requirements to the runtime, possibly with feedback from
runtime data back to requirements.

Technos: UPDM, SysML, Simulink.

*** Thales
Product: Flight Management System.  This is the system that computes a flight
plan according to localization information gathered by sensors.  This flight
plan can be used by the guidance sub-system for autopilot, or its information
can be used by the human pilot.

Need: earlier verification, reduce risk of costly errors.  (Don't we all?)

Hard requirements:
- every command instructed by the pilot to the system shall have a visual
  display in less than 1s.
- new flight plan should be computed in 3sec or less.

Want: tools that estimate the worst time in a simulation, and report the causes
of deadline misses to the designer.

Technos: Capella

*** Architecture presentation by Andrey
They harvested the requirements and the tool interfaces and put that into
models.  So they can track what kind of format the tool expects, what format
they output, and requirement providers could peruse this info to synchronize.

* [2017-10-25 mer.]
** Second day                                                      :megamart:
*** Hugo: work package 4
On global model & traceability management.

Goal: link WP2 (design time models) and WP3 (run time traces and logs)
together.

Upcoming deadline: architecture report (waiting on WP2 and WP3).

Tools in WP4:
- Modelio Constellation (Softeam)
- EMF Views
- AM3/MoScript (legacy)
- NeoEMF
- JTL (traceability)
- PADRE (anti-patterns detection)
- MDEForge (repository solutions for models)

Interfaces in WP4:
- model storage,
- model versionning,
- model access control,
- model query,
- model cartography,

Still open questions about traces between design-time and run-time models: need
more use info from use cases.

Volvo guy: focus more on methodologies.  They want to use views and viewpoints,
but they need more info?

Guy 1: if we have tools first, then we can build the methodology.

Industry Guy: methodology is more important than the tools.

Guy 1: if we have matched use-cases to tasks first, then we can build the
methodology.

Guy 2: as a company, would you prefer a complete tool, or to change your whole
methodology?

Industry Guy: things will evolve, so we'd rather support a methodology than a
specific tool that would become obsolete, and is more rigid.

Hugo: how do use case providers feel about filling a questionnaire about what
models you use?

Room: [silence]

Hugo: okay so we'll do that.

*** Orlando (ATOS): WP5
They are in charge a making a framework bundling most of the tools.

Principles: we should try to orchestrate version pinning so it's transparent to
the users.

Use loose coupling and asynchronous messaging: interact with publish/subscribe,
message queues rather than direct API calls.

There should be a joint release of tools bundled in the framework at M22
(initial release) and M36 (final release).

Hugo: will the framework include documentation on the processes (methodologies)?

Orlando: no, that's not our responsibility.

Bombardier gal: we are really missing info about processes.  What you should
model, how you should model, how you can validate the model.

Hugo: even if it's not the responsibility of WP5, the info should be reflected
in the framework

[more back and forth]

Orlando agrees to include information about methodologies in the framework

*** Gunnar: WP7 administration stuff
All partners need to sign an agreement of acceptance for joining Artemis.

Gunnar says European money won't come until the PCA (consortium agreement) is
signed by all partners.

For some countries, national funds won't be unblocked before the PCA either.

On the continuous reporting portal, we should:
- report the number and gender of researchers involved
- update any relevant risks
- make sure publications are visible, but don't edit directly the tab (contact
  Clara or Gunnar?)

Planning of next meetings:
- April 2018 in Finland (city not determined yet)
- May 2018 Brussels (first review, not plenary)
- October 2018 France?
- ...rest unclear

Local partners should decide exactly on the location, venue, week, and cost.

Suggestion: draw up a list of probable locations with full costs, and let other
partners take a look.

Gunnar is not convinced.

Clara insists.

** Trying to preserve the state of tree viewer when refreshing     :emfviews:
I got refreshing to work on right-click.  It's already not bad and more reliabe
than the sample editor.

Apparenty using the expand* methods is useless.  But using setExpandedState
works.

The main issue with preserving the open state is that currently I'm rebuilding
the whole resource, and all the virtual objects are re-created anew.  So, how
can we match the new virtual objects to the previous ones?

If we use numbers, then it breaks when a node is added or removed between
updates.  We can't use names, because some nodes don't have any.

So we need to determine an ID that should be preserved between updates.  Note:
we only need nodes that bear children to have consistent IDs.

* [2017-10-26 jeu.]
** Third day                                                       :megamart:
*** Wrap-up
Tool provides should set up meetings/demos with use-case providers.  These
meetings should be synchronized at the work package level.

WP4 task: writing a survey to find out what models are used by use-case
providers, in what amount, etc.  Share with other work packages.

Dragos: also, focus on methods, not just tools.

Bombardier girl & Volvo guy: yes.

* [2017-11-13 lun.]
** Back in the saddle                                              :emfviews:
So I was working on a custom EView editor, for two reasons:

- the sample Ecore editor does not handle refresh from resources graciously
- a custom EView editor could indicate synthetic elements with a different color

Currently, the EView editor has basic functionality.  What to improve:

- the presentation in the "Properties" tab is a bit lacking.  Although it allows
  for expanding references inline.
- One issue in the "properties" tab is that I'm not quite sure to understand why
  some properties are present.  It looks like inherited properties are present,
  sometimes?  Investigate.
- auto-refresh from resource change as an option
- add button for manual refresh from resource

A thorny issue is how to preserve the state of opened nodes when reloading the
resource.  I think it amounts to making a diff of the trees.  But we could get
by with a simple hash function that preserves identity between resource reloads.

Another path I've yet to explore is to use an adapter factory to provide the
sample Ecore editor with our own info on the Eview.  But now that I'm looking at
it again, it seems the sample Editor has no issue opening up a viewpoint or
view.  So this might not be necessary.

Also, test with the Modisco browser to see if it works.

Before working on Eview, my task was to improve the VPDL language.  Still left:

- create a full, coherent VPDL file
- see if we can make containing references implicit
- the ECL part is still untouched
- auto-completion only works after we give one letter

But for the short term, we established that I should first plug the metamodel
extension language to the new weaving model.

After that, if I have time, I should look into the ECL part of the VPDL.

** Plugging the metamodel extension language                   :emfviews:mel:
Generated a new project with the old grammar.  Added a simple example file.
Seems to work.

Now to generate the weaving model with ATL.

Things I noted while sketching out the ATL transformation:

The namespace URI of the contributing metamodels is never provided.  Need to
extend the grammar.

The weaving model supports specializing a virtual concept, but with the current
syntax:

: add class Y specializing uml.C

It's unclear how we could know in the ATL transformation whether the parent
class is virtual or concrete.  Maybe if it doesn't have a prefix, it's virtual?

I should generate an Eviewpoint file alongside the weaving model.

The syntax:

: extending UML:uml, BPMN:bpmn

does not actually tie the metamodel to its prefix in the parsing model (unless
the order of addition in containments references is deterministic).

There's renaming to be done in the grammar.

As I did not want to touch the grammar just yet, but still wanted to generate
the Generalize clause correctly, it resulted in this gem:

#+BEGIN_SRC atl
subConcepts <- s.prefix->iterate(p; tu : OclAny = Tuple{idx=0, concept=Sequence{}} |
            Tuple{idx = tu.idx + 1,
                  concept = tu.concept->append(thisModule.LazyRule(p, s.class.get(tu.idx)))
             }).concept
#+END_SRC

Just to be able to get the corresponding element from the ~s.prefix~ and
~s.class~ lists.  A zip would have been more elegant, but it's not in the
language.  For a one-shot, might as well use an accumulator to populate a list
and keep track of the current index.

Have to fix the grammar.

* [2017-11-14 mar.]
** Working on MEL                                              :emfviews:mel:
On AddProperty, the type probably shouldn't be optional.

I'm not sure what ModifyProperty is for.  The example

: modify property propertyC attribute="name", value="propertyC2"

is not very telling.

Oh wait, I think I get it.  It modifies the name of the propertyC to be
propertyC2 instead.  Ok.

Well, that's a bit too open unfortunately.  We should either fix what we can
modify on an attribute in the language, or remove this construct.  Besides
changing the name, we could change the cardinality, or the type.  Is there
anything else?

Also, this raises the question: what happens to models that use this property?
We should probably update the models to display the value for "propertyC" under
"propertyC2" now.

So, modifying a property would not be functionally equivalent to filter+add in
this case, because the latter would not have this explicit link preserved at the
model level.

* [2017-11-15 mer.]
** Further work on MEL grammar/syntax                          :emfviews:mel:
We could Constraint as annotation?

Reworked the grammar a bit to use namespace URIs.

But now concrete concepts are not unique anymore in the weaving model after the
transformation.

* [2017-11-16 jeu.]
** Setting up new machine                                              :dell:
A Dell Latitude 7480.

First gotcha: Arch does not see the nvme drive when booting in UEFI.  Legacy
mode works fine.

Switching the SATA configuration from RAID to AHCI fixes it (but breaks
windows).

After that, it seems the D6000 universal dock is badly supported.  I followed
the [[https://wiki.archlinux.org/index.php/DisplayLink][wiki]] and installed the displaylink and evdi-git AUR packages.  The display
ports work: the monitors are recognized by xrandr, and I can use both of them.
However, there is unbearable lag on the monitors.

This seems to be a known issue.  I tried switching drivers (without being sure
that I had succeeded), and turning off Vsync (but with glxgears always reporting
that it was on...).  No success so far.

My best bet would probably be to use the HDMI output for one screen, and the
USB dongle for the other HDMI screen.

The dock can still be useful for the ethernet and USB ports.

** MEL progress                                                :emfviews:mel:
Can't specialize and supertype at the same type when creating a new class.  Is
this useful?  I don't know, but the grammar does not support it, although the
weaving model does.

Solving the uniqueness of concrete concepts: this worked when I used a unique
lazy rule with the tuple (metamodel, name) as argument.  From my understanding
of ATL, the fact that it's unique will ensure that each tuple (metamodel, name)
will always produce the same output (concreteConcept).

If I pass a TargetClass instead as argument to the rule, then for different
target class instances which have the /same content/, I get different outputs:

: TargetClass1 (uml, A) -> ConcreteConcept1 (uml, A)
: TargetClass2 (uml, A) -> ConcreteConcept2 (uml, A)

So the lazy rule has to stick to the contents of the target class.  But since
that's a little verbose to call, I added a helper:

#+BEGIN_SRC atl
helper context MEL!TargetClass def : toLink : VirtualLinks!ConcreteConcept =
	thisModule.ConcreteConcept(self.metamodel, self.name)
;

unique lazy rule ConcreteConcept {
  from m : MEL!Metamodel, name: ECORE!EString
  to   t : VirtualLinks!ConcreteConcept (
      model <- m,
      path <- name
  )
}
#+END_SRC

Aaaargh.  Another issue with dupes.  The problem is that I have duplicates of
VirtualConcepts now.  One 'add class A' statement will create a VirtualConcept A
in the transformation, but I can also use that new class as a target for a new
association.  In this case, the association need to refer to the virtual
concept, but not create it.

I think I found a way to solve it by finding the corresponding AddClass
declaration.

Ah yes, it works.  I can only have one rule for creating classes though.  But
that's more flexible that way anyway.

** Next time                                                   :emfviews:mel:
Cardinality for reference.

Tackle modify property.

* [2017-11-17 ven.]
** Another look at the new machine                                     :dell:
*** Second take on the DisplayLink issue                        :displaylink:
: pacaur -S displaylink

Requires evdi>=1.5, but package is evdi 1.3.  Using evdi-git:

: pacaur -S evdi-git

Succeeds after kernel headers are installed.

After that, installing displaylink works.

: systemctl start displaylink


Regarding the display link: noticeable lag using the modesetting driver just by
moving the mouse cursor around and selecting stuff in Firefox.  No perceivable
lag in urxvt.  Small lag doing the same things in Emacs.

Now, playing a video on the screen and the video plays fine but the mouse lag is
pretty bad.

No lag when doing the same thing on the laptop screen.

The whole hub also disconnected and reconnected itself without me touching it.
Though the USB-C connector looks flimsy.

Same lag with PageFlip off.

Also,

: env vblank_mode=0 glxgears

reports ~627FPS on the laptop monitor, and ~510FPS on the displaylink monitor.

Let's try the Intel driver.

glxgears reports ~584FPS on laptop monitor.

Displaylink looks like it refuses to work with the intel driver actually.  That
matches with the info on the wiki (except the suggested workaround does not
work).

Well, so that's it then.  Displaylink driver is garbage for linux.  I'm not
plugging my screens this way.

No noticeable lag when plugging the monitor via VGA using an USB-C dongle (also
with ethernet plugged-in).

*** Disabling the PC speaker
Wow, somehow there is a PC speaker on that thing, and it's really loud.
Blacklisting:

: blacklist pcspkr

in /etc/modprobe.d/nobeep.conf

*** Emacs and hi-dpi                                              :emacs:dpi:
Emacs seems to obey the dpi argument to startx just fine:

: startx -- -dpi 120

Using xrandr also works:

: xrandr --dpi 120

but you have to restart the application to see changes.

Although, the only thing that gets scaled is the text size, not the interface.

Well, the toolbar and menu bar can be scaled with:

: env GDK_SCALE=2

Though the tooltips are off by a large amount.

But the fringe stays the same size, regardless of all these settings.

In any case, even if the fringe scaled, all the regular images inside are
bitmaps, so they would need high-resolution versions to go along.

*** Multiple monitors and hi-dpi                                        :dpi:
Also, I have a (mid) high-DPI laptop screen and regular DPI monitors.  The [[https://wiki.archlinux.org/index.php/HiDPI][wiki]]
suggests to use the scale option of xrandr.  But scaling means a blurry output,
which is also unacceptable.

So I guess when I use the laptop alone I can set the dpi to 144 to be
comfortable (but then I have to switch to a TTF font in Emacs and in the
terminal).  But when plugging the external monitors I should stick to 96 DPI and
forego the laptop screen.

This, unfortunately, is not easy to change dynamically, since some applications
require to be restarted after a DPI change.  And Firefox for instance does not
listen to the X server DPI settings, but to the Xft.dpi resource value.

This period between ubiquitous 96 DPI and ubiquitous 300 DPI has more annoyances
than benefits.
** MEL improvements                                            :emfviews:mel:
Handled cardinality.

Added scoping for class names, so now we get validation and auto-completion for
free.

We could do the same for properties, but I haven't gotten back to modify the
syntax for modify property yet.

Opening the eviewpoint file now... and it seems to work!  I see the new classes,
the new properties.

There is a strange bug though, if I do:

: add class Z supertyping uml.Activity, uml.Action

and later:

: modify class uml.Activity

then loading the viewpoint fails because uml.Activity cannot be found.  When
debugging, I see that it's only the second search for uml.Activity using
EMFViewUtil.findElement that fails to find it.

So not using the same class twice makes the viewpoint loads without issues:

: modify class uml.Behavior

Probably related: the Behavior classifier is nowhere to be found, even though it
was never filtered.  If I write:

: modify class uml.Behavior {
:   filter property propertyB
: }

Then the Behavior classifier is absent.  If I remove the "filter property" line,
then the classifier appears.  Something funky in the filtering algorithm when
the property does not exist.

* [2017-11-20 lun.]
** Fixing the filter property bug                              :emfviews:mel:
Okay so the bug was on the ATL transformation side.  I told the weaving model to
filter the Behavior class, instead of the Behavior.propertyB feature.

It's a bit of a hassle to do in ATL, because I have again to use a unique lazy
rule to ensure that there are no duplicate filters.  But hey, bug fixed.

** About the duplication in the ATL transformation         :emfviews:atl:mel:
I think the pattern I've encountered boils down to this.  The source model has
'add attributes' elements contained in a 'modify class':

- modify class A
  - add attribute P
  - add attribute Q

and the target model needs one element for each 'add attribute', that refer to
the same class A.  So:

#+BEGIN_SRC atl
rule R {
  from s : IN!AddAttribute
  to
  t : OUT!NewAttribute (
    name <- s.name,
    class <- class
  ),

  class : OUT!ReferredClass (
    name <- s.refImmediateComposite().className
  )
}
#+END_SRC

This won't work, because it will generate two instances of 'ReferredClass A'.

Instead, here, we can clearly have to matched rules:

#+BEGIN_SRC atl
rule R {
  from s : IN!ModifyClass
  to   t : OUT!ReferredClass (
    name <- s.className
  )
}

rule R2 {
  from s : IN!AddAttribute
  to   t : OUT!NewAttribute (
    name <- s.name,
    class <- s.refImmediateComposite()
  ),
}
#+END_SRC

No duplicates, as R is matched only once, and the links are taken care of in R2.

So this is not the issue I'm having.  My problem is that the class A can be
referred to in other places, like:

- modify class A
  - add attribute P
  - add attribute Q
- modify class A
  - add attribute R
  - add attribute S

and I want, as a target:

- new attribute P
  - parent -> A
- new attribute Q
  - parent -> A
- new attribute R
  - parent -> A
- new attribute S
  - parent -> A
- referred class A

Now, if I'm using the two-rules solution above, 'ReferredClass A' will appear
twice in the target model, which I don't want.

Instead, I'm doing:

#+BEGIN_SRC atl
rule R {
  from s : IN!AddAttribute
  to   t : OUT!NewAttribute (
    name <- s.name,
    class <- thisModule.R2(s.refImmediateComposite().className)
  ),
}

unique lazy rule R2 {
  from name : ECORE!EString
  to   t : OUT!ReferredClass (
    name <- name
  )
}
#+END_SRC

Now, for each AddAttribute, I have a corresponding NewAttribute, which has the
correct link to the class.  But the class is generated only once, since the rule
is unique.

I'm suggesting that instead of having to use the lazy rule, I keep using the
solution with two matched rules, but somehow I can tell ATL that rule R should
only match for distinct ModifyClass.className.

Asking around, Massimo suggested this:

#+BEGIN_SRC atl
rule R {
  from s : IN!ModifyClass
   (s = s.getRepresentative())
  to   t : OUT!ReferredClass (
    name <- s.className
  )
}

rule R2 {
  from s : IN!AddAttribute
  to   t : OUT!NewAttribute (
    name <- s.name,
    class <- s.refImmediateComposite().getRepresentative()
  ),
}
#+END_SRC

The key part being restricting the match of R using the guard:

: (s = s.getRepresentative())

#+BEGIN_SRC atl
helper context IN!ModifyClass def: getRepresentative(): IN!ModifyClass =
	IN!ModifyClass.allInstances()->select(c | c.className = self.className)->first();
#+END_SRC

** Further MEL improvements                                    :emfviews:mel:
- Multiple inheritance
- Validation of property names
- Implement 'modify property'

Out of scope for now: making sure that we are not adding duplicate properties or
classes.

I thought the command:

: add class B specializing Y and supertyping Z

would work, but it doesn't.  I'm not seeing in the grammar why it shouldn't
work.

Oh rightn.  There's no need for that "and" in there.  Silly me.  Were I of bad
faith, I would say the default parsing error did not help me in locating the
error.

Anyway, multiple inheritance now.  Yep, that works as well.  It even allowed me
to get rid of that ugly condition masking the lack of option type in ATL:

#+BEGIN_SRC diff
-        superConcepts <- if s.parent.oclIsUndefined()
-                        then Sequence{}
-			 else Sequence{s.parent.toLink()}
-			 endif,
+        superConcepts <- s.parents->collect(e | e.toLink()),
#+END_SRC

Fixed a couple of bugs with the EView editor.  Forgot to implement the ID
feature for attributes in VirtualEAttribute.dynamicGet.  This also affected
other viewers, of course.

There is still an issue when wanting to print the value of the eFactoryInstance
attribute for EPackages.  It currently throws as unimplemented, because I still
don't know what to provide, if anything.  I guess we could provide a factory
that does... nothing?  Or throw when you want it to actually create instances?

Hmm so about that modifyProperty clause.  It seems to me the most natural way of
writing it would be so:

#+BEGIN_SRC
modify class bpmn.Activity {
  modify property propertyC {
    name propertyC2
    type X
    cardinality 0..1
    relation type association
  }
}
#+END_SRC

So that it echoes the syntax for modify class.

On the implementation front, since it's supposed to be syntactic sugar for a
filter+add property, I was hoping to be able to desugar this it with Xtext.  Not
sure if there are any default facilities for that.

Otherwise the cleanest approach would be to do one ATL transformation for
desugaring, then one transformation for turning it into a weaving model.

Since it seems wasteful to launch and run two transformations instead of one, I
guess I'll have to translate the sugar myself.

Got validation for property names working instead, since it was simpler.

** Next time                                                   :emfviews:mel:
Finish 'modify property' ATL transformation.

* [2017-11-21 mar.]
** Handle modify property clause in ATL transformation         :emfviews:mel:
So I managed to make a simplification in the grammar for the 'modify property'
clause.  At first I went with:

#+BEGIN_SRC xtext
ModifyProperty:
  'modify' 'property' property=[ecore::EStructuralFeature] '{'
    operators+=ModifyPropertyOperator*
  '}'
;

ModifyPropertyOperator:
  ChangeName | ChangeType | ChangeCardinality | ChangeRelationType
;

ChangeName: newName=ID;
...
#+END_SRC

But then it was a hassle to handle in the ATL transformation, because to get the
value of name to assign to the new property, I had to find the 'ChangeName'
instance, and use its value.

Then I realized that the grammar was wrong, in that it allowed us to write
the nonsensical:

#+BEGIN_EXAMPLE
modify property foo {
  name bar
  name baz
  name null
}
#+END_EXAMPLE

And, the grammar could be more restrictive /and/ be easier to handle as well
using unordered groups:

#+BEGIN_SRC xtext
ModifyProperty:
  'modify' 'property' property=[ecore::EStructuralFeature] '{'
    (('name' newName=ID)?
     & ('type' type=Type)?
     & ('cardinality' cardinality=Cardinality)?
     & ('relation' 'type' relationType=RelationType)?)
  '}'
;
#+END_SRC

The extra parenthesis ensures the unordered group constraint only applies inside
it (and does not mess with what's around the curly brackets).  And, I don't have
to dig in order to get the values in ATL.  Although... another issue arises.

The point of having clauses inside 'modify property' be optional, is that you
shouldn't have to repeat what is already there.  In this case, if I want to
rename a property, I should just have to say:

#+BEGIN_EXAMPLE
modify class A {
  modify property foo {
    name bar
  }
}
#+END_EXAMPLE

Conceptually, this is syntactic sugar for a filter + add property:

#+BEGIN_EXAMPLE
modify class A {
  filter property foo
  add property bar [..]
}
#+END_EXAMPLE

And this is done the ATL transformation.  But the devil is in the elision:
`[..]` should specify the type and cardinality of the new property.  These
values are known: whatever was already present for the property A.foo in the
metamodel.  Except the ATL transformation does not have knowledge of the content
of this property.

But maybe it could.  The ATL transformation can accept multiple sources.  So we
could, e.g., add an ECORE input model, and navigate it to populate the missing
entries in 'modify property'.

Ah, but Hugo raises a good objection: What happens if you use 'modify property'
on different metamodels?  Your ATL transformation cannot handle N varying
inputs, unless you first generate the transformation from... another
(higher-order) transformation?  And you still need to sort out the
correspondence between the input models and the modify property clauses.

So, maybe the desugaring phase is the simplest solution after all.  If I find a
'modify property' clause, I expand it into 'filter + add' and navigate the
metamodels to find the default values.

Aaaah, but I'm dumb.  I realized that we already had a reference to an EStructuralFeature
in the grammar, so I don't need to navigate anything: I just look up its
attributes to populate the default values in a modify property.

One remaining issue with the 'modify property' clause, is that the grammar
potentially allows you to turn an attribute into a reference and vice-versa.  If
we allow that semantically, then it's a pain to handle in the transformation.

But, we agreed with Hugo that it seems unuintuitive to allow changing the nature
of a feature with 'modify property'.  It's fine for small changes like the name,
the type, or cardinality.  But if you want to change its nature, then you can
always add a new property/association, and hide the previous one (if you want
to).

So I need to change the grammar to reflect this distinction, and disallow
invalid programs.

** At some point                                          :emfviews:mel:vpdl:
I'll have to Write tests for both languages.  Test valid programs, invalid ones,
and also test the generator.

I'm not sure it would have sped up prototyping, since the syntax is fluid at
this point.

But once we design starts to gel, it's time to make sure the basic and corner
cases work.

** Next time                                                   :emfviews:mel:
I've left the cardinality to handle tomorrow.  Maybe I can update the grammar
here as well to forbid using an unbounded one for attributes.

* [2017-11-22 mer.]
** Finishing MEL cardinality                                   :emfviews:mel:
We assumed that attributes could only be typed using primitive types, but it is
not the case in the UML metamodel.  uml.Behavior.isReentrant has type Boolean,
which is part of an EENum in the same metamodel.

And I see that it's perfectaly valid in Ecore, to define an EEnum, and use that
as the type for an EAttribute.  It makes me think that we could revisit the
weaving model to use EDataType as the type for virtual attributes, rather than
strings.  It would make the model less prone to errors, and would get rid of
dumb code for the translation.

Same thing for using EClass in ConcreteClass, rather than this messy business of
finding elements using a fully-qualified name.  I believe the reasoning against
that is that we didn't want to tie the weaving model to EMF.  But it would only
tie it to /Ecore/, which is different.

Actually, it maeks me wonder why we don't also link metamodels directly in the
Xtext grammar for MEL/VPDL.

Another solution might be to include Ecore as contributing model in the weaving
model, and refer to the EDataType as concrete elements.  But we'd still need to
update the weaving model VirtualProperty to accept a different type.

Handled cardinality.

The type issue is still open: if we redefine uml.Behavior.isReentrant without
specifying the type, we try to reuse the Boolean enum, and we have no way to
instruct ATL or the weaving model to use that.  That's just not something we
have considered.

** Generating ECL from VPDL                                   :emfviews:vpdl:
If there is an ECL Xtext grammar fragment, then that's great.  If not, I can
just put the ECL expression in a string for the time being.

Ah, [[https://git.eclipse.org/c/epsilon/org.eclipse.epsilon.git/tree/plugins/org.eclipse.epsilon.ecl.engine/src/org/eclipse/epsilon/ecl/parse/Ecl.g][it looks like]] they are using ANTLR for their grammar.  So... too bad.
String it is.

Also, from the 'How to' page:

#+BEGIN_QUOTE
Epsilon languages do not have Ecore-based metamodels.
#+END_QUOTE

So I can't generate the concrete syntax from a model.  Need generate text
directly, or maybe I can build an in-memory representation of the AST, and
pretty-print that.

Okay so I did the minimal incremental functionality: pass strings in the 'where'
clause of the VPDL directly to ECL.  So now we write:

#+BEGIN_SRC vpdl
where "s.name=t.name and
       s.isAutomated = false"
      for detailedProcess
      "t.values.exists(v | v.theValue=s.name)"
      for detailedRequirement
#+END_SRC

And it generates:

#+BEGIN_SRC ecl
//alias_togaf=http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0
//alias_bpmn=http://www.omg.org/spec/BPMN/20100524/MODEL-XMI
//alias_reqif=http://www.omg.org/spec/ReqIF/20110401/reqif.xsd

rule detailedProcess
match s : togaf!Process
with  t : bpmn!Process
{
  compare
  {
    return s.name=t.name and
           s.isAutomated = false;
  }
}
rule detailedRequirement
match s : togaf!Requirement
with  t : reqif!SpecObject
{
  compare
  {
    return t.values.exists(v | v.theValue=s.name);
  }
}
#+END_SRC

I'm pretty sure it's not composable, and is very prone to breaking.  Discovering
ECL syntax errors only when launching the view is very bad, but it's still
better than what we had until then.

(But I'm not sure it's better than letting the user write the ECL file by
hand...)

One observation: from the look of it, I'm not really sure why we need the
metamodels in the header.  We can certainly pass them to the ECL delegate, so
they really don't need to appear here.

* [2017-11-23 jeu.]
** Comparison of ATL VM performance                                     :atl:
Specifically, if there is a significant speedup when running a transformation
written in Java, versus running a transformation using the ATL VM or EMFTVM.  If
the speedup is significant, then it could valuable to compile ATL
transformations directly to Java code (and rather interesting to boot).

So, premilimary results on a really dumb transformation:

#+BEGIN_SRC atl
rule Metamodel {
    from s : MEL!Metamodel
    to   t : VirtualLinks!ContributingModel
}
#+END_SRC

The source model has 1000 Metamodel elements.  Using EMFTVM: 65.79ms to load the
bytecode, 57.45ms to execute the transformation, 123.24ms total.

Using Java to populate the resource: 7.32ms.  Not bad.

Let's get some more numbers (time in milliseconds):

| EMFTVM (load) | EMFTVM (run) | EMFTVM (total) | Java |
|---------------+--------------+----------------+------|
|         63.67 |        56.09 |         119.76 | 7.27 |
|         70.92 |         76.5 |         147.42 | 5.69 |
|         69.96 |        66.06 |         136.02 | 7.27 |
|         59.77 |        56.11 |         115.88 | 9.88 |
|         62.34 |        55.92 |         118.26 | 7.47 |
|         67.10 |        64.89 |         131.99 | 7.20 |
|         70.77 |        60.79 |         131.56 | 7.80 |
|         63.31 |        58.04 |         121.35 | 7.66 |
|         65.82 |        59.61 |         125.43 | 7.33 |
|         65.99 |        74.26 |         140.25 | 5.99 |
|---------------+--------------+----------------+------|
|         65.97 |        62.83 |         128.79 | 7.36 |
|          3.78 |         7.51 |          10.40 | 1.12 |
#+TBLFM: $2@=$3-$1::@12=vmean(@I..II);%.2f::@13=vsdev(@I..II);%.2f

So the average speedup of the Java transformation is:

: 128.79 / 7.36 = ~17.5

That's one order of magnitude and more.  Pretty good.  Even if you only count
the transformation time, it's still a 8.54 speedup.

Now another question is: how does the performance scale with the number of
elements model size?

Time still in milliseconds:

| Nb of elements | EMFTVM (total) |    Java |
|----------------+----------------+---------|
| 1k             |         128.79 |    7.36 |
| 10k            |         229.62 |   21.16 |
| 100k           |         778.40 |  118.61 |
| 1000k          |        4968.08 |  330.65 |
| 10000k         |              - | 2833.60 |

EMFTVM crashed with OutOfMemoryError after a few minutes of burning all my CPU
cores.  The performance dip at 1 million elements is also strange; it seems to
exhibit non-linear behavior here.  Maybe most of the time is spent in GC; I
would need to profile to see what's happening exactly.

The numbers are also a bit raw.  Getting more samples:

|        | EMFTVM (total) |    Java |
|--------+----------------+---------|
| 10k    |         229.62 |   21.16 |
|        |         247.58 |   18.31 |
|        |         256.83 |   19.78 |
|        |         241.50 |   19.24 |
|        |         287.65 |   14.61 |
|        |         255.47 |   15.12 |
|        |         229.89 |   16.11 |
|        |         262.84 |   16.30 |
|        |         228.45 |   15.80 |
|        |         253.97 |   14.91 |
|--------+----------------+---------|
| Mean   |         249.38 |   17.13 |
| Stdev  |          18.36 |    2.31 |
|--------+----------------+---------|
| 100k   |         778.40 |  118.61 |
|        |         654.89 |  129.84 |
|        |         662.66 |  112.93 |
|        |         703.02 |  116.72 |
|        |         661.14 |  130.02 |
|        |         654.88 |   98.90 |
|        |         672.87 |   69.80 |
|        |         686.44 |   90.11 |
|        |         732.92 |   89.95 |
|        |         676.96 |  100.69 |
|--------+----------------+---------|
| Mean   |         688.42 |  105.76 |
| Stdev  |          39.89 |   19.34 |
|--------+----------------+---------|
| 1000k  |        4968.08 |  330.65 |
|        |        4328.87 |  308.59 |
|        |        4413.08 |  325.68 |
|        |        4395.61 |  312.63 |
|        |        4754.49 |  321.02 |
|        |        4729.85 |  316.54 |
|        |        4439.81 |  355.46 |
|        |        4213.97 |  327.41 |
|        |        4391.01 |  333.40 |
|        |        4377.02 |  326.70 |
|--------+----------------+---------|
| Mean   |        4501.18 |  325.81 |
| Stdev  |         234.96 |   13.09 |
|--------+----------------+---------|
| 10000k |                | 2833.60 |
|        |                | 4371.31 |
|        |                | 5404.33 |
|        |                | 4417.67 |
|        |                | 4577.32 |
|--------+----------------+---------|
| Mean   |           0.00 | 4320.85 |
| Stdev  |           0.00 |  930.53 |
#+TBLFM: @12$2..@12$3=vmean(@I..II);%.2f::@13$2..@13$3=vsdev(@I..II);%.2f
#+TBLFM: @24$2..@24$3=vmean(@14..@23);%.2f::@25$2..@25$3=vsdev(@14..@23);%.2f
#+TBLFM: @36$2..@36$3=vmean(@26..@35);%.2f::@37$2..@37$3=vsdev(@26..@35);%.2f
#+TBLFM: @43$2..@43$3=vmean(@38..@42);%.2f::@44$2..@44$3=vsdev(@38..@42);%.2f

So, to recap:

#+tblname: recap
| Nb of elements (k) | EMFTVM (total) |    Java | Speedup |
|--------------------+----------------+---------+---------|
|                  1 |         128.79 |    7.36 |   17.50 |
|                 10 |         249.38 |   17.13 |   14.56 |
|                100 |         688.42 |  105.76 |    6.51 |
|               1000 |        4501.18 |  325.81 |   13.82 |
|              10000 |              - | 4320.85 |         |
#+TBLFM: $4=$2/$3;%.2f

#+begin_src gnuplot :var data=recap :file doc/atl-bench.png
reset
set logscale x

set xlabel 'model size (k)'
set ylabel 'time to transform (ms)'

plot data u 1:2 w lp title 'EMFTVM', \
     data u 1:3 w lp title 'Java'
#+end_src

#+RESULTS:
[[file:doc/atl-bench.png]]

So, both curves seem to have the same profile, although Java is clearly faster
all along.  The spikes at the end may come from the GC dominating, but I haven't
profiled yet.

This is with ~java -version~:

: openjdk version "1.8.0_151"

Anyway, interesting!  There is definitely something to be gained by translating
transformations to Java from the look of it.

I probably need more tests for less trivial transformations, and to profile
both, in order to understand where the time is spent.

Also, I could add the regular ATL VM to the mix.

** Summarizing what's left for EMFViews when I come back           :emfviews:
*** EMFViews
- Resolve filtering interference with inheritance, references, etc.
  Interference with metamodel coherence.
- Resolve the data type conundrum
- EFactory for viewpoints/views.  Do we want one?  Do we return null?
- UI and Editor plugin are still broken.  Do we want wizards?

*** VPDL/MEL
- Add parser tests for valid programs, invalid ones
- Add integration tests from the output of the generator
- Add static checks for things that are not caught by the grammar?
- Properly integrate ECL in VPDL

*** Deployment
- Continuous integration on Travis
- Provide an easy way to use EMFViews outside of Eclipse (maven central?)
- Start using version numbers
- Cleanup copyright (esp. for VPDL and MEL)
- Upgrade to EPL 2.0

*** Documentation
- Add Javadoc on EMFVIews core
- Cleanup examples.  Remove outdated one, update the ones that can be salvaged.
- Update or remove videos
- Add tutorial for setting up
- Repopulate website
- [X] Cleanup wiki

* [2017-11-24 ven.]
** Screen backlight on Latitude 7480                                   :dell:
For the brightness key to work, it seems I need to use the intel graphics driver
after all.  No kernel option needed after that.

* [2017-12-01 ven.]
** The search for a new wiki                             :wiki:
I've narrowed down the list to:

- Gollum (the thing Github uses).  Ruby.
- Gitit.  Haskell.
- ikwiki.  ??

All of these support multiple editing formats, web-based editing as well as
direct file editing, use Git to store revisions, and can be self-hosted.

Gollum is not free software though.

ikwiki looked rather minimal, even though a handful of plugins seem provided
with the base install.

I opted to try Gitit first since there's a Github OAuth example on the README,
which is already promising.

Trying to install with cabal...

: pacman -S ghc cabal-install
: cabal update
: cabal install gitit

warns me about dependencies that would break existing installs, notably of ghc.
Hmm, let's try stack then.  It's a folder-local install, so it should be more
robust?

: pacman -S stack
: git clone https://github.com/jgm/gitit.git
: cd gitit
: stack install

I didn't checkout any tag; building straight from master.  Looks like stack is
installing GHC 9.3 or something?

Fails with:

#+BEGIN_EXAMPLE
Progress: 13/133
--  While building package digest-0.0.1.2 using:
      /home/fmdkdd/.stack/setup-exe-cache/x86_64-linux-tinfo6-nopie/Cabal-simple_mPHDZzAJ_1.24.2.0_ghc-8.0.2 --builddir=.stack-work/dist/x86_64-linux-tinfo6-nopie/Cabal-1.24.2.0 build --ghc-options " -ddump-hi -ddump-to-file"
    Process exited with code: ExitFailure 1
    Logs have been written to: .stack-work/logs/digest-0.0.1.2.log

    Configuring digest-0.0.1.2...
    Building digest-0.0.1.2...
    Preprocessing library digest-0.0.1.2...
    /usr/bin/ld: .stack-work/dist/x86_64-linux-tinfo6-nopie/Cabal-1.24.2.0/build/Data/Digest/CRC32_hsc_make.o: relocation R_X86_64_32 against `.rodata' can not be used when making a shared object; recompile with -fPIC
    /usr/bin/ld: final link failed: Nonrepresentable section on output
    collect2: error: ld returned 1 exit status
    linking .stack-work/dist/x86_64-linux-tinfo6-nopie/Cabal-1.24.2.0/build/Data/Digest/CRC32_hsc_make.o failed (exit code 1)
#+END_EXAMPLE

Trying with:

: git checkout 0.12.2.1

same thing.  Grmbl.

I'll let cabal do its thing then.

: cabal install --force-reinstalls gitit

#+BEGIN_EXAMPLE
cabal: Leaving directory '/tmp/cabal-tmp-14769/byteable-0.1.1'
cabal: Error: some packages failed to install:
Diff-0.3.4-9Jk7nn49ORI32Gqvs1rQQi failed during the building phase. The
exception was:
ExitFailure 1
HStringTemplate-0.8.6-4urbpt7EoCN94ZLHEgcUuE depends on HStringTemplate-0.8.6
which failed to install.
SHA-1.6.4.2-BFIBO7i65E6HsO6Fy2Jbdf failed during the building phase. The
exception was:
ExitFailure 1
...
#+END_EXAMPLE

Come on...

There is a recipe in AUR.  I guess I'll try that.

: pacaur -S gitit

#+BEGIN_EXAMPLE
AUR Packages  (2) ghc-pristine-8.2.1-4  gitit-0.12.2.1-3
Repo Packages (3) ghc-8.2.1-3  ghc-libs-8.2.1-3  ghc-static-8.2.1-3

Repo Download Size:     85.86 MiB
Repo Installed Size:  1332.75 MiB
#+END_EXAMPLE

That's a lot of GHCs.

#+BEGIN_EXAMPLE
cabal: The following packages are likely to be broken by the reinstalls:
process-1.6.1.0
haskeline-0.7.4.0
ghc-8.2.1
Cabal-2.0.0.2
ghci-8.2.1
directory-1.3.0.2
hpc-0.6.0.3
ghc-boot-8.2.1
Use --force-reinstalls if you want to install anyway.
==> ERROR: A failure occurred in build().
    Aborting...
:: failed to build gitit package(s)
#+END_EXAMPLE

Oh well.

But what's this ghc-static anyway?  Looking at the Archwiki on Haskell, it looks
like the packaged GHC does not support dynamic linking.

So, retrying:

: pacaur -S ghc-pristine
: pacman -S cabal-install

But the wiki also says I also need ghc-static...

: pacman -S ghc-static

Cabal still bugs me about dependencies and --force-reinstalls... ok let's try
it.

Seems to go further in the build now.

After a few minutes, the install fails because pandoc failed to build.

The last resort is to install the Haskell platform, and retry the build from
there (or from source).

Hahahaha

#+BEGIN_EXAMPLE
# ./install-haskell-platform.sh
Unpacking ./hp-usr-local.tar.gz to /...
Running /usr/local/haskell/ghc-8.2.1-x86_64/bin/activate-hs ...
#+END_EXAMPLE

Returned with status 127.

: ghc --version

#+BEGIN_EXAMPLE
/usr/local/haskell/ghc-8.2.1-x86_64/lib/ghc-8.2.1/bin/ghc: error while loading shared libraries: libtinfo.so.5: cannot open shared object file: No such file or directory
#+END_EXAMPLE

* [2017-12-02 sam.]
** Gitit: part 2                                                       :wiki:
Okay, last chance.  It seems gitit is packaged in Debian, so it should be fine
to run on the Atlanmod server.

I see there are Docker recipes, so maybe I can try that?

Trying this one: https://hub.docker.com/r/marcelhuberfoo/docker-gitit/

: pacman -S docker
: docker pull marcelhuberfoo/docker-gitit
: sudo docker run -d --name gitit -e GIT_COMMITTER_NAME="Test User" \
:                                 -e GIT_COMMITTER_EMAIL="test@domain.com" \
:                 -p 60000:5001 marcelhuberfoo/docker-gitit

Oh hey, look at that.  Browsing to localhost:60000, and it works!

Now, it seems we still have a bunch of pages in the MediaWiki syntax, and Gitit
doesn't support it apparently.  I misread: it supports /exporting/ to MediaWiki,
which is decidedly not the same thing.

Well, ultimately, I just want to make sure our mediaWiki won't get hacked.
Maybe just using OAuth there would do?

Seems [[https://www.mediawiki.org/wiki/Extension:OAuth][there is one]].  Not sure how it applies to us though.x

* [2018-02-01 jeu.]
** Back in the saddle                                      :emfviews:eclipse:
One of my first order of business would be to tackle some infrastructure.  I
want to be able to ~make~ the project, distribute it, test it, all on the
command-line so I can use Travis, and the build is reproducible.

Eclipse launch configurations drive me mad with the amount of hand
configuration.  You'd think it would be enough to add the plugins you want to
run, and click "Add Required Plug-ins", but no!  You get a mystifying error:

: Unresolved requirement: Require-Capability: osgi.extender; filter:="(&(osgi.extender=osgi.component)(version>=1.2)(!(version>=2.0)))"

[[https://bugs.eclipse.org/bugs/show_bug.cgi?id=494913][The solution]] is to add the ~org.eclipse.equinox.ds~ plugin, and its required
plug-ins again.

* [2018-02-05 lun.]
** Cleaning up dependencies                                :eclipse:emfviews:
Turns out we have dependencies in plugins that are not even used.  Eclipse
helpfully provides a "Find unused dependencies" tool, but why is that not
automatic?

I've tried to use Import-Package instead of Require-Bundle.  You have to version
packages independently, and for some reason EMF tends to break if we only import
packages.  So, at least for EMF, it's better to include bundles.  Also, most
Eclipse packages do not export package versions, so...

** Fixing copyrights                                               :emfviews:
We should upgrade to EPL-2.0, as it can be made compatible with GPL via the
Secondary License clause.

[[https://www.eclipse.org/legal/epl-2.0/faq.php#h.2487uaelxj1l][The FAQ]] is very helpful in answering tricky questions, and providing clear
examples of how to do that.

Here is the template I've settled onto:

#+BEGIN_SRC java
/*******************************************************************************
 * Copyright (c) 2018 Armines
 *
 * This program and the accompanying materials are made available under the
 * terms of the Eclipse Public License 2.0 which is available at
 * https://www.eclipse.org/legal/epl-2.0/
 *
 * This Source Code may also be made available under the following Secondary
 * Licenses when the conditions for such availability set forth in the Eclipse
 * Public License, v. 2.0 are satisfied: GNU General Public License, version 3
 * which is available at https://www.gnu.org/licenses/gpl-3.0.txt
 *
 * Contributors:
 *   fmdkdd - initial API and implementation
 *******************************************************************************/
#+END_SRC

** Cool trick with dired                                              :emacs:
To replace text in multiple files:

- find-name-dired
- Press 't' to select all files
- dired-do-query-replace-regexp

Interactive search/replace in all selected files!

* [2018-02-06 mar.]
** Tycho + Xtext                                       :maven:xtext:emfviews:
Just copying the POM from [[https://github.com/xtext/maven-xtext-example][this example project]] works.  The [[https://www.eclipse.org/Xtext/documentation/350_continuous_integration.html][documentation]] is also
helpful.

There are still some rough edges: it's very slow (maven queries repositories
every time...), and it regenerates the DSL plugins every time, but at least it's
reproducible!

* [2018-02-07 mer.]
** Skipping DSL generation from grammar if the grammar hasn't changed :maven:xtext:
Because currently, if I run `mvn integration-test`, it will regenerate all the
DSL plugins...

If I RTFM'd correctly, `mvn integration-test` will run all phases up to
(including) `integration-test`, and that includes `generate-sources`, which is
the phase where we declared that MWE2 generation should happen.  So, it makes
sense that the MWE2 generation happens every time.

Now, is there a way to conditionally exec this generation?

It doesn't seem that like this is configurable.  And maven doesn't support
arbitrary conditional execution either.

I could write a script that would conditionnally execute the MWE2... but a
simpler solution would be to /not/ bind that execution to the default life
cycle.

I've added a flag, so I can do:

: mvn -o -Dmwe2-skip-generate=true verify

and not regenerate the plugins from the grammar.  It's faster, but honestly, the
only downside of regenerating aside from speed, is touching the dependencies in
the manifest files.

* [2018-02-08 jeu.]
** Running integration tests for DSLs on Travis          :emfviews:atl:maven:
I've written the tests that use the generator.  They pass locally, but not on
travis yet because we have not instructed the maven build to compile ATL files!

I found [[https://wiki.eclipse.org/ATL/User_Guide_-_Building_ATL_With_ANT_And_Maven][this guide]] that use an ANT task.  However, the code is obsolete.

Instead, I think it wouldn't be too hard to write a simple Maven plugin that
discovers ATL files and does whatever the Eclipse ATL builder does.

For inspiration: [[https://github.com/eclipse/xtext-xtend/blob/master/org.eclipse.xtend.maven.plugin/][Xtend maven plugin]], [[http://git.eclipse.org/c/mmt/org.eclipse.atl.git/tree/plugins/org.eclipse.m2m.atl.adt/src/org/eclipse/m2m/atl/adt/AtlBuildVisitor.java][ATL Eclipse builder]], [[http://git.eclipse.org/c/mmt/org.eclipse.atl.git/tree/plugins/org.eclipse.m2m.atl.engine/src/org/eclipse/m2m/atl/engine/compiler/AtlCompiler.java][ATL compiler]].

Hmm, one issue is that AtlCompiler requires the eclipse.core plugins to run.
Calling ~AtlCompiler.compile~ first fails because maven has to find the ATL
dependency.

I found [[https://repo.eclipse.org/content/groups/atl/org/eclipse/m2m/atl/org.eclipse.m2m.atl.engine/][this maven ATL repository]].  It only contains snapshot releases, but it's
an official one.

Adding that as a repository and declaring the dependency, I can't get the maven
plugin to compile, because:

: cannot access org.eclipse.core.resources.IFile
: [ERROR]   class file for org.eclipse.core.resources.IFile not found

So I should add org.eclipse.core.resources as dependency... but I don't have a
Maven repository for that!  Oh wait, they are on maven central.  Strange that
the ATL maven artifact does not declare them as dependencies...

Adding ecore as dependency, which is also on central... Haha!  It compiles!

But explodes when launching the plugin goal:

: [ERROR] Failed to execute goal fr.atlanmod.atl:maven-plugin:0.1-SNAPSHOT:compile (default-cli) on project atl-maven-plugin: Execution default-cli of goal fr.atlanmod.atl:maven-plugin:0.1-SNAPSHOT:compile failed: A required class was missing while executing fr.atlanmod.atl:maven-plugin:0.1-SNAPSHOT:compile: org/eclipse/emf/common/notify/Notifier

Can I add it to the runtime dependencies?  Yep.  Adding them one by one...

Antlr dependencies is tricky, as 3.5 fails with a MethodNotFound.  Presumably
some method was removed (breaking API, without increasing major version!).
Testing with 3.4, 3.3... Ah 3.3 raises an exception.
3.2, 3.1, same.  3.0... success!

Now, unfortunately, that generated an ASM, because EMFTVM was not recognized.
Can I make it work?

Including emftvm.compiler as dependency is not enough.  Probably the detection
that ATL does is not fooled so easily.

It seems ATL uses the extension point to detect installed compilers...  but I'm
not even running an Eclipse instance here.  Can I get the compiler directly?

I can call AtlToEmftvmCompiler, but it ultimately fails with:

: Failed ATL compilation: Error during module loading: Module ATLWFR not found

Even though these transformations are included in the emftvm.compiler JAR, which
is a runtime dependency.

Argh, wait, I can't declare the dependency twice.  But how do I declare a
dependency that's required at compile time /and/ runtime?

Nevermind, it doesn't seem to make a difference.

However, testing the code used by EMFTVM to load the resources in the plugin, I
can see that it uses a "platform:" EMF URI, but I am not running Eclipse!  So we
end up with:

: Caused by: java.net.MalformedURLException: unknown protocol: platform

Solutions?  Override the AtlEmftvmCompiler class to not use platform URIs?
Otherwise, maybe use Tycho to build the maven plugin.. but I really don't see
how that would work.

* [2018-02-09 ven.]
** ATL Maven plugin                                      :atl:maven:emfviews:
After tinkering with class.getResource() for over an hour, I can't get to the
files inside the ~transformations~ folder, even though they are in the JAR.
Presumably, they are not on the classpath.

Other way: just grab these damn files and put them in the plugin.  Doesn't
work.

Maybe the issue is that the module resolver can't get files from inside a JAR?

I give up.  I've tried building the plugin using Tycho... that fails when
running the goal.  Tycho doesn't want to build the ~maven-plugin~ packaging
anyway, so I tried to build using the ~eclipse-plugin~ packaging, then switching
to ~maven-plugin~ for generating the descriptor and installing.  Or the other
way around.

Anyway, it doesn't work.

I've gone back to cleaning up the POM and using the straight ~maven-plugin~
approach, albeit with all the dependencies added because ATL dependencies are
not transitive.

I've added the logic to walk the project directory to find ATL files.  It was
surprisingly painful.  Not because of Java: Java 8 has a nice ~Files.walk~ that
outputs a stream, so it's rather easy to use.  Although, you can't put methods
that can throw exception in a ~forEach~, so it's not as nice as it could be.
But Maven was tricky to build with Java 8.

The descriptor plugin failed with a mysterious error code when I built the
plugin with the source set to 1.8.  Upgrading the descriptor plugin fixed it.

And I added logic to display errors.  It's not very ergonomic, but at least it's
informative if the build ever fails on Travis.

That was... more work than I would've liked to build that on Travis.  And I
still need to adapt the Xtend generator code to use the standard ATL VM rather
than EMFTVM.

* [2018-02-12 lun.]
** Converting the Mediawiki into a Gitlab/Gollum wiki                  :wiki:
Our mediawiki is a security liability.  We are moving all internal pages to a
private gitlab repository instead.

Using pandoc, we can convert pages to Markdown automatically:

: pandoc --columns=80 -f mediawiki -t gfm file.mediawiki > file.md

We also had a bunch of files uploaded to the mediawiki.  There is a list
containing all files.  From that, I can get the URLs with this JS code in the
console:

: $$('table a').filter(a => a.text === 'file').map(a => a.href)

In Firefox, right-click the result, "Copy object", and you've got a JSON array
of URLs to fetch the files from.  Clean up the file to have one URL per line
without quotes, and just invoke:

: wget -i urlfile -P dir

Done.

* [2018-02-13 mar.]
** Running a second Eclipse instance                       :eclipse:emfviews:
This has been broken ever since I got back it seems.

I really don't want to re-install Eclipse or wipe my configuration, as there is
no easy way to re-use an parts existing configuration, as far as I can tell...

Anyway, loading all plugins in the runtime Eclipse works.  But of course I don't
want to do that.

Adding "required plugins" isn't enough: I need to /at least/ add ~equinox.ds~.
But that triggers a runtime error saying that the ~ide.worbkench~ application
cannot be found.  Adding that one still triggers the error.

I went the other way around: add everything, remove features that are useless.
Add "required plugins" just in case.  Good to go.

** Improving DSL tests                                       :xtext:emfviews:
I wanted to use the ValidationTestHelper to go further than just testing the
parsing.  Even though we have no custom validation rules, we do have custom
scoping rules, and I wanted to see if we could test that.

Turns out, the ValidationTestHelper does not take scoping into account!
Checking through the debugger, we never go through our custom scope provider.

I don't think we need to turn that into an UI integration test.  Maybe we need
to call the scope provider explicitly.

Anyway, I found out that our tests were also a bit fishy: not checking for
correct parsing before running the generator was a bad idea.

After struggling with obscure ATL errors, it turned out that I was not loading
the UML2 plugin.  Added that as dependency, and all is fine.  That's why I
always use the "required plugins" button: it catches that stuff before the CI!

Strangely though, our MEL tests also use the UML2 metamodel.  But they seem to
run fine without it being loaded at runtime?

* [2018-02-14 mer.]
** Thinking about a S-expr syntax for writing tests on EMF models :emfviews:emf:
For the MEL generator test for instance, it makes no sense to test against the
resulting XMI.  It's not readable.

Creating an expected WeavingModel using the EMF-generated factories is even more
verbose.

I think something like this would work:

#+BEGIN_SRC elisp
(WeavingModel
 :name "extension1"
 :virtualLinks [(VirtualConcept :name "X" :superConcepts #1#)]
 :contributingModels
   [(ContributingModel
     :uri "http://www.eclipse.org/uml2/5.0.0/UML"
     :contreteElements [#1=(ConcreteConcept :path "Class")])])
#+END_SRC

Since we can have cycles, I've found this nifty ~#1#~ syntax on [[http://wiki.c2.com/?EssExpressions][the wiki]].

I don't think we can easily translate to XMI, because there are tricks used in
EMF at least to reuse tags when they contain a single child.  So the mapping is
not 1-1.

However, if we turn that into calls to the reflective EMF API (or even the
generated one):

#+BEGIN_SRC java
val f = VirtualLinksFactory.eINSTANCE
val wm0 = f.createWeavingModel()
val vc0 = f.createVirtualConcept()
val cm0 = f.createContributingModel()
val cc0 = f.createConcreteConcept()

wm0.setName("extension1")
wm0.getVirtualLinks().add(vc0)
wm0.getContributingModels().add(cm0)

vc0.setName("X")
vc0.getSuperConcepts().add(cc0)

cm0.setURI("http://www.eclipse.org/uml2/5.0/UML")
cm0.getConcreteElements().add(cc0)

cc0.setPath("Class")
#+END_SRC

Create all objects first to account for eventual cycles.  Then just set
properties.  We cannot set lists outright in EMF (maybe with the reflective
API?), but since we know whether we have a list dynamically... there is no
ambiguity.

Now the question is: do I want to use Xtext for that...?  Probably not.

* [2018-02-15 jeu.]
** Adding example wizards                                  :eclipse:emfviews:
I've looked at the ones that are in NeoEMF, ATL and Xtext.  They all create a
projects in your workspace, fully set up.

In NeoEMF, they provide the demo projects in the repo.  You can clone that and
import the projects in your Eclipes, and you should have the exact same thing as
what the wizards provide.

The wizards actually contain these projects in zips, and simply inflate them in
the workspace.

So as a first step I can just clean up the examples folder, make sure they work,
document them the best I can.

Then I can create the wizards.  I don't like the zip duplication however.  I
guess I could zip them when building the plugin only?

** Revamping examples                                              :emfviews:
There were simple examples using Books and Publications already to showcase
creating a viewpoint and a view.

It's not obvious what the are the benefits of the use case.  But it shows the
mechanisms.

** Move the matching model to view?                            :emfviews:ecl:
It's only used by the view.  You could imagine different ways to populate the
view using different matching models, but using the same viewpoint.

In the book/publication example, the matching model has this constraint:

: return ps.title = c.title and ps.nPages >20 and not ps.isTOC;

If you wanted to create another view using a different predicate, you would have
to create another viewpoint currently.  But if the matching model is part of the
view, then you don't have to!

** Cleanup up the ECL delegate                                 :emfviews:ecl:
The ECL delegate does two things:

1. execute the ECL matching model
2. create a weaving model from the matches

Here is an example ECL rule:

#+BEGIN_SRC ecl
rule ruleName
match s : mm1!Feature
with  t : mm2!Feature
#+END_SRC

In order to do #1, we have to know:

1. where the ECL file is
2. what are the input models
3. what are the metamodels
4. which metamodels ~mm1~/~mm2~ refers to
5. where to write the weaving model

#1, #2 and #5 are directly provided to the delegate.  #3 can be figured out by
#looking in the models.

But #4 is tricky, because that information is nowhere else.  We don't need to
names the metamodels in the viewpoint.  Arguably, metamodels don't even need
names because they already have namespace URIs which uniquely identify them.

However, it's cumbersome to use the URI to refer to them multiple times in the
same ECL file.  In ATL, you use an alias (in the comments, for some reason).
Here we also use an alias.  But that's a duplication of information, right?  We
have already specified the metamodels in use in the viewpoint.

I think it's reasonable in this case, since it makes the ECL autonomous.

One downside of the current implementation is that you refer to metamodels only
using namespace URIs.  But they might not be loaded in the global registry.  ECL
allows you to specify Ecore files instead.  Let's try to add that.

Okay so the problem with that idea, is that we need the namespace URI to match
the input models with their metamodels.  The syntax would become quite
cumbersome if we had to specify the namespace URI /and/ the path to an eventual
Ecore.

Hmm, but we could do the same thing the Viewpoint does: load the metamodel from
that alias.  Then use that namespace URI.

Okay that works.  But it's a little dumb?  Let's see:

- If given an Ecore file, the viewpoint creates a resource and resource set in
  order to load the EPackage into a private list.
- If given an Ecore file, the ECL delegate does the same thing, but throws away
  the EPackage since it only needs the namespace URI /and/ the location of the
  Ecore to give to EclModule
- EclModule then creates a resource/resourceSet to load the Ecore file again.
  Although they seem to have a pool in EmfUtil.register to avoid loading
  packages twice from the same Ecore file.

It seems that putting the EPackage in the global registry would not be a bad
idea after all.

* [2018-02-22 jeu.]
** Extending the test suite for DSLs                           :efmviews:mel:
I found a strange bug, which I attributed to the lazy rule having funky
behavior.  Turns out, lazy rules do not worm the same with EMFTVM and the
regular ATL VM.  As [[https://wiki.eclipse.org/ATL/EMFTVM#Lazy_rules][the documentation states]], in EMFTVM lazy rules are matched
against the arguments, and I can see that with the regular VM, the unique lazy
rule seems to ignore further arguments.

The [[https://wiki.eclipse.org/ATL/User_Guide_-_The_ATL_Language#Unique_Lazy_Rules][ATL reference]] is not explicit on this, only stating:

#+BEGIN_QUOTE
When a unique lazy rule is executed, it always returns the same target element
for a given source element.
#+END_QUOTE

I guess it's back to EMFTVM... but I will need to find a way to build it using
Maven.

* [2018-02-26 lun.]
** Prototyping new NaoMod website                                    :naomod:
Simple, but effective.

I had to resort to JS for fetching things publications from HAL.  It's either
that or generating them statically... which requires some intervention on our
part at some point.

At least with JS, they are always up to date!

For reference, since I had to track this down, here is [[https://api.archives-ouvertes.fr/docs/search/schema/fields/#fields][the list of fields]] we can
query and fetch from HAL entries.

* [2018-03-02 ven.]
** Adding wildcards to VPDL                                   :emfviews:vpdl:
For attributes, when you want to select all of them, it's cumbersome having to
write them all out by hand.

So instead of writing

: select a[b,c,d,e,f,g]

You want to just write:

: select a.*

To implement that, I extended the VPDL grammar.  At first, I wanted to do a
syntactic sugar pass, or handle the extension of wildcards in the ATL
transformation, but that is not possible.  The ATL transformation would need to
load the metamodel in order to know what features to include.

It could be doable as syntactic sugar, but I haven't found how to do that with
Xtext.

So I just output an 'a.*' path in the weaving model, and modified emfviews
to handle that case.

There's a tricky bit because of the way blacklisting and whitelisting are
implemented in EMF Views at the moment.  The filters path are used differently
in each case.

** Building an example from design to runtime models               :emfviews:
For the project, we want to showcase an example including four models:

- A requirements model (ReqIF metamodel)
- A component diagram (UML metamodel)
- A Modisco model of Java source (Modisco/Java metamodel)
- A model of runtime trace (custom metamodel)

I built very simple models for each.  One pain point is I forgot to add the
~viewpoint=~ line in the eview file, and got an NPE.

Of course, EMF silently collects exceptions when loading a resource, so the
resource still loads.  Then when EMF tries to populate the editor, the View
fails because it has uninitialized fields.

Adding custom exception when parsing View does not help: they are captured by
EMF.  Don't know where or when they are supposed to appear though.

When loading the view with the Sample Ecore Editor, there are two issues:

1. The UML model raises an error when clicking on any component.

   : EObjectContainmentElist$Resolving cannot be cast to EObject

2. The reqif model cannot be browsed.  There's only a VirtualEObject top-level
   element:

   [[file:doc/reqif-fail.png]]

When loading the view with the Modisco Model Browser, I get another error:

: ECollections$UnmodifiableElist cannot be cast to InternalEList

and the editor does not allow me to browse the model.

When loading the view in the EView editor, everything is fine: the reqif can be
browsed, and there are no errors.

* [2018-03-05 lun.]
** Fixing views with Modisco                                       :emfviews:
So the problem is a cast from UnmodifiableElist to InternalElist.

Is there an unmodifiable list that implements this interface, or do we have to
define one?

Yes, there is one: EcoreElist.UnmodifiableEList.  Using that, the view can be
browsed using Modisco.

There are still a bunch of exception in the console:

#+BEGIN_EXAMPLE
java.lang.UnsupportedOperationException
	at org.atlanmod.emfviews.elements.VirtualEPackage.getEFactoryInstance(VirtualEPackage.java:153)
	at org.eclipse.gmt.modisco.infra.browser.editors.MetaclassViewer$MetaclassLabelProvider.getImage(MetaclassViewer.java:378)
	at org.eclipse.jface.viewers.WrappedViewerLabelProvider.getImage(WrappedViewerLabelProvider.java:101)
	at org.eclipse.jface.viewers.WrappedViewerLabelProvider.update(WrappedViewerLabelProvider.java:146)
        ...
#+END_EXAMPLE

We do not provide an EFactory instance.  We could provide a dumb one that throws
UnsupportedOp for each method.  Although why is modisco asking for one?  For
images?

Here is MetaclassViewer.java:378:

#+BEGIN_SRC java
// instantiate an element in order to be able to use the image provider
final EObject dummyInstance = eClass.getEPackage().getEFactoryInstance()
  .create(eClass);
#+END_SRC

A dummy instance indeed.

So providing an EFactory instance would not solve the issue.

Looking at the rest of the code:

#+BEGIN_SRC java
// instantiate an element in order to be able to use the image provider
final EObject dummyInstance = eClass.getEPackage().getEFactoryInstance()
  .create(eClass);

// icon provided by an extension
final IconProvidersRegistry iconProvidersRegistry = IconProvidersRegistry
  .getInstance();
final Image icon = iconProvidersRegistry.getIcon(dummyInstance);
if (icon != null) {
  return icon;
}

// icon provided by an adapter from the registry
final IItemLabelProvider itemLabelProvider =
  (IItemLabelProvider) MetaclassViewer.this.browserConfiguration
  .getAppearanceConfiguration().getAdapterFactory()
  .adapt(dummyInstance, IItemLabelProvider.class);

if (itemLabelProvider != null) {
  return ExtendedImageRegistry.getInstance()
    .getImage(itemLabelProvider.getImage(dummyInstance));
}
#+END_SRC

It appears we would need to provide at least a class instance in order for this
mechanism to work.

In this case, we could probably delegate to the concrete EFactory, and the
proper icons would be found.  However, it doesn't seem like the proper solution,
because the EFactory could be used for other purposes as well...  and the
returned object would not actually reflect that they are part of a view.

Maybe the proper solution is to augment these image registries / label providers
with knowledge of the virtual objects?  Go through them, and if we find an
object that has been virtualized, also associate the virtual object to the same
images/labels?

Another issue with Modisco, at least for the UML model, is that I get many
duplicated attributes:

[[file:/home/fmdkdd/proj/monoge/doc/modisco-duplicates.png]]

Also in the properties view:

[[file:/home/fmdkdd/proj/monoge/doc/modisco-duplicate-properties.png]]

This duplication also happens with the EView editor.

** Fixing the test view in the Sample ECore Editor                 :emfviews:
For the exception thrown for the UML model, here is the incriminating cast:

: EObject otherEObject = (EObject)((EObject)value).eGet(eOtherEnd);

At runtime, ~value~ is an instance of TemplateSignatureImpl (from the UML2
package), and ~eOtherEnd~ is a VirtualEReference for the 'template' feature of
the TemplateSignature eClass.

The eGet returns an (empty) EObjectContainmentElist$Resolving, which cannot be
cast into EObject.

Interestingly, opening the UML model directly with the same editor, it seem sthe
~eGet~ calls returns ~null~ instead of this resolving elist.

But I don't have control over what TemplateSignatureImpl is doing.

However, I don't know /why/ the editor ended up with TemplateSignatureImpl
instance and not a virtual object.

After debugging for a while, I'm lost in a sea of
CreateChildCommand.createCommand thingies.  It looks like these UML2 objects are
coming from inside CommandParameters, but I don't see when these are created.

Breaking on constructors for CommandParameter, I see that ultimately these
objects come from EcoreUtil.create.

So delegating to the EFactory fixes icons in Modisco, but triggers an error in
Sample ECore Editor.

But wait, I had the exception before I made the changes?

Ahah, still the same error.

The raw eClass comes from the StereotypeApplicationItemProvider of UML2.  How
does it extract it?

It builds a list of all runtime EPackages and EClasses.  So the raw UML2 package
is there, as are all its classes.

In ReflectiveItemProvider.getAllConcreteSubclasses, it iterates over all known
classes to find the subclasses of a given class (here, a VirtualEClass).  Since
VirtualEClass correctly handles the isSuperTypeOf call, the item provider
gathers the raw subclass and runs with it.

Yet another pain created by item providers.

Can we override them?  That's what the EView editor does, but is there a way to
override such a provider in other editors?

In [[*Constructing%20a%20VPDL%20for%20a%20coherent%20model][a previous episode]], I found a trick for displaying BPMN correctly.  It still
works for BPMN, but does not solve the UML issue.

That's because the adapter factory for the item provider is ultimately chosen by
ComposedAdapterFactory.getFactoryForTypes, which, at a glance, does:

1. find a factory that has isFactoryForType true for each type
2. if it's not a catch-all EObject/Object factory, return it
3. if there is an adapter factory registered from the extension point, return it
4. otherwise return the catch-all factory

So the factory from the extension point (UMLItemProvider) overrides the
ReflectiveItemProvider adapter factory.

I tried to define an extension point, but it asks for an URI, and in the code it
matches against the VirtualEPackage instance!  It's not the only case in the
registry: I spotted a BPMN (or ReqIF?) instance as a key in there as well.

And there doesn't seem to be a way to add in the registry by using code.

I think I would be better off just polishing up the EView editor for now.

* [2018-03-06 mar.]
** Fixing duplication of features                                  :emfviews:
This only happens with the UML model apparently.

One culprit is VirtualEClass.getAllFeatures method that returns duplicate
features.  Seems wrong to me.  It's an easy fix: just use a Set and return a
list from that.

I don't know why exactly this only happens with UML though.

I probably want to extend the Set fix to other methods in there as well:
superTypes, etc.

Yep, super types also had duplicates in a situation of diamond inheritance.
Turns out, using a set for features started to break tests, because HashSet has
an unspecified order of iteration.  I could fix the tests to not care about the
order... but some internal parts of EMF (e.g. DynamicEObjectImpl) assign numbers
to features, so it's better to keep the order of features as stable as possible.

Using a LinkedHashSet gives us the insertion order, which is what we want here.

* [2018-03-08 jeu.]
** Creating HTML from a view                               :emfviews:eclipse:
Tried with Acceleo.  Looks bloated.

Found some ~.egl~ files in the old examples.  That's from the Epsilon project.

Trying that instead.  I need to install the Epsilon DevTools in order to have
the EGL launch configuration.

But I don't see any model I can load in there.  Installing the Epsilon EMF
DevTools.

This provides the elusive "Register EPackage" on right-click on ECore file!  It
wasn't in Modisco after all.

Adding all plugins in the examples configurations did the trick.  Don't know
which is used by Epsilon though!

Trying to generate a template from a view...

Using the 'EMF Model' type, I can give the Eview file and its metamodels.  EGL
barks when I'm using an unwknown class, like this:

: [% for (b in Banana.allInstances()) { %]

so when I'm using ~TimedAction~, it does not error, indicating that it's able to
load classes from the viewpoint at least.

But the loop does not create anything!  If I try with the Trace model directly,
it works.

Debugging...

Ah!  In AbstractEmfModel.getAllOfKindFromModel:

#+BEGIN_SRC java
final EClass eClass = classForName(kind);
final List<EObject> allOfKind = new ArrayList<EObject>();

for (EObject eObject : (Collection<EObject>)allContents()) {
	if (eClass.isInstance(eObject)){
		allOfKind.add(eObject);
	}
}
#+END_SRC

It's using isInstance, which returns false, since all the Eobjects here are
virtual, and the eClass comes from the concrete metamodel.

Changing to use the Eviewpoint file as metamodel.

But isInstance still fails!  I have implemented it wrong:

#+BEGIN_SRC java
public boolean isInstance(Object object) {
  return concreteEClass.isInstance(object);
}
#+END_SRC

It only works if the given object is concrete.

Hmm, trying the following:

#+BEGIN_SRC java
if (object instanceof VirtualEObject) {
  return isSuperTypeOf(((VirtualEObject) object).eClass());
} else {
  return concreteEClass.isInstance(object);
}
#+END_SRC

Doesn't work because we have /different instances/ of the same EClass
ExecutedAction at runtime.

What I think is happening is that the EView is creating one Viewpoint, which in
turn loads the metamodel from file and instantiate it.  But since we also give
the EViewpoint to EGL, there's another Viewpoint instance, which does the same
thing.

So, does this happen with metamodels not loaded from file?  No.

Well, we do have duplicated virtual EClasses instances.  But the concrete
eClasses are the same, so we can match on that.

Now...

: Property 'name' not found in object Component [name=Component1, ...

Well, looks like the property is there!  What are you doing EGL?

#+BEGIN_SRC java
// Look for a getX() method
ObjectMethod om = registry.findContributedMethodForEvaluatedParameters(object, "get" + property, new Object[]{}, context);
if (om != null) return om;

// Look for an X() method
om = registry.findContributedMethodForEvaluatedParameters(object, property, new Object[]{}, context);
if (om != null) return om;

// Look for an isX() method
om = registry.findContributedMethodForEvaluatedParameters(object, "is" + property, new Object[]{}, context);
if (om != null) return om;
#+END_SRC

Okay.  So you are looking for a Java method ~getname~ on my ... DynamicEObject.
Of course that cannot work.  Why don't you use eGet?

When creating a template for the Trace model, which has no generated code, there
are no issues.

There, it looks up the structural features of the EClass.  If the feature is
found by name, it uses an EmfPropertyGetter to look up the properties.

Hmm, that's puzzling.  In debugging, I can see that it's actually finding the
property without issues.  But at some point it can't?
