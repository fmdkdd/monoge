* [2017-04-03 lun.]
** Notes on setting up for the MoNoGe project              :eclipse:emfviews:
Eclipse 3.8 does not start with Java 9 from Oracle.

: sudo update-alternatives java

-> java8-openjdk was installed on the machine

Installed Eclipse 4.6 anyway.

Additional dependencies for the project:

- ATL
- Xtext
- Epsilon (http://download.eclipse.org/epsilon/updates/)

First two can be installed from Eclipse (Help -> Install modeling components).
Epsilon has an update site.

For running the ECNA2014 demo, I will probably need:

- BPMN 2
- RMF (ReqIf)

Short-term tasks:

- Re-run the examples from the video with the source code
- Learn EMF
- Draw a diagram of how EMFViews works, structurally (what plugin does what, how
  they fit together, etc.)

** Importing EMFViews into Eclipse                         :eclipse:emfviews:
For some reason, when importing the plugin projects, Eclipse thinks the packages
in the src/ folder begin with src.  Save for the very first one.

I just need to open the project properties, go to build path, and click apply.
The src folder is already the build path, but the setting is not applied
correctly.

Then, I also need to add the "plugin dependencies" library for each project.

Doing that for all plugins...

There are still errors from missing dependencies.  Why is there no "one-button"
install?

Finally, some discrepancies in version numbers for our own plugins, that could
be tracked to the way different versions of the plugins have been merged into
the repository.

Only 7 errors left out of >1000 thousands when I started.  The remaining errors
I have to look into the APIs of the libraries to see if some things have changed
since 2013.

* [2017-04-04 mar.]
** Inria provided infrastructure                                   :atlanmod:
R told me about continuous integration server provided by Inria.  They run on
jenkins, and we can have a decent amount of VMs apparently.

They also host a GitLab service, so we could host repositories there as well.

** Understanding the code                                          :emfviews:
There's a feature.xml that seem to describe the EMFViews feature, with juicy
info like dependency with version numbers:

: <import plugin="org.eclipse.uml2" version="4.0.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.emf.ecore.xmi" version="2.7.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.uml2.uml" version="4.0.0" match="greaterOrEqual"/>

Not all dependencies have explicit version numbers, but that's a start.

There's also a discrepancy in version numbers: in the feature.xml file, all the
plugins have the version "0.2.0.qualifier", but in the MANIFEST.MF for the
EMFViews plugin, we ask for 1.0.0 versions:

: Require-Bundle: org.eclipse.emf.ecore,
:  org.eclipse.emf.ecore.xmi;bundle-version="2.7.0",
:  fr.inria.atlanmod.emfviews.vlink-mm;bundle-version="1.0.0",
:  org.eclipse.core.resources;bundle-version="3.8.1",
:  fr.inria.atlanmod.emfviews.virtuallinksdelegator;bundle-version="1.0.0",

I understand we also have code generated from ECore models (vlink-mm) which is
checked in the repo.  Since the code is generated from the model, it might make
more sense to not check it in, and regenerate after a ~build~ step.

Other discrepancy: copyright attribution on the feature.xml file is for Inria
Rennes Bretagne Atlantique, while the rest of the plugin, you can see individual
contributor names.  Which is it?

* [2017-04-05 mer.]
** Exploring Eclipse                                     :eclipse:
Specifically, I'm interested in understanding how and where Eclipse saves
preferences for a project: dependencies, how to build, etc.

That's important when putting these things into a repository.

For instance: when I "Run as.. Eclipse Application" an Eclipse plugin like the
one from this [[http://eclipsesource.com/blogs/tutorials/emf-tutorial/][EMF tutorial]], it runs the new Eclipse under another workspace.
The path of this new workspace is specified by the "Eclipse Application" run
configuration.

By default, it is:

: ${workspace_loc}/../runtime-EclipseApplication

So it creates a folder above the current workspace.  Since my workspace is in
$HOME, it creates $HOME/runtime-EclipseApplication.  But, for the purpose of the
tutorial, the files I create in this new workspace should reside inside the
repository.  So, I rather want:

: ${project_loc}/../runtime-EclipseApplication

so it creates the folder at the same level of the project folder I am running.

Now, where is this preference saved?

: $ rg --hidden "project_loc" ./eclipse/ eclipse/ workspace/ proj/monoge/emftuto/
: workspace/.metadata/.plugins/org.eclipse.debug.core/.launches/Eclipse Application.launch

In my workspace.  I guess it makes sense since "Run as..." is an Eclipse thing,
so it should be an Eclipse pref.

But, if you checkout the repository, you would have to manually replicate the
"Run as..." setting in order to get my examples working.

One solution is to export the workspace preferences and put it in the
repository.  So at least, if you use Eclipse, you can import these settings as a
one-click solution.

** Speeding up Eclipse                                              :eclipse:
Even on a powerful and recent machine, Eclipse is quite slow and feels
unresponsive.  Things to set in eclipse.ini to ([[https://www.eclipsecon.org/europe2015/sites/default/files/slides/Boosting%2520the%2520Performance%2520of%2520your%2520Eclipse%2520IDE_0.pdf][allegedly]]) speed it up:

#+BEGIN_EXAMPLE
-server
-Xms512m
-Xmx2g
-Xmn512m
-Xverify:none
-XX:+AggressiveOpts
-XX:+UseParallelGC
#+END_EXAMPLE

Removing unnecessary stuff also helps: Git control, startup plugins,
auto-updates, etc.

Curiously, in the Modeling Tools distribution, there is another EGit plugin that
you also have to remove.

** Trying to replicate the ECNA2014 demo                           :emfviews:
I've got the emfviews plugin building without errors in Eclipse.  Run
as... application (I guess?)

Now to create an EAdata project, add the travelAgencyEA.xmi.

Uhoh, error:

: http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0' not found

Hmm hmm.  Maybe I need [[https://github.com/ObeoNetwork/TOGAF-Designer][this plugin]]?

Getting the source, adding the plugin (subfolders) to the EMFViews workspace,
and adding them as a dependency for the EMFViews plugin, running "Run as.."
again.  I can check in Help -> Installation details of the recursive Eclipse
that EMFViews and TOGAF plugins are both present.

After that, opening the travelAgencyEA.xmi again yields:

: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'belongsTo' not found. (platform:/resource/EAdata/models/1_travelAgencyEA.xmi, 26, 270)

A bunch of them.  'isOwnedByUnit', 'communicatedWithFunctions',
'providesEntities', 'containers', 'labels'.

And some IllegalValueExceptions:

: Value 'BusinessService[TRANSIENT]' is not legal. (platform:/resource/EAdata/models/1_travelAgencyEA.xmi, -1, -1)

Could it be a mismatch between the TOGAF version I'm using and the one used in
the demo?

Grepping around the TOGAF repo, I can see hits for these strings, especially in

: plugins/org.obeonetwork.dsl.togaf.contentfwk/model/contentfwk.aird

#+BEGIN_EXAMPLE
1277:      <ownedDiagramElements xmi:type="diagram:DEdge" xmi:id="_eyUzMP63Ed-AK7xgn-H1PA" name="[0..1] isOwnedByUnit - [0..*] ownsFunctions" sourceNode="_ugYTwJ-9Ed-hg-_nMagkzg" targetNode="_zjeaMJ-9Ed-hg-_nMagkzg">
1280:        <semanticElements xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2562:        <lines xmi:type="table:DLine" xmi:id="_BsDvz6AREd-mRqry0T_xvQ" label="EReference : isOwnedByUnit">
2563:          <target xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2564:          <semanticElements xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
2567:            <target xmi:type="ecore:EReference" href="contentfwk.ecore#//Function/isOwnedByUnit"/>
#+END_EXAMPLE

I can also see these strings in the EA.ecore metamodel, and these looks like
definitions.

Maybe the example was self-sufficient after all.  But how to link the XMI file
to an ECore metamodel?

Further investigation.  If I load up the TOGAF contentfwk model (one I found to
load it is to create a dummy ECore file, and Right click -> Load resource, and
look for the obeo URL near the bottom).

I can see the mismatch.  The TOGAF contentfwk has, in the Function class:

- communicatesWithFunctions
- isOwnedByOrganizationUnit

whereas the EA.ecore has:

- communicatedWithFunctions
- isOwnedByUnit

So the errors make sense.  And, it would seem that I need to point the XMI files
to use my EA.ecore metamodel.

Looking for help.. G helpfully answered my questions:

You can't link an XMI to an Ecore as-is.  Eclipse has a global registry of
metamodels, and there is no way to Right-click on an Ecore file, and add it to
the registry.

(Unless, possibly maybe, through some ATL plugin, but I don't have it installed
right now)

The alternative is to generate plugin code from the Ecore metamodel, and "Run
as.." again.

So:

In the base Eclipse workspace (where the EMFViews plugin resides), create an
empty EMF project add the EA.ecore file to the model folder.  Create a genmodel
file, and generate the model code.

Then, launch the recursive Eclipse.  All open projects will be loaded as
plugins, so no need to add this project (or TOGAF) as dependency to EMFViews.

This time, I can load the XMI without troubles.

The two other XMI files require BPMN2 and ReqIf10.  At this point, I'm
remembering that the emfviews repo had a "dropins" folder containing JAR files
for BPMN, ReqIf and.. TOGAF contentfwk.  And eclipse has a dropins folder as
well.

I'm thinking that the dropins are supposed to be added to Eclipse in order to
run the examples.

And indeed, it works.
For BPMN2 and ReqIf.  For TOGAF, I get a NullPointerException when trying to
open the Ecore file.  So maybe sticking to what I have generated is better.

Next step in the demo is to create an EMF Viewtype through an Eclipse wizard.  I
don't have that wizard in my recursive Eclipse.  Probably because the "editor"
and "ui" plugin projects are closed in my base Eclipse.

Let's open them.

Uhoh, compile error.

: Viewtype.getHiddenElements()

is undefined.  There is a ~getHiddenAttributes()~ method though.  Let's try
that.

Haha!  Now I have the wizard in my recursive Eclipse.  Clicking next
enthusiastically and:

: java.lang.ArrayIndexOutOfBoundsException: 0
: 	at fr.inria.atlanmod.emfviews.ui.wizard.view.CreateViewtypeScreen.createControl(CreateViewtypeScreen.java:132)

:(

Time to quit for the day.

* [2017-04-07 ven.]
** IndexOfOfBounds exception                                       :emfviews:
Okay so, the incriminating line:

: comboLinksDsl.setText(availableLinksDsls[0]);

We made no provision to check that this array (of strings) had any element, and
we access the first one.

Let's add a check.  I guess I'll be greeted by an empty window, since it means
we haven't found any LinkDSL, but at least I won't crash.

(Though, like JavaScript, Eclipse doesn't crash: it just throws an Exception and
keeps going).

Changing the array value at runtime in the debugger to {"foo"} let me proceed.
I can add the metamodels.  But I can't select any linking DSL (since there is
none, and "foo" isn't a valid one I'd wager).

(To change an array of String in the debugger, right-click -> change value, and:

: return new String[]{"foo"}

primitive values are easier to change, usually just click.)

Still, it let me proceed to the next screen.  Of course, "Finish" triggers a
NullPointerException.

In the demo video, he has "ecl" as DSL language.

Looking at the code that populates availableLinksDsls, it iterates into:

#+BEGIN_SRC java
extensions = Platform
				.getExtensionRegistry()
				.getExtensionPoint(
						"fr.inria.atlanmod.emfviews.virtuallinksdelegator.type")
				.getExtensions();
#+END_SRC

But this is also empty.  I guess because I haven't opened
virtuallinksepsilondelegate.  Let's do that.

I need ECL to compile it.  It comes from org.eclipse.epsilon.  Let's not install
that into Eclipse, but put the JAR in dropins instead.  Wait no, I don't want it
to run as plugin in my Eclipse.  I just need to add it as a dependency to the
project.

Import errors disappear.  Other errors appear.  Deprecated methods
and... methods that are not here anymore.  Presumably because I got the latest
ECL version, and the project used another one.  Is there any trace of the
versions we used previously?

In emfviews/feature.xml:

: <import plugin="org.eclipse.epsilon.ecl.engine"/>
: <import plugin="org.eclipse.epsilon.eol.engine" version="1.0.0" match="greaterOrEqual"/>

Let's try the 1.0.0 version then.  It's from 2012.  I guess the project was
working in 2016, so let's try the 1.3 instead.

1.3 makes one error disappear, still 2 left.  1.2 has only deprecation warnings.

Still errors in the MANIFEST file for unmet dependencies.  But it's for stuff we
don't need, otherwise we wouldn't compile, right?  Let's ditch them.

Ah!  I've got "ecl" in the dropdown menu now.  But clicking "Finish" triggers a
NullPointerException in CreateViewtypeWizard.  It's because we want to open the
newly created .eviewtype using our editor for that file type, and we fail in
Viewtype.loadFilterMetamodel:

#+BEGIN_SRC java
private void loadFilterMetamodel(String filtersMetamodel) {
  ResourceSet filtersResourceSet = new ResourceSetImpl();
  attributesToHideMM = filtersResourceSet.getResource(URI.createPlatformResourceURI(filtersMetamodel, true), true);
}
#+END_SRC

because filtersMetamodel is null at this point.

Culprit: Viewtype.doLoad which pass

: loadFilterMetamodel(properties.getProperty("filtersMetamodel"));

but there is no "filtersMetamodel" property there.  "properties" is created from
parsing an inputStream which seem to correspond to the contents of the eviewtype
file.  And the eviewtype file has no filtersMetamodel value.

When is this written?

Line 545, in Viewtype.serialize.  It puts the value of ~filtersMM~, which is a
String, and populated in the constructor of Viewtype.  Hmm, so that's actually
just the serialization of a Viewtype, but since the constructor already calls
loadFilterMetamodel, I guess this is the wrong place.

In CreateViewtypeWizard.performFinish, we are writing to the eviewtype file.
Then it calls

: serializeViewtype(viewTypeFile, fileContent);

Stepping through CrewteViewtypeWizard.performFinish, there is no code adding the
"filtersMetamodel" line.  And I see no trace of code that /would/ add these
lines to the file.

Also, in the video, there are four files created by the wizard: an ECL, an
Ecore, an EViewtype and an XMI.

I've only got two: EViewtype and XMI.

Strange.

** Reading about Eclipse as a platform                              :eclipse:
http://www.aosabook.org/en/eclipse.html

All classes in a plugin are not considered part of the plugin API.  You need to
define extension points for that.  Visibility of class/method/attributes
is presumably restricted to your plugin.

At Eclipse startup, all plugins manifests are scanned to know the extension
points in advance, but the plugins themselves are not loaded.  It's very much
like Emacs autoloads: they give an example of a plugin adding a menu item, and
only when the user clicks on the menu item will the corresponding plugin be
actually loaded.

Instead of Swing or AWT, Eclipse uses SWT as widget toolkit.  JFace comes on
top, and provides frameworks for preferences and wizards.

Hmm the bit about plugin class visibility is somewhat in contradiction in \sect6.2:

#+BEGIN_QUOTE
If plugin A requires plugin B, plugin A can see all the Java classes and
resources from B, respecting Java class visibility conventions
#+END_QUOTE

Ah I get it know: the above describe the situation before the move to OSGi, and
the paragraph at the start describes the situation after the move.

#+BEGIN_QUOTE
With the switch to OSGi, Eclipse plugins became known as bundles. A plugin and a
bundle are the same thing [...]  Previously, dependencies, exported packages and
the extensions and extension points were described in plugin.xml. With the move
to OSGi bundles, the extensions and extension points continued to be described
in plugin.xml since they are Eclipse concepts. The remaining information was
described in the META-INF/MANIFEST.MF, OSGi's version of the bundle manifest.
#+END_QUOTE

Good news: OSGi supports semantic versioning, very much like SemVer:

major.minor.service.qualifier

Increment major when breaking API
Increment minor when adding API
Increment service for bug fixing
Qualifier is used to indicate a build tag

It's OSGi that takes care of resolving dependencies for a package.

Ah: apart from the extension registry in Eclipse, there is also a service
registry provided by OSGi.  Unlike extensions, services can be discovered
dynamically, after startup.

#+BEGIN_QUOTE
A feature is a PDE (Plugin Development Environment) artifact that defines a set
of bundles that are packaged together in a format that can be built or
installed. Features can also include other features.
#+END_QUOTE

p2 has replaced Update Manager for provisioning Eclipse.  Might be useful for
continuous integration.

** What if I provide filtersMetamodel myself?                      :emfviews:
Since it seems this line is not going to write itself in the eviewtype file,
might as well put it, just to see if the rest of the demo can work.

Ah yes, of course, it points to an ECore file that was also not generated.
Let's bring that in.

Hmm, this time I have a NPE in ViewtypeEditor.createViewtypeTreeEditorPage,
at this line:

: treeViewer.setInput(((Viewtype) viewtypeResource).getResourceSet().getPackageRegistry().values());

because the ~getResourceSet()~ returns null.  The viewtypeResource is populated
from the file at the beginning of the try block:

: viewtypeResource.load(uri.toURL().openStream(), new HashMap<Object, Object>());

and after that, the resourceSet attribute is null.

Since viewtypeResource is an EMF Resource object, maybe a change in the EMF API?

I am tempted to try archeology and rebuild an environment circa 2014.  Here I've
got EMF Ecore 2.12.0 and the feature... has no version requirement.

But, there are version requirements for:

: <import plugin="org.eclipse.emf.ecore.editor" version="2.8.0" match="greaterOrEqual"/>
: <import plugin="org.eclipse.emf.ecore.xmi" version="2.8.1" match="greaterOrEqual"/>

and I've got 2.12 loaded, again.  So since these are part of EMF, a safe guess
would be to find EMF Ecore 2.8.

2.8 is from 2012.

Now, according to the semantic versioning, that shouldn't change anything,
right?

Hmm, trying to put the EMF 2.8 JARs into a copy of my Eclipse Neon 3 resulted in
lots of deep stack straces and an error at launch.  p2 couldn't resolve the
frankenEclipse I created I guess.

Let's get a MDE Eclipse circa 2012 then.  Luna is the first version supporting
Java 8.  That's 2014; maybe it will still make a difference.

Ah of course, I have to set up a new workspace.

Hmm, just importing the projects, and everything builds without errors.
Adding dropins, TOGAF project...

And same exact error!  ViewtypeEditor.createViewtypeTreeEditorPage.

So I guess I would like to know what a ResourceSet is, and what value it should
take at this point.  Maybe brush up my EMF knowledge.

* [2017-04-10 lun.]
** Trying to replicate friday's situation: new error       :eclipse:emfviews:
Can't even get to the EViewtype creation wizard as Eclipse crashes on load with:

: org.eclipse.core.runtime.CoreException: Plug-in "fr.inria.atlanmod.emfviews.virtuallinksepsilondelegate" was unable to instantiate class "fr.inria.atlanmod.emfviews.virtuallinksepsilondelegate.EclDelegate".

How in hell did it work Friday?

Looking at changes I did on the project in Git... wow, there are .class files
checked in.

There are also ~._trace~ files, which I understand are generated by Xtex.  Since
I'm not dealing with Xtext there, and these are generated files, I'd rather get
rid of them.

Some .classpath are checked in, some are not.

Let's just remove the useless files and ignore them to get a usable git diff.

Now, I did modify the MANIFEST which included ECL.  Maybe this wasn't a good
idea?

If I restore these lines, Eclipse complains that it cannot resolve bundles
pertaining to ECL in the MANIFEST of virtuallinksepsilondelegate.

The JARs are in the build path, but maybe they need to be loaded into Eclipse
instead.  Let's remove them from the build path.  Cannot build now because
imports are not resolved.  Let's add them as drop-ins.

Hmm, they don't seem to be recognized when added to the dropins folder.

Opening Window -> Show view -> Error log displays the errors when loading
Eclipse.  To start, I can see that it's trying to load the Git plugin for each
project, even though I've removed it.

Removing all org.eclipse.team plugins fails to start Eclipse.  It's not as
modular when many pieces depend on each other!

Restoring team.core and team.ui did the trick.  At least I got rid of CVS.
I might investigate a minimal Eclipse setup another time.  And one that can be
auto-provisioned trough a config file for reproductibility.

Still have GitProvider errors.  Why is it trying to load the plugin?  Since I
see to Git-related feature under eclipse/features, I'm guessing Git is tightly
integrated into another feature that is still being loaded.  Ugh.

In any case, I can see errors related to my dropins JAR:

#+BEGIN_EXAMPLE
!ENTRY org.eclipse.equinox.p2.publisher.eclipse 4 0 2017-04-10 15:04:47.288
!MESSAGE Unable to acquire PluginConverter service during generation for: /home/fmdkdd/eclipse/dropins/epsilon-1.2-emf-src.jar.

!ENTRY org.eclipse.equinox.p2.core 4 0 2017-04-10 15:04:47.411
!MESSAGE Provisioning exception
!STACK 1
org.eclipse.equinox.p2.core.ProvisionException: No repository found at jar:file:/home/fmdkdd/eclipse/dropins/epsilon-1.2-emf-src.jar!/.
#+END_EXAMPLE

(the Error log view just pretty prints the content of .metadata/.log ... without
giving you the ability to copy lines; and why is there a hidden file in a hidden
folder?  Grmpf).

Maybe, the 1.2 JAR of Epsilon is not OSGi compliant or whatever.  Let's try to
dropins the 1.4.

Hmm nope, same error.

Okay then let's install them from inside Eclipse.  Version 1.2, preferably.

That does get rid of the build errors and MANIFEST errors.  Now, to run.

I have worrying warnings in my .log though:

: org.eclipse.core.runtime.CoreException: Executable extension definition for "class" not found.

But, I can launch the recursive Eclipse.  So, lessons learned:

Required bundles are actually runtime requirements?

** Explaining the discrepancy with the 2014 demo                   :emfviews:
According to H, the previous engineers might have already started some
refactoring in the goal of simplifying Viewtype creation.  In the demo, we see
an Ecore file being created along the Eviewtype.  That's something H did not
want, since we could just register the selected filters in the XMI itself.

In the current version, there is no Ecore file being generated, and the
XMI contains the line:

: <linkedElements elementRef="//Process" modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0" name="Process" estructuralFeatures="isAutomated"/>

which corresponds to what I've cliked on in the last step of the wizard.

In emfviews.core.Viewtype, there is a serialize method that added the
filtersMetamodel line that was in the demo.  It isn't called anymore by the
wizard.

Looking through the history of this file and in the commit history, all I can
see is that there was a first version of emfviews (0.1 I presume) with a vastly
different Wizard.  Then there was a version 2 (0.2), where the wizard was
changed to basically what I have inherited.

In any case, we don't have a definitive reference of source of truth for "how it
should work" other than examples and videos.  Possibly outdated.

Better brush up my knowledge of Eclipse plugins and EMF.

** A clean Eclipse                                                  :eclipse:
I've found the minimal Eclipse experience:

From [[http://download.eclipse.org/eclipse/downloads/][this page]], go to the latest release, and grab the "Platform runtime binary"
for your arch.

Very snappy Eclipse.  No crap like Mylin and EGit installed by default.

Then, I can pass a configuration folder on the command line:

: eclipse -configuration ~/eclipse-configs/test/configuration

From there, I can install new software from inside eclipse, and they will be
installed at eclipse-configs/test/plugins.  The eclipse-configs/test folder
becomes the new home folder for eclipse.

No pollution between configurations.

So that's good for reproductible environments (except, you know, the manual step
of actually provisioning Eclipse with the new packages).

But now if I need to install the Java dev tools for every
configuration... or even update them... that's going to be a pain.  Ideally, I
read somewhere that p2 was able to pool from a common bundle.  So I should be
able to download all this stuff in just one place, then let Eclipse get the
plugins from one pool.

But I really don't want Eclipse to load /all/ the plugins in the pool.  Even if
it's "lazy-loading" them, it's still taking ages AND I have no say in how
what plugins are /actually/ loaded even if I don't use them.

* [2017-04-11 mar.]
** Trying bundle pools in Eclipse                                   :eclipse:
For speeding up provisioning, and making updates more sane.

I tried to use Oomph, which is actually the Eclipse Installer, the default
download provided by Eclipse.  In the advanced mode, you can select the Eclipse
Platform, and additional projects.  Except, these are pulled from master and put
/into/ your workspace; not additional plugins.  The use case this solved is when
you want to contribute to some Eclipse project.

It also works with any Github project, so I guess you could use Oomph to
somewhat easily provision an Eclipse to work on EMFViews.  You just have to say
"pick the MDE product, then add EMFviews, done".

But in my case I don't want all the cruft.

What you should be able to do is run Oomph, install an Eclipse platform, and
that Eclipse will be setup to get its bundles from the bundle pool.  Except
Oomph fails to install Eclipse platform.

Well, so much for saving bandwidth.

** Installing EMF tools in the platform                             :eclipse:
So installing the EMF sdk feature is apparently not enough to run the tutorial.
I lack emf.edit.  Even though they are part of EMF Core, according to [[http://www.eclipse.org/modeling/emf/][the
website]].

Maybe I'm not pulling from the correct update site?

Adding the update site mentioned on [[http://www.eclipse.org/modeling/emf/updates/][this page]] does not work.  After adding it to
the available sites list in the preferences, and loading up the preferences
again, the site has mysteriously disappeared.

But, there is an update site with URL:

: http://www.eclipse.org/modeling/updates/

disabled by default.  Enabling it and going through "Install new software",
selecting it...

waiting a long time...

Now it has added a bunch of other sites (what?)

And I can install EMF... 2.7.  From 2012.

Gosh, why is this so hard?

On [[http://www.eclipse.org/modeling/emf/downloads/][this page]], it seems I can /download/ an update site containing EMF.  So let's
try to add this ZIP as a local update site.

It does not disappear from the list when I leave it there.

And it's lightning fast when I go into "Install new software".  And it's version
2.12

But EMF Edit is grayed out, since it's already installed.

Removing... installing from this local update site...

EMF edit plugin is marked as loaded in Eclipse, but it's marked as not found in
the plugin.xml dependencies.

Let's remove everything EMF related, and try to load it as a dropin.

There's no dropins folder in my test configuration.  AAArgh.

There's one in eclipsen/platform though.

Hmm, maybe I only have the /runtime/, and not the SDK.  That's another download
on the page.  Let's try that.

Well, the SDK feature seems to only add documentation and source.  No
difference.  Other than that, still not finding emf.edit.

Ah, it works!  [[https://www.eclipse.org/forums/index.php/t/134617/][This thread]] was golden.  Apparently, for building plugins, you
need to setup the Target Platform correctly.  And, for some reason, even though
in my two workspaces they target platforms are set up correctly, they do not
find the same plugins.  One finds 190 plugins, the other 316.

Trying to clean up my test configuration now... trying to install things in
dropins, but that's a BadIdea.  Stuff's missing.  "Install new software" works
when I pull from the default update sites.

Installing PDE, JDT and EMF is enough to be able to run the tutorials.

** Eclipse plugin tutorial                                   :eclipse:plugin:
Following "Eclipse 4 plug-in development by example", by Alex Blewitt, Packt
Open Source.

Plugins which add to the UI or require the UI to operate conventionally have
'ui.' in their package name.

MANIFEST.MF file is for dependencies (OSGi-related stuff).  While the plugin.xml
file is for describing extensions and extension points.

Having extensions described as XML speeds up plug-in loading: you don't have to
execute any code of the plugin (though you do need to parse XML).

** Some links on building plugins with Maven+Tycho           :eclipse:maven:
https://zeroturnaround.com/rebellabs/building-eclipse-plug-ins-with-maven-3-and-tycho/
http://www.vogella.com/tutorials/EclipseTycho/article.html

* [2017-04-12 mer.]
** Eclipse plugin tutorial (cont.)                           :eclipse:plugin:
Clock tuto.

Some issue with Display.getDisplay() that crashes when launching Eclipse with
multiple monitors.  Did not happen when hot loading the code.

How are you supposed to get the current display then?

* [2017-04-14 ven.]
** Eclipse plugin tutorial (cont.)                           :eclipse:plugin:
Re: error from last time.  [[http://stackoverflow.com/questions/33157856/getting-swterror-not-implemented-multiple-displays-with-simple-code-sample][Found someone]] who raised the error on SO.  No answer,
no fix.

From what I gather, you /shouldn't/ use Display.getDisplay, since it creates a
new display (that you need to dispose of).

(Also, the error has nothing to do with multiple /monitors/, but multiple
Display objects as understood by Eclipse.)

If I use Display.getCurrent instead, I get null back, since no display has been
created when Activator.start is called.  Another suggestion is to use:

: PlatformUI.getWorkbench().getDisplay()

this also fails on startup with:

: java.lang.IllegalStateException: Workbench has not been created yet.

Again, it seems the plugin is started very early in the process.  One workaround
would be to create the tray item as soon as the workbench started.  This is
[[https://wiki.eclipse.org/FAQ_Can_I_activate_my_plug-in_when_the_workbench_starts%253F][possible]].

Yep, this works nicely.

** Resource management in JFace and SWT
SWT has manual resource management: when create instance of Color or Image, you
are supposed to .dispose() of them when you don't need them anymore.  That way,
SWT, releases the associated native objects.

JFace has resource registries to deal with the allocation and disposal of resources.

* [2017-04-19 mer.]
** Nearly done with the Eclipse Plugin book                  :eclipse:plugin:
Lots of learning were had.

Chapter 9 touches automated testing with JUnit.  Nothing fancy; plugins just
need to run with a special JUnit configuration.

More interesting is the UI testing with SWTBot, to simulate click and go through
the UI programmatically.  It's fun seeing Eclipse launch and crunch through
dialogs at inhumane speeds.

Although, even if the JUnit bar fills with green, I get a bunch of Exceptions in
the host console after the tests are run.  Presumably, SWTBot is too fast for
Eclipse, and does not take care of disposing some resources properly when
exiting then client instance.

: org.eclipse.swt.SWTException: Failed to execute runnable (org.eclipse.swt.SWTException: Widget is disposed)

** Building the plugins with Maven+Tycho                      :maven:plugin:
Following Chapter 10 of the book.  Apart from writing XML files, it's rather
smooth.

: mvn clean package

seems to poll the Eclipse update sites on each build, which takes a loooooooong
time.  You can avoid that check with the ~--offline~ flag:

: mvn --offline clean package

Hmm can't seem to run the SWTBot tests using Maven.  Might be that the book is
slightly outdated, as it was tested with Tycho 0.18, whereas we now have Tycho
1.0.0.

[[http://www.vogella.com/tutorials/EclipseTycho/article.html][This tutorial]] is fresher.

Still have troubles loading requirements for the test... It seems the client
Eclipse launched by Maven is really barebones (good): there are basically no
views!

I should at least get the Clock View that the tutorial plugins adds.

From what I understand, Maven /should/ obey the plugin dependencies in the
MANIFEST file.  But the runtime target configuration is different.

Maybe try to test with a barebones run configuration in Eclipse itself.

* [2017-04-21 ven.]
** Getting Maven+Tycho to run the tests                        :maven:plugin:
Trying with a barebones run configuration in Eclipse.

Only adding "Required plugins".  Cannot validate due to a not very talkative
error:

: org.eclipse.e4.ui.workbench.swt [9]
: Unresolved requirement: Require-Capability: osgi.extender; filter:="(&(osgi.extender=osgi.component)(version>=1.2)(!(version>=2.0)))"

Maybe it's a [[https://bugs.eclipse.org/bugs/show_bug.cgi?id=494913][bug]]?  Anyway, adding org.eclipse.equinox.ds and clicking "Required
plugins" (for the requirements of equinox) fixes it.

Another way to do it is to add equinox.ds to the dependencies in the MANIFEST,
saving it, and and clicking "Required plugins".  But at this point I don't know
if these dependencies should be declared in the MANIFEST itself...!

Now:

: org.eclipse.core.runtime.AssertionFailedException: null argument:Could not find IExtension for application: org.eclipse.ui.ide.workbench

I know that it works if I select all plugins in the Target Platform, so the
question is: which plugin is missing?

: org.eclipse.ui.ide.application

seems to do it.  At least the client Eclipse runs, but the tests all fail, and
the console is full of:

: Event Admin service is not available, unable to publish event org.osgi.service.event.Event

Adding org.eclipse.equinox.event to the dependencies solved it.  Thanks [[https://www.eclipse.org/forums/index.php/t/293382/][thread]].

Now only the third test fails:

: org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException: Timed out waiting for tree item General

Because when SWTBot does File->New->Project, the dialog is empty.  There's no
General folder.  There's only "Project", no categories.  Hmm, then I can just
use "Project" without adding another dependency.

It works.. not.  It creates the project, but the assertion fails.  Somehow it
runs too fast and does not wait for the project to be created.  Adding a
bot.sleep does it, but there's a nicer way with wait conditions.

Okay so now, back to Maven.

: Tests run: 3, Failures: 0, Errors: 0, Skipped: 0

Actually, before that, I had to remove one testUI that's just too brittle, the
one testing against the String value of the SWTBot shells.

But, it works.

** General best-practices for Eclipse plugins               :eclipse:plugins:
In Mastering Eclipse Plugin Development, by the same author as the tutorial book
I finished this week, there's a chapter Designing Modular Applications with some
pointers on best practices for Eclipse plugins.

How semantic versioning works for Java.  Like semver, adding a method is a minor
increase, changing or removing API is a breaking change.  In Java, adding
methods to interfaces is a breaking change, since classes that implement this
interface have to be modified.  Interfaces can be @noimplement, and adding
methods to these is only a minor version increase.

There's also the @since annotation which is rather useful.

There are tools for looking at the API of your releases and suggesting the
correct semantic version increases, like the API baseline in Eclipse.  Maven can
also do it.

** State of EMFViews                                               :emfviews:
We have no tests.  But, there are 15 examples in the examples/ folder.  Do they
still all work?

I've already asserted that the project is not in the state of running the ECNA
demo from 2014.  (Might not be too far, but things have changed since the demo
at least).

The examples are mostly models: XMI, Ecore, UML files.  Cloc is in fact totally
unable to give me a count, as it ignores basically all files except one in this
folder.

More interesting is when I cloc the plugins directory:

#+BEGIN_EXAMPLE
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Java                           223          12613          19404          36444
Assembly                         3              0              0           6062
XML                             14             44             18            978
-------------------------------------------------------------------------------
SUM:                           240          12657          19422          43484
#+END_EXAMPLE

That seems like a lot of Java.  And assembly, strangely.  But many Java files
are in fact generated.  Let's look at only emfviews.* plugins.

#+BEGIN_EXAMPLE
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Java                            58           1268           3376           4856
XML                              7             11              2            149
-------------------------------------------------------------------------------
SUM:                            65           1279           3378           5005
-------------------------------------------------------------------------------
#+END_EXAMPLE

Less daunting.  Many files are smallish to tiny:

: cloc --by-file plugins/fr.inria.atlanmod.emfviews.* | cut -c180-190

#+BEGIN_EXAMPLE
588
272
234
204
188
179
173
167
154
153
139
134
129
126
126
113
110
106
98
93
83
82
77
77
74
73
70
65
60
58
56
55
54
51
50
48
43
38
37
31
24
24
21
20
20
19
16
15
15
15
15
15
15
12
11
11
10
10
10
9
7
7
6
5
5
#+END_EXAMPLE

The largest one is emfviews.editor.editors.ViewtypeEditor, which looks all hand
coded and not generated.

[Still have issues with Epsilon missing; have to install 1.2 from the update
site; ecore, ecore development tools, emf; and also UML2 extenders from the Neon
update site... it builds!]

Now let's look at the dependencies.

* [2017-04-24 lun.]
** Dependency graph for EMFViews                                   :emfviews:

[[file:doc/emfviews-plugin-dependencies.svg]]

All the beige boxes are plugins, eggs don't have a plugin.xml, and all are
included in emfviews.feature.

Most depend on the VirtualLinks model, as expected.

Even though it's included in the feature, emfviews.util has no plugin.xml, and
contains only public static methods.

Curiously, virtuallinksocldelegate does not depend on virtuallinksdelegator,
because it does not implement the interface IVirtualLinksDelegate, even though
virtuallinksepsilondelegate does.

In fact, I'm not sure the OCLDelegate is plugged into anything.  The
VirtualLinksDelegator declares an extension point that is used by the
EpsilonDelegate, but not the OCLDelegate.

There are also two plugins (cream) not declared by the feature.  They don't
compile due to change to emfviews.core, so not sure what their role is.

Other plugins: vpdl.dsl.* and monoge.dsl.*.  VPDL is the View Point Description
Language mentionned in the EMFViews paper.  It seems monoge.dsl.* fits the same
role; all of it was added in one commit title "Added DSL for metamodel
extension".  It might do more.  Hard to say.  Most of it is generated by Xtext.
Have to lookup how Xtext works.  On a cursory examination, monoge.dsl.* seems
less fleshed out than Vpdl.

** Point with H                                                    :emfviews:

- Merge emfviews.util in emfviews preferably
- Merge virtuallinksdelegator in vlink-mm
- monoge.dsl is the DSL for the second paper, vpdl.dsl is the DSL for the first
  paper.  Both are useful, but will be tackled later.
- Check for dead code, duplicates.
- Remove unnecessary dependencies that come from transitivity (if you include
  emfviews, you don't need to include vlink-mm explicitly).

* [2017-04-25 mar.]
** Cleaning up warnings                                            :emfviews:
Mostly generics missing, unused vars, and other niceties.

Could not get at everything, since I don't understand the code fully yet.

* [2017-04-26 mer.]
** Still cleaning up and formatting                                :emfviews:
The autoformatter of Eclipse is helpful, but for wrapping especially, multiple
rules can apply, and I'm not sure of the priority between them.  At least, the
process is deterministic (I hope).

Some things are plain weird in the code.  Pretty sure I am looking at dead code
sometimes, but Eclipse cannot tell me that because these are all plugins, and
public methods are part of the API.

Trying to eliminate the dead code...  Eclipse can tell me if a method is used
in the workspace with Ctrl+Alt+H.  That's helpful.  Then, let's say method M is
unused and I remove it.  M called A.  Now A is unused, and Eclipse tells me so.
But if A was the sole caller of B, Eclipse does not immediately tell me by
transitivity that B is also unused.  A bit annoying.

Wait no.  That's not the good approach.  If B subclasses A, and B is given as an
A somewhere, Eclipse can't know that the overridden methods in B will be
called.

Checking for unused constructors I think should be safe.  Static methods as
well.  And methods that are not overridden.

The case of emfviews.elements.MergeElementsImpl is curious: I can't find any
calls for its constructor, but there are references to /casts/ to this class.
Maybe the instances are created through reflection somewhere, but grepping
around does not help.  Also, it seems it's only partially implemented, as
presumably emfviews.rules.MergeRule is strongly related, and most of the methods
there return null.

So, I'm not sure what's truly dead code and what was just forgotten.  Observations:

In emfviews.ui.CreateViewWizard.performFinish, I have a
EMFViewsFactory.createEView call that's seemingly unused.  Instead, we write
directly to a file in the code that follows.  Same thing with the createViewtype
constructor in the factory; it's called nowhere, and in turn one Viewtype
constructor is never called.  In Viewtype.serialize, there's a bunch of stuff
that's eerily similar to EView.serialize.

That was a part that didn't seem to work when I tried to replicate the ECNA
demo... definitely a hot point.

* [2017-04-28 ven.]
** Looking at the examples                                         :emfviews:
Okay so from what I can see, the examples all contain model files (ECore, XMI,
UML).  No code.

Crucially, the only instructions to use the examples are in videos.  Some
examples contain already-created viewtypes and views.

Opening a viewtype file with the viewtype editor throws an exception:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at org.eclipse.emf.common.util.URI$URIPool$PlatformAccessUnit.setValue(URI.java:865)
	at org.eclipse.emf.common.util.URI$URIPool.intern(URI.java:1949)
	at org.eclipse.emf.common.util.URI.createPlatformResourceURI(URI.java:2680)
	at fr.inria.atlanmod.emfviews.core.Viewtype.loadFilterMetamodel(Viewtype.java:171)
	at fr.inria.atlanmod.emfviews.core.Viewtype.doLoad(Viewtype.java:160)
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:1518)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createViewtypeTreeEditorPage(ViewtypeEditor.java:118)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createPages(ViewtypeEditor.java:445)
#+END_EXAMPLE

The ER2015 video shows that you can also open the viewtype as an ECore model.
Doing that also throws an exception:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl$4.getChildren(ResourceImpl.java:522)
	at org.eclipse.emf.common.util.AbstractTreeIterator.hasAnyChildren(AbstractTreeIterator.java:97)
	at org.eclipse.emf.common.util.AbstractTreeIterator.hasNext(AbstractTreeIterator.java:85)
	at org.eclipse.emf.ecore.presentation.EcoreEditor.createModel(EcoreEditor.java:1278)
	at org.eclipse.emf.ecore.presentation.EcoreEditor.createPages(EcoreEditor.java:1339)
	at org.eclipse.ui.part.MultiPageEditorPart.createPartControl(MultiPageEditorPart.java:363)
#+END_EXAMPLE

This one is more concerning, since it's not tied directly to any code in our
plugins.  Might be that we implement some interface incorrectly.

** Trying to open an eviewtype with the editor                     :emfviews:
So the first NPE was due to missing plugins.  This line in Viewtype:

: EPackage contributingEcoreModelPackage = EPackage.Registry.INSTANCE.getEPackage(modelURI);

was returning null.  The modelURI came from the eviewtype file:

#+BEGIN_EXAMPLE
contributingMetamodels=smartEAintegration/metamodels/contentfwk.ecore,http://www.omg.org/spec/BPMN/20100524/MODEL-XMI,http://www.omg.org/spec/ReqIF/20110401/reqif.xsd
#+END_EXAMPLE

In Viewtype.loadContributingMetamodels, we split on this property value, and for
each model, we make a copy of it and in the copy remove attributes and
classifiers.

But this was null, since the plugins were not in the registry.  This should be a
better error.

Anyway, I could have added the model plugins in the dropins folder of my
Eclipse, but I wanted them to run only on the target configuration.  Going into
run configurations, you cannot add arbitrary plugins that are not already loaded
in the current Eclipse: the plugins can only be a subset of the workspace +
target platform.  But you can change the target platform.  And there, you can
add arbitrary plugins.

Adding the model plugins and their requirements did the trick.

Now, another NPE:

#+BEGIN_EXAMPLE
java.lang.NullPointerException
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createViewtypeTreeEditorPage(ViewtypeEditor.java:143)
	at fr.inria.atlanmod.emfviews.editor.editors.ViewtypeEditor.createPages(ViewtypeEditor.java:445)
#+END_EXAMPLE

This is because of that line:

: treeViewer
          .setInput(((Viewtype) viewtypeResource).getResourceSet().getPackageRegistry().values());

Namely, viewtypeResource.getResourceSet is null.  [[*What if I provide filtersMetamodel myself?][Wait a minute]].  I got to the
same conclusion two weeks ago.  But then, I have no idea why the resourceSet is
null.

All I know is Viewtype extends ResourceImpl, but does not override that method,
so ResourceImpl returns its resourceSet.  Which, from what I see in the code, is
only ever set by basicSetResourceSet.  Which is never called anywhere.

However, we do have a virtualResourceSet in Viewtype.  Could that be it?

Oh wow, adding:

#+BEGIN_SRC java
  @Override
  public ResourceSet getResourceSet() {
    return virtualResourceSet;
  }
#+END_SRC

does seem to work.  I do have a property editor, a tree viewer, and the text
source view.

I wonder how this ever worked... other than changes in the API.

Anyway, success!

* [2017-05-02 mar.]
** Eclipse non-determinism                                 :emfviews:eclipse:
Launching Eclipse, trying to open an eviewtype file with the editor that I've
fixed Friday... only the source tab works.  The other two are blank.  Friday
this was working...

What changed?

After opening other files... the tabs have mysteriously appeared.  Okay, what's
going on here?  Some lazy loading of plugins?  Then our views are silently
failing if we fail to create them?

Okay so starting Eclipse again... Opening up
~EAview_Test/1_viewtype/myEAviewpoint.eviewtype~ haha!  Blank tabs.  At least
it's consistent this time.

(Note: for some reason, when switching tabs, the eviewtype file is marked as
dirty even though we didn't change its contents)

After I open the XMI file in the same folder, the tabs appear.  When opening the
XMI file I noticed a pause, so it most probably did load something.

** Fixing Eclipse tooltip background                                :eclipse:
The background for Javadoc tooltips is black, with white text, and crucially,
dark blue links.  That's a hard contrast, but crucially, the links are difficult
to read.

It seems Eclipse inherits the value from GTK.  It's true that the tooltips in
Firefox are also white on black.

So what do I have to change?

Adding a ~/.config/gtk-3.0/gtk.css file with:

#+BEGIN_SRC css
.tooltip .info {
  background-color: #f5f5bf;
  color: #000;
}
#+END_SRC

This changes the tooltip color in Firefox, and in Eclipse when I hover buttons
in the toolbar, but /not/ the Javadoc tooltips.

[[https://bugs.eclipse.org/bugs/show_bug.cgi?id=501742][This bug]] seems relevant; the issue has been fixed in the Oxygen pre-release.
But what if I don't want to switch?

There's a Javadoc background color preference in Eclipse->Appearance.  It's for
the Javadoc view, not the Javadoc tooltip.  Curiously, there's no setting for
the foreground, which is white by default, with dark blue links again making
selecting a good background color difficult.

Using ~SWT_GTK3=0~ does have an effect: Eclipse seems to switch to the awful
GTK3 theme, where every widget is large.  The Javadoc tooltips are readable then
(black on light grey), but the links are missing since the SWT browser fails to
instantiate.  That's not a solution.

Changing gtk2 preferences has no effect.

I see that the commit fixing the bug just changes one line in the JDT UI
plugin.xml:

#+BEGIN_SRC diff
       <colorDefinition
             label="%JavadocBackgroundColor.label"
             categoryId="org.eclipse.jdt.ui.presentation"
-            value="COLOR_INFO_BACKGROUND"
+            defaultsTo="org.eclipse.ui.workbench.HOVER_BACKGROUND"
             id="org.eclipse.jdt.ui.Javadoc.backgroundColor">
#+END_SRC

My understanding is that ~COLOR_INFO_BACKGROUND~ is picked up from GTK3, but
that's clearly not the case here as the setting is ignored.  Would have to dig
into the source.

: git clone https://git.eclipse.org/r/jdt/eclipse.jdt.ui
: rg --hidden COLOR_INFO_BACKGROUND

Oh hey:

#+BEGIN_SRC java
eclipse.jdt.ui/org.eclipse.ltk.ui.refactoring/src/org/eclipse/ltk/internal/ui/refactoring/RefactoringStatusDialog.java
87:			Color foreground= parent.getDisplay().getSystemColor(SWT.COLOR_INFO_FOREGROUND);
88:			Color background= parent.getDisplay().getSystemColor(SWT.COLOR_INFO_BACKGROUND);

eclipse.jdt.ui/org.eclipse.jdt.ui/ui/org/eclipse/jdt/internal/ui/infoviews/AbstractInfoView.java
390:			fgColor = display.getSystemColor(SWT.COLOR_INFO_FOREGROUND);
401:			bgColor= display.getSystemColor(SWT.COLOR_INFO_BACKGROUND);
#+END_SRC

getSystemColor then.  Trying to get the values returned for that by Eclipse, I
do get black for background, and white for foreground, even with the gtk.css
file.

In the Display class, there are two functions that set ~INFO_BACKGROUND~ from
GTK: ~gtk_css_default_theme_values~ and ~initializeSystemColors~.

The first looks like it's reading the CSS file for the current theme:

#+BEGIN_SRC java
case SWT.COLOR_INFO_FOREGROUND:
if (OS.GTK_VERSION >= OS.VERSION(3, 20, 0)) {
  tSelected = cssOutput.indexOf ("tooltip * {");
} else {
  tSelected = cssOutput.indexOf (".tooltip {");
}
selected = cssOutput.indexOf ("@define-color tooltip_fg_color");
if (tSelected != -1) {
  if (OS.GTK_VERSION >= OS.VERSION(3, 20, 0)) {
    COLOR_INFO_FOREGROUND = gtk_css_parse_foreground(themeProvider, "tooltip * {");
  } else {
    COLOR_INFO_FOREGROUND = gtk_css_parse_foreground(themeProvider, ".tooltip {");
  }
  return "parsed";
} else if (selected != -1) {
  color = simple_color_parser(cssOutput, "@define-color tooltip_fg_color", selected);
  if (!color.isEmpty()) {
    break;
  }
}
#+END_SRC

Looks like it's not really parsing the whole CSS, just looking for specific
strings and getting the colors.

The search for the background color is slightly different:

#+BEGIN_SRC java
case SWT.COLOR_INFO_BACKGROUND:
			tSelected = cssOutput.indexOf ("tooltip.background {");
			selected = cssOutput.indexOf ("@define-color tooltip_bg_color");
			if (tSelected != -1) {
				COLOR_INFO_BACKGROUND = gtk_css_parse_background(themeProvider, "tooltip.background {");
				return "parsed";
			} else if (selected != -1) {
				color = simple_color_parser(cssOutput, "@define-color tooltip_bg_color", selected);
				if (!color.isEmpty()) {
					break;
				}
			}
			break;
#+END_SRC

It's not picking up the background-color property.  initializeSystemColors is
the one who calls the code above, with the logic:

#+BEGIN_SRC java
if (OS.GTK_VERSION >= OS.VERSION(3, 14, 0)) {
			String colorInfoForeground = gtk_css_default_theme_values(SWT.COLOR_INFO_FOREGROUND);
			if (!colorInfoForeground.isEmpty()) {
				if (colorInfoForeground != "parsed") {
					rgba = gtk_css_property_to_rgba (colorInfoForeground);
					COLOR_INFO_FOREGROUND = toGdkColor (rgba);
				}
			} else {
				styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
				COLOR_INFO_FOREGROUND = toGdkColor (rgba);
			}
		} else {
			styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
			COLOR_INFO_FOREGROUND = toGdkColor (rgba);
		}
#+END_SRC

I don't know how what CSS Eclipse gets back from GTK, but the ones I have in the
theme are separated into multiple files, with a main.css that includes other
files with @import directives.  Since the code above is grepping for
@define-color, I'm guessing it's looking at the raw CSS files sitting on my
drive.  In that case, it will only match the @define-color line, which goes
through ~simple_color-parser~.

#+BEGIN_SRC java
String simple_color_parser (String output, String value, int index) {
	/*
	 * This method takes a color value (rgb(...), #rgb, an X11 color, etc.)
	 * and makes sure it's input we can handle. We can handle rgb/rgba values,
	 * X11 colors, or colors in the format #rgb or #rrggbb.
	 *
	 * We cannot handle shade/gradient functions or references to other colors.
	 * Because of this we strip out values that start with "@" and check
	 * non rgb values against X11 named colors.
	 *
	 * The following would be invalid input:
	 *
	 * shade(@bg_color, 0,7)
	 * or
	 * define-color error_bg_color @bg_color
	 */
	if (output != null && value != null) {
		int position;
		String color;
		position = index + value.length() + 1;
		color = output.substring(position);
		// Check for rgb color case
		if (color.startsWith("#") || color.startsWith("rgb")) {
			return color;
		} else if (!color.startsWith("@")) {
			// Check for an X11 color
			String [] cut = color.split(";");
			if (colorList.contains(cut[0])) {
				return color;
			}
		}
	}
	return "";
}
#+END_SRC

This function, again, seems rather brittle; it will break if there is more than
one space before the actual color value given to a @define-color prop.  Since
this is clearly a flavor of CSS used by GTK, maybe they have a stricter syntax
than CSS.  Or maybe all CSS files on the web are actually non-compliant, but web
browsers are lax in parsing?

Anyway, my ~tooltip_bg_color~ has a hexadecimal value, so it should return it.
And then... since we are not returning "parsed", the color is converted to RGBA,
which calls delegates to native code.

#+BEGIN_SRC java
GdkRGBA gtk_css_property_to_rgba(String property) {
	/* Here we convert rgb(...) or rgba(...) properties
	 * into GdkRGBA objects using gdk_rgba_parse(). Note
	 * that we still need to remove the ";" character from the
	 * input string.
	 */
	GdkRGBA rgba = new GdkRGBA ();
	String [] propertyParsed = new String [1];
	propertyParsed = property.split (";");
	OS.gdk_rgba_parse (rgba, Converter.wcsToMbcs (null, propertyParsed[0], true));
	return rgba;
}
#+END_SRC

The comment suggests that this method only works on rgb and rgba color values,
not hexadecimal.  Changing the values in the gtk-main.css to rgb color values
has no effect.

(I wish I could add a breakpoint into the code I'm seeing Eclipse).

Maybe it's using default colors somehow?  These are the calls to get the default
foreground and background colors:

: styleContextGetColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);
: getBackgroundColor (context, OS.GTK_STATE_FLAG_NORMAL, rgba);

The first one calls into native code.  The second draws a surface and look at
the color in it.

Oh wait: I /can/ put breakpoints into the code.  That's going to be much
simpler.

Okay so the CSS Eclipse is looking at to determine the colors is... not the one
I was modifying.  It's much larger, and has rule declarations instead of only
@define-color calls and @import statements.

Unfortunately, the debugger is unable to give me the full value.  In the part
I've managed to extract, I don't see any comments.  That might indicate the file
was generated.

So this file apparently contains a ~.tooltip~ declaration, since that's a hit
for the code in Display.  When it gets to it, here is what it finds:

#+BEGIN_SRC css
.tooltip {
  border-bottom-left-radius: 5px;
  border-bottom-right-radius: 5px;
  border-top-left-radius: 5px;
  border-top-right-radius: 5px;
  box-shadow: none;
  color: rgb(255,255,255);
  padding-bottom: 4px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 4px;
  text-shadow: 0 1px rgb(0,0,0);
}
#+END_SRC

That's coherent with the white foreground.  For background:

#+BEGIN_SRC css
tooltip.background {
  background-clip: padding-box;
  background-color: rgba(0,0,0,0.8);
  border-bottom-color: rgba(255,255,255,0.1);
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-image-repeat: initial;
  border-image-slice: initial;
  border-image-source: initial;
  border-image-width: initial;
  border-left-color: rgba(255,255,255,0.1);
  border-left-style: solid;
  border-left-width: 1px;
  border-right-color: rgba(255,255,255,0.1);
  border-right-style: solid;
  border-right-width: 1px;
  border-top-color: rgba(255,255,255,0.1);
  border-top-style: solid;
  border-top-width: 1px;
}
#+END_SRC

So the question now is: where is this CSS coming from?  It's not from the theme
I've specified, and not from the user CSS file.  Maybe it's a file used by
Eclipse?

It is requesting the "Adwaita" theme by name.

Okay so I've dumped the CSS that Eclipse gets from GTK to disk.  I still have no
clue how it's constructed, and how it sets the color values for tooltips.

Looking at the GTK documentation:

#+BEGIN_EXAMPLE
In addition, certain files will be read when GTK+ is initialized. First, the
file $XDG_CONFIG_HOME/gtk-3.0/gtk.css is loaded if it exists. Then, GTK+ loads the
first existing file among XDG_DATA_HOME/themes/theme-name/gtk-VERSION/gtk.css,
$HOME/.themes/theme-name/gtk-VERSION/gtk.css,
$XDG_DATA_DIRS/themes/theme-name/gtk-VERSION/gtk.css and
DATADIR/share/themes/THEME/gtk-VERSION/gtk.css, where THEME is the name of the
current theme (see the gtk-theme-name setting), DATADIR is the prefix
configured when GTK+ was compiled (unless overridden by the GTK_DATA_PREFIX
environment variable), and VERSION is the GTK+ version number. If no file is
found for the current version, GTK+ tries older versions all the way back to
3.0.

In the same way, GTK+ tries to load a gtk-keys.css file for the current key theme, as defined by gtk-key-theme-name.
#+END_EXAMPLE

If we actually look in these folders, the gtk.css for Adwaita is empty, since
it's the default theme.  Presumably, all is implemented in the code.

I don't have ~XDG_CONFIG_HOME~ set, but I suspect the user file is still getting
read, since it's modifying the tooltip colors for other parts of Eclipse.

Okay, what about pointing to a custom theme?  Will it follow the CSS then?

Creating a Foo theme and setting as default, with this gtk.css:

#+BEGIN_SRC css
.tooltip {
  color: rgb(91, 91, 91);
}

.tooltip.background {
  background-color: rgb(230, 230, 230);
}
#+END_SRC

In Eclipse, the CSS dump for Foo is as huge as Adwaita's.  Tooltip values are
the same as well:

#+BEGIN_SRC css
.tooltip {
  border-bottom-left-radius: 5px;
  border-bottom-right-radius: 5px;
  border-top-left-radius: 5px;
  border-top-right-radius: 5px;
  box-shadow: none;
  color: rgb(255,255,255);
  padding-bottom: 4px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 4px;
  text-shadow: 0 1px rgb(0,0,0);
}
#+END_SRC

Something is fishy with this GTK function, and I can't find a way to influence
the values.

Looks like I have to switch to Oxygen.  Oh well.

Oxygen fixed it... but not the colors in the Content Assist.  I understand
that's a fresh commit that should go in the release.

* [2017-05-03 mer.]
** Fixing the empty tabs in the EMF Views editor                   :emfviews:
So: loading an eviewtype, I get a MultiPageEditor with 3 pages.  Page 2 and 3
are blank.  After I load the XMI file in the same folder, the two pages have
content.

Trying to add a very simple page to the MultiPageEditor with a single button:
switching to this page, the button exists.

Trying to add a more involved page with a ScrolledForm and a TreeViewer:
switching to this page, it is blank.

However, using setActivePage to point to this new page, the page is indeed
constructed and visible, and all the other pages are blank, except the first
one.

Using setActivePage to point to the properties page: it is visible on launching
Eclipse and after switching to and back from other pages.  First page is
visible, other two pages are not.

The common factor in the invisible pages seem to be that they use a
ScrolledForm.

I just need a Control to put into a page.  A ScrolledForm is a Control, but a
Composite is a Control as well.

Trying to put a button and a TreeViewer in a Composite: grey page.

If I add a layout to the composite:

: comp.setLayout(new GridLayout());

Now it's displayed.  Same thing with a ScolledForm actually: adding the
setLayout to its Composite returned by getBody will make the widgets visible
when switching to the page.

But creating the ScrolledForm through the FormToolkit, that doesn't work.

Need to look into forms and editors.

* [2017-05-05 ven.]
** Eclipse forms and editor bug                            :eclipse:emfviews:
Reading: https://www.eclipse.org/articles/Article-Forms/article.html

This is a good (albeit dated) resource on what Eclipse Forms are useful for.  It
seems PDE uses them extensively for editing the plugin.xml file for instance.
So now I understand what the EViewType editor tries to emulate.

Since we are trying to build a multi-page form, it seems the preferred way is to
extend FormEditor rather than MultiPageEditor.

Found [[http://git.eclipse.org/c/platform/eclipse.platform.ui.git/plain/examples/org.eclipse.ui.forms.examples/src/org/eclipse/ui/forms/examples/internal/rcp/FreeFormPage.java][an example]] of using FormEditor and multiple FormPage.

Doing that seems to fix the blank page bug.  I just converted the code that
created the forms to FormPage inner classes.  It's not as clean as I'd like,
since there seem to be weird explicit dependencies between models and views.
Considering that all three pages must stay in sync, it would seem that changing
the model and listening to changes would be cleaner.

But, I also don't know if we want to keep the editor in this current form.  So
that fix should do it for now.

** More dead code                                                  :emfviews:
Looking around, I see there are two classes that are not used: FormComposite, a
small utility class to adapt a composite with a toolkit, and Overview, which
seem to be the properties view as it existed before.

Of importance, the Overview class takes care of using text strings pooled from a
text file for the UI, so they can be translated.  But I can't seem to succeed in
including the page in the editor, so...  Dead code.

* [2017-05-09 mar.]
** Fixing the TreeViewer in the Viewtype editor                    :emfviews:
So, first of all, there was the issue of dirtying the state of the editor when
switching to the TreeViewer.

While trying to understand what the page is for, it hit me that a few things are
not working properly: some boxes should be ticked, and selected elements should
be expanded as well.

In addition, I see that basically all objects can be expanded in the TreeViewer,
even when they don't have any children.

Luckily, I've already done the TreeViewer tutorial from the book.

So, we are reusing the ContentProvider from our Viewtype creation wizard.
Basically, we delegate to the EMFContentProvider to display models, except we
add another layer of EPackage.

Rewriting the ContentProvider getChildren and hasChildren to be in sync fixes
the issue with empty children showing a twistie.

But we expand/tick/reveal calls still have no effect.

Debugging a reveal call indicates that it returns null internally.

So I can get the treeViewer to reveal/tick/expand elements when I build the
elements array myself.  I guess what we get from viewtype.getHiddenAttributes
are not elements related to the input of the tree.

Wait a minute.  The tree is not complete in the view... Looks like the models we
display are the one from the virtual resource set of the viewtype... so the
items are already filtered out.  The code is trying to tick the exact same
items, so of course that shouldn't work.

Not removing the items in the resource set... well, that still doesn't tick
them.  But I think that's because the virtual resource set contains clones of
the models, and the hidden attributes are objects of the base resource set, so
maybe they cannot be equal to one another.

Ah!  Yes, that's it.  After putting the originals in the virtual resource set
and not the copies, the ticks appear.  But the containing classes are not
expanded.

Which is weird, because we construct the array of containing class based on the
hidden attributes.  So if the hidden attributes are ticked because the tree
contains the same objects, it should also contain the right classes.

Hmm maybe we are changing the expanded elements at another point.  We do, in
pageChange.

But commenting that does not help.

Wait, after adding breakpoints to step through the code that sets the expanded
state internally in AbstractTreeViewer, it does work!  Shenanigans.  I guess the
hot code replace can get confused by my changes, without warning me.  This is
unfortunate.

Also, the code was trying to set the expanded state on a tree item below the top
level.  According to the documentation, this should work: expanded states are
saved even if you close the parent, so when you reopen the parent, the expanded
children should still be open.

However, if I manually do it in the tree, that's not the behavior I observe.
Expanding a child, and toggling its parent: the child is closed.  Looks like
closing an item closes its children recursively.  What works is to reveal the
elements.

Okay so now, I still haven't solved the mysterious dirtying of the editor when
opening the Contents page.

There's an editorDirtyStateChanged which I can override.  But it doesn't get
called.

Okay, found it.  The AttributeSelectionAdapter is changing the model every time
we select something.  That's overkill, and wrong.  We should only update the
model when there are actual changes in the tree: that is, when we check/uncheck
elements.

But I'm not fixing it right now.  Better focus on cleaning up the core of
EMFViews: the virtual model.  I'm leaving notes to know that these parts of the
code are busted.

** Notes on EMFViews core                                          :emfviews:
What is referred to as the Weaving model in the paper is our VirtualLinks
package.  It's a collection of links between models and metamodels.  For the
moment, we have two kind of links: associations and filters.

Associations are virtual references.

Filters hide attributes from models.

We don't have virtual attributes or virtual classes, but that might be something
to improve upon (the Extension paper was a step in that direction).

The virtual models are realized by the emfviews.core package.  There we have
Viewtype (a viewpoint in the paper), View and EView.

We have two levels: the viewtype describes the links between contributing
metamodels, and the view describes how to construct a virtual model from
contributing models (which are instances of the contributing metamodels of the
viewtypes).

Practically speaking, when opening an EView file with an ECore editor, EMF will
display the virtual model.  This is achieved by registering EMFViewsFactory as
the parser class in an extension point.

This class then creates an EView and Viewtype, depending on the file extension.
These two files extend ResourceImpl, so they can be transparently used as
resources by EMF.

How being a resource helps in displaying a model, I still have to find out.

H pointed out some redundancies in the EView file: we specify the ECL file, but
we don't need it.  It's already in the EViewtype, which is also specified, and
in any case we only need the XMI describing the weaving model.  The ECL file is
used to generate the weaving model, but once we have one, we don't need the ECL
anymore.  And in any case, we can also provide the weaving model XMI manually.

Same thing in the EViewtype: the examples have an ECore file that contains the
hidden attributes.  These should be part of the XMI, which already register the
association virtual links.

* [2017-05-10 mer.]
** Renaming VirtualLinks package and freshening up the model       :emfviews:
Annoyingly, we had a package named fr.inria.atlanmod.emfviews.virtualLinks.  Note
the camelCase.

Since this package is generated by EMF, better to update the model directly.
I'm not quite sure what to make of the namespace URI we have:

: http://inria.fr/virtualLinks

But I know that changing it will break existing serialized XMI files, so that's
probably a bad idea for the time being if I want to run the examples, without
having to change the namespace there as well.

** Testing out containment references in EMF                            :emf:
In a language where objects are allocated on the heap, I did not understand the
use of containment references.

Turns out, a containment reference and vanilla reference both include a list of
target objects.  The list implementation are different classes, but I don't see
anything vastly different about them.

According to the EMF bible, an object B that has a container can only be in one
container at the time.  Changing its container will remove it from the previous
container.  That's neat.

But doesn't that apply to bidirectional references with a single multiplicity at
one end as well?

Looks like it does.  So, a containment reference is equivalent to a
bidirectional reference with multiplicity 1 at one end.  One difference is that
to make a bidirectional reference in ECore, you have to create two references.

But the major difference since to lie in the serialization.  Contained targets
will be serialized in the same resource as the container, whereas vanilla
references are serialized in different resources.  In other words, it does what
you expect when you consider storage.  A quick test reveals that indeed,
contained objects are saved in the same file as their parent, whereas with
vanilla references you are dealing with multiple files.

So, for simplicity, and simplified management of serialized resources,
we should prefer containment references.

** Trying to use the MoDisCo model browser                         :emfviews:
Because the model browser provided by ECore is very basic, and does not follow
references.  The MoDisCo browser does.

However, trying to open the examples XMI with it, I am greeted with familiar
errors concerning unknown features from the TOGAF metamodel:

: !MESSAGE org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'belongsTo' not found. (platform:/resource/1_EAdata/models/1_travelAgencyEA.xmi, 26, 270)

I slayed this dragon previously, and I kept my custom TOGAF plugin.  Re-using
it...

Okay, it works.  I can follow recursive links in the model.  It's... not very
impressive, or convincing, but it works.  The Modisco browser is dog slow
however.

** Following the code                                              :emfviews:
After the EmfViewsFactory delegates to either the EView or Viewtype constructor,
what happens?

Well, nothing at that point: the constructor returns a resource.  That resource
is only loaded when its doLoad method is called.  That's where the magic
happens.

In Viewtype.doLoad, we parse the eviewtype file, load the models, and create the
virtual resource set.

The correspondenceModelBase seem unused at this point.  The Viewtype only uses
it in serialize()... except this function is never used.  The actual
serialization happens in the doSave method of the resource.

First we load the filter metamodel: the ECore file that should not be here.

Then we load the contributing metamodels.  We get the corresponding package, and
each package is cloned and kept in contributingEPackages.

Then, we first filter out any attributes as specified by the filter metamodel.
If the package matches one in the filters, we remove every structure from common
classifiers.

There are two issues currently: we loop through all filtered packages, for
each contributing package.  That's unnecessarily quadratic.

Second issue: we only seem to care about EClass classifiers with an unchecked
downcast.  So I'm pretty sure that's an exception if the filter metamodels
contains an Enum or Datatype.

Hmm, it crashes, but not where I expected.  Actually, I see other downcasts in
the same method, and they seem unsafe, but no warnings.  Need to check that as
well.

*** TODO Check copyright/contributions
Copyright is attributed to Inria in some places, Atlanmod in others (or should
it be AtlanMod?).

Copyright years are 2013,2014 tops.

Copyright notice should maybe be generated for VirtualLinks.

Copyright notice should be included in all packages.

AtlanMod should be the provider of all packages.

*** TODO Investigate dependencies
Some EMF plugins depends on other EMF plugins, some depend on EMF packages
directly.  The book I read on Eclipse plugin development recommended to depend
on packages.

*** TODO Change the logo background to be transparent
This is unnerving.

* [2017-05-12 ven.]
** Downcasts in Java are "safe"                                        :java:
Because there will be runtime checks...  I was under the impression the compiler
would complain, but it's just in case of unchecked cast with generics.  Because
of type erasure, the compiler cannot insert a runtime check (a List is still a
List), so the warning is to make sure you know what you are doing.

Otherwise, Java assumes you do know what you are doing with straight downcasts
from A to B, even though the compiler only knows that this downcast /could/
work (if B :< A).

That's disappointing.

Is there a linter out there that could at least pick up downcasts so I could
review them?  FindBugs [[http://findbugs.sourceforge.net/bugDescriptions.html#BC_UNCONFIRMED_CAST][appears to]].

The Eclipse plugin is a bit rough, but it does report the stupid downcast from
my test code.  However, it does not report the troubling downcasts in EMFViews.
So, more trouble than it's worth.

** Mysterious crash when loading funky ECore file                  :emfviews:
So adding other classifiers (EEnum, EDataType) to the Ecore file containing our
filters and opening the Eviewtype with the ECore editor results in 3 thrown NPE.

The puzzling part is that, in all of the stack traces, our code is not on the
stack.  Maybe we implement something wrongly.

Adding a breakpoint shows Viewtype.getContents is called and returns the null in
question.  But since the null value is used by ResourceImpl, that's where the
NPE is thrown.

Anyway, we only set virtualContents after doLoad() has completed.

Hmm, I see!  Stepping through again, and in fact ResourceImpl.load wraps our
doLoad with a try/finally, but no catch.  So we do throw a cast exception due to
the presence of other classifiers!  But that was masked by ResourceImpl.
Sneaky.

** EMFViews archeology                                             :emfviews:
So, H found the original demo paper along with the initial prototype
implementation of EMFViews (then called VirtualEMF).  The novel idea at the time
was to have a /virtual/ model, that composed multiple contributing models.  The
virtual model is lazy: attributes are proxies to the concrete models, and the
virtual attributes are synthesized on-demand.

In the code, you can find a VirtualModel class that's absent from the current
version.  That's because at the time, only models were virtualized, not
metamodels.  But, the same virtualization approach can be applied to metamodels,
since they can be viewed as models as well; hence EMFViews.  In EMFViews, we
have Viewtype which should be the equivalent of VirtualModel for metamodels, and
View, which would be closer to the original VirtualModel.

Looking at the rest of the code, everything in emfviews.elements seem very
similar to the first version.

In emfviews.rules, the MergeRule was severely cut.

In emfviews.core, the MetaModelManager was mostly changed.  The
VirtualLinkManager was slightly changed, and that's it (other than added/removed
files).

** Further code investigation                                      :emfviews:
Now I'm in Viewtype.loadCorrespondenceModel.  The correspondenceModel is the XMI
file that describe the VirtualLinks: it gives us the info we need to compose the
contributing models (and in this case, metamodels).

There are two kinds of links actually: Filter and Association.  But filter links
are not currently used in this path of code; the filters are specified in a
separate ECore file which is used in the loadFilterMetamodel phase.

So the code is concerned only with Association links.  For each Association, we
synthesize an EReference with the Association attributes (source, target,
lower and upper bounds) and add it to the EClass in which it resides (in the
virtual packages we created earlier).

Ultimately, in Viewtype.setVirtualContents, we turn the EPackage from our
virtual resource set into a VirtualContents object (which is just an EList).  I
had looked at VirtualContents before: it's a curious implementation of an EList
from a list of lists, which only purpose seem to be to simulate a flat list:

#+BEGIN_SRC java
public E get(int index) {
    if (index >= 0) {
      for (List<E> l : subLists) {
        if (index < l.size()) {
          return l.get(index);
        } else {
          index -= l.size();
        }
      }
    }
    throw new IndexOutOfBoundsException();
  }
#+END_SRC

I'm assuming this is done because getContents requires an EList.  But, then, why
not flatten the lists once and for all?  The VirtualContents list seem to be
read-only, since the set method is implemented by a call to super
which... throws UnsupportedOperation.

** Open questions                                                  :emfviews:
- Is Viewtype creating a truly virtual metamodel?  It doesn't seem to do any
  demand-loading, but maybe that's behind the scenes.  Should compare with what
  View/EView does for models, or what VirtualModel did in the first prototype.

- There are still a bunch of files in the core, are they used by View/EView or
  not?  MergeRule, TranslationRule, etc.

* [2017-05-15 lun.]
** Is Viewtype proxying metamodels?                                :emfviews:
To me it seems that no, it just plain clones them into the virtual resource
set.  This is done in loadContributingMetamodels:

#+BEGIN_SRC java
EPackage contributingEcoreModelPackage = EPackage.Registry.INSTANCE.getEPackage(modelURI);

Copier copier = new Copier();
EObject copy = copier.copy(contributingEcoreModelPackage);
copier.copyReferences();
EPackage copiedPackage = (EPackage) copy;
EcoreUtil.remove(copiedPackage);
contributingEpackages.add(contributingEcoreModelPackage);
#+END_SRC

Regardless of whether there are filters, we clone the packages.  Then, if there
are filters, we remove the attributes from these copies.

: eClassWithItemsToHide.getEStructuralFeatures().remove(theAtt);

Then, if there are associations, we add EReferences to these copies:

#+BEGIN_SRC java
EReference theR = EcoreFactory.eINSTANCE.createEReference();
theR.setName(association.getName());
theR.setLowerBound(association.getLowerBound());
theR.setUpperBound(association.getUpperBound());
theR.setEType(theTargetEClass);
...
theSourceEClass.getEStructuralFeatures().add(theR);
#+END_SRC

So, is this different from how View/EView work?

** Investigating View/Eview                                        :emfviews:
Stepping through the code.  When we load an eview file, we trigger EView.doload.

First thing is to read the file, and create a Viewtype resource from the
compositionMetamodel line.  We are creating a whole new Viewtype (and copying
packages), just for the EView.  If a Viewtype is a virtual metamodel, we should
be able to locate it from the registry, and create it only if it does not exist.

I'm wondering if the EView/View split is the half-finished result of trying to
abstract the common parts of EView and Viewtype into a common abstract class.
But at the moment, EView is the sole subtype of View.

In EView, we then load the View.contributingMetamodels.  This merely register
the metamodels in the virtualResourceSet of View.  But this virtual resource set
is different from the one held by Viewtype.  At this point, the metamodels are
not modified.

Then we create a MetamodelManager.  This one populates a bunch of Maps.  A map
of composition classes keyed by their names; these are taken from the contents
of the constructed Viewtype.  Then a map of all the EClass of the contributing
metamodels, again keyed by their names; these are taken straight from the
classifiers of the contributing metamodels.

Then a map of concrete to virtual classes.  That's interesting:

#+BEGIN_SRC java
for (List<EClass> lcec : contributingClassesByName.values()) {
  for (EClass cec : lcec) {
    List<EClass> lvec = compositionClassesByName.get(cec.getName());
    for (EClass vec : lvec) {
      if (vec.getEPackage().getNsURI().equals(cec.getEPackage().getNsURI())) {
        this.concreteToVirtualClass.put(cec, vec);
        mapFeatures(cec, vec);
      }}}}
#+END_SRC

The "virtual EClasses" (vec) that are put into the map are pulled from
coompositionClassesByName, and used as values keyed by the corresponding class
in contributingClasses.

mapFeatures does the same mapping, but for structural features, recursively:

#+BEGIN_SRC java
private void mapFeatures(EClass concEC, EClass virtuEC) {
  for (EStructuralFeature feature : concEC.getEStructuralFeatures()) {
    EStructuralFeature vf = virtuEC.getEStructuralFeature(feature.getName());
    if (vf != null) {
      this.virtualToConcreteFeature.put(vf, feature);
      this.concreteToVirtualFeature.put(feature, vf);
    }}}
#+END_SRC

Now we have a bidirectional map.

Lastly, there may be additional features in the virtual classes (created by the
associations), so we also record them in a map of virtualAssociations, but only
if they were not present in virtualToConcreteFeatures:

#+BEGIN_SRC java
for (List<EClass> lec : compositionClassesByName.values()) {
  for (EClass ec : lec) {
    for (EStructuralFeature sf : ec.getEStructuralFeatures()) {
      if (virtualToConcreteFeature.get(sf) == null)
        if (virtualAssociations.get(sf.getName()) == null) {
          List<EStructuralFeature> sfs = new ArrayList<>();
          sfs.add(sf);
          virtualAssociations.put(sf.getName(), sfs);
        } else {
          virtualAssociations.get(sf.getName()).add(sf);
        }}}}
#+END_SRC

After that we are back in EView, and that's it for the metamodels.  Now we
loadContributingModels:

#+BEGIN_SRC java
protected void loadContributingModels(List<String> contributingModelsPaths) {

  for (String modelURI : contributingModelsPaths) {
    virtualResourceSet.getResource(URI.createPlatformResourceURI(modelURI, true), true);
  }

}
#+END_SRC

Which just seems to force the loading of each model, without doing anything with
the returned resource (why?).

If there is a correspondenceModelBase we... don't do anything with it (yet)?  We
get the correspondence XMI, create a VirtualLinksDelegator for the
correspondenceModelBase, and let the delegate create the links:

#+BEGIN_SRC java
if (properties.getProperty("correspondenceModelBase") != null) {
  IWorkspace workspace = ResourcesPlugin.getWorkspace();
  java.net.URI linksModelURI = workspace.getRoot()
      .findMember("/" + properties.getProperty("correspondenceModel")).getLocationURI();
  try {
    VirtualLinksDelegator vld =
        new VirtualLinksDelegator(properties.getProperty("correspondenceModelBase"));

    vld.createVirtualModelLinks(org.eclipse.emf.common.util.URI
        .createURI(linksModelURI.toString()), getContributingModels());
#+END_SRC

In this case, it creates an EclDelegate.  In
EclDelegate.createVirtualModelLinks, we open the ECL file and first parse the
aliases in the header.

Here is a sample ECL file from the examples:

#+BEGIN_EXAMPLE
//alias_ea=http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0
//alias_bpmn=http://www.omg.org/spec/BPMN/20100524/MODEL-XMI
//alias_reqif=http://www.omg.org/spec/ReqIF/20110401/reqif.xsd

rule detailedProcess
match s : ea!Process
with  t : bpmn!Process
...
#+END_EXAMPLE

I think the intent here is pretty clear: to define ~ea~, ~bpmn~ and ~reqif~ as
aliases for the metamodels in the header.  Still, it would be better to have ECL
support these kinds of declarations rather than hack a parser with indexOf
calls.

[H: usually you'll run ECL with a launch configuration file, specifying the
aliases.  Here it's inlined.  Maybe there is away to provide a launch
configuration at runtime, but it's not really important.]

In any case, we populate two maps keyed by the aliases: one to the resource of
the metamodel, and one to the package URI.  No provisions are made if we don't
find a corresponding resource.

After that, we close the ECL file because we let ECL parse the rest.  Then we
add instances of EmfModel to the model repository of the Ecl module.

Then, we executet the ECL module, and iterate on the resulting MatchTrace in
order to create virtual links for each matching trace:

#+BEGIN_SRC java
for (Match match : matches) {
  if (match.isMatching()) {
    EObject left = (EObject) match.getLeft();
    EObject right = (EObject) match.getRight();

    Association vAsso = vLinksFactory.createAssociation();
    vAsso.setName(match.getRule().getName());
    vAsso.setAssociationTypeName(match.getRule().getName());
    vAsso.setLowerBound(0);
    vAsso.setUpperBound(1);

    LinkedElement lSource = vLinksFactory.createLinkedElement();
    lSource.setModelRef(left.eClass().getEPackage().getNsURI());

    lSource.setElementRef(left.eResource().getURIFragment(left));
    vAsso.setSourceElement(lSource);

    LinkedElement lTarget = vLinksFactory.createLinkedElement();
    lTarget.setModelRef(right.eClass().getEPackage().getNsURI());
    lTarget.setElementRef(right.eResource().getURIFragment(right));
    vAsso.getTargetElements().add(lTarget);

    virtualLinks.getVirtualLinks().add(vAsso);
    virtualLinks.getLinkedElements().add(lSource);
    virtualLinks.getLinkedElements().add(lTarget);
  }
}
#+END_SRC

After that, we save the populated virtualLinks to the XMI file.

So, it seems we always recreate the XMI file from the ECL.

[H: that may not be ideal, but models can be updated, so you usually want your
view to synchronize with these changes by default.  Here we run the ECL query
again.]

Back in EView, we now create a VirtualLinkManager, given the correspondence
model URI (the XMI).  The manager merely holds a reference to both the EView and
the VirtualLinks instance from the XMI.

Then the VirtualLinkManager is initialized, which creates a LinksProjector.
There, for each Assocation in the XMI, we get a virtual element from the
VirtualLinkManager corresponding to the source element of the association, and
we link the target elements to it:

: vElement.setVirtualAssociation(virtualFeature, EStore.NO_INDEX, targetElements);

After that, we set the virtual contents of our EView resource, by translating
each package of the contributing models to virtual elements.  Creating virtual
element happens in VirtualLinkManager.getVirtualElement:

#+BEGIN_SRC java
public EObject getVirtualElement(EObject e) {
  VirtualElement vElem = virtualLinks.get(e);
  if (vElem == null) {
    vElem = new ReproduceElementImpl(virtualModel, e);
    virtualLinks.put(e, vElem);
  }
  return vElem;
}
#+END_SRC

and ReproduceElement uses a ReproduceRule, which implements an EStore... and
that's probably where the secret virtualization sauce lies.  But it already
looks like there is much more happening in EView/View concerning virtualization,
and I didn't see any copying taking place.

So my premature answer is: the Viewtype is not virtualized as the Views are.
Which was kind of the point of EMFViews.  That should be fixed in priority.

* [2017-05-16 mar.]
** Reading the EMF bible                                                :emf:
To get a clearer picture of the concepts at hand.

Questions still open after reading the relevant chapters:

- Can we read a UML model and access it using the
  EPackage/EClass/EAttribute/... interfaces?

- Is demand-loading and demand-creating for resources lazy, eager, or something
  else?  Specifically, the createResource and getResource methods accept a
  boolean argument: does it forces resolution or rather delays it?

- It seems, at least for references, that EMF already does some
  auto-proxification.  What is the mechanism we use in EMFViews
  (ReproduceRule?), and how does it compare?

  If we use "Dynamic EMF" as it's called in the book to create our view
  packages, would we not benefit from proxification?

And an observation:

EMFViews add copies of contributing model packages to a registry local to the
virtual resource set of a Viewtype.  But then, the EView does not tap into this
virtual resource set, so there's duplication here.

* [2017-05-17 mer.]
** EMFViews uses an EStore                                         :emfviews:
A VirtualElement inherits from an EStoreEObjectImpl, which is an EObject
implementation backed by an EStore.  Then, our translation rules are all
different EStore implementation.

From what I gather, this is where the actual magic for models happen (and this
was part of the initial implementation back in 2011).

When we load a model, the very last step of EView.doLoad is to set the virtual
contents:

#+BEGIN_SRC java
for (Resource r : contributingModels) {
  ArrayList<EObject> oneOftheSublists = new ArrayList<>();
  oneOftheSublists.add(translateToVirtualElement(r.getContents().get(0)));
  sublists.add(oneOftheSublists);
}

this.virtualContents = new VirtualContents<>(this, sublists);
#+END_SRC

This populates lists with virtual elements, which are obtained from the virtual
link manager:

#+BEGIN_SRC java
public EObject getVirtualElement(EObject e) {
  VirtualElement vElem = virtualLinks.get(e);
  if (vElem == null) {
    vElem = new ReproduceElementImpl(virtualModel, e);
    virtualLinks.put(e, vElem);
  }
  return vElem;
}
#+END_SRC

That's where reproduce elements are instantiated.  (And, interestingly, only
reproduce elements; MergeElement and FilterElement do not seem to be created
anywhere)

A reproduce element is a virtual element, so an EStoreEObjectImpl, and holds a
concrete EObject called the concrete element.  The idea is to pass through
access to the concrete element using the EStore interface.

At the end of creating a reproduce element, this is what happens in init:

#+BEGIN_SRC java
this.eProperties().setEResource(vModel);
this.concreteElement = concreteElement;
this.eSetClass(eClass);
this.eClass();
setTranslationRule(ReproduceRule.INSTANCE);
eSetStore(this.getTranslationRule());
#+END_SRC

We create a reproduce rule, which implements EStore, and will capture get/set
calls on this virtual object.  That's why, in ReproduceRule.get:

#+BEGIN_SRC java
public Object get(InternalEObject object, EStructuralFeature feature, int index) {
  ReproduceElementImpl vElement = (ReproduceElementImpl) object;

  View vModel = (View) vElement.eResource();
  if (vModel.getMetamodelManager().isVirtualAssociation(feature)) {
    return vElement.getVirtualAssociation(feature, index);
  }
  EStructuralFeature cFeature = vElement.getConcreteFeature(feature);
  Object value = vElement.getConcreteElement().eGet(cFeature);
  ...
  return value;
#+END_SRC

We ultimately return the concrete value.  But not in every case:

#+BEGIN_SRC java
if (feature instanceof EReference) {
  if (feature.isMany()) {
    value = new VirtualModelList<>(object, feature, Arrays.asList((List<EObject>) value));
    if (index != NO_INDEX) {
      value = ((VirtualModelList<EObject>) value).get(index);
    }
  } else {
    value = vModel.translateToVirtualElement((EObject) value);
    if (value instanceof FilterElement) {
      value = null;
    }
  }
}
#+END_SRC

If the requested structural feature is an ERef, and it's many, we return a
virtual list.  Ultimately, inside this virtual list, we will call
getVirtualElement.  If the ref has a single multiplicity, then we can directly
return the virtualElement.

In essence, we perpetuate the virtualization recursively.

It seems to be this part of the code is mixing concerns.  There is a test for
FilterElement here, to mask the value if it should be filtered.  But then we
also have the same test in the VirtualModelList.  Why does the virtual list
repeats this instead of delegating to single virtual elements?

Besides, it seems to me we should have a clear mapping from the Ecore model to
the virtual model, defined for all classifiers and features.

** Using a code coverage tool to find hot/cold code        :emfviews:eclipse:
Following T's recommendation, I used the EclEmma plugin, which is based on
JaCoCo.

Installation was painless.  The plugin supports coverage for running client
Eclipse application, which is my use case.

So now I can answer with certainty that, opening EView and EViewtype files with
a model browser and the viewtype editor, the following classes are never used:

- MergeRule, MergeElementImpl
- FilterElement

In other classes, besides what I already identified as unused, it seems we have
no examples using the sourceAttribute and targetAttribute of a Association.
Maybe there are superseded by sourceElement/targetElements.

* [2017-05-19 ven.]
** How are virtual model attributes filtered out?                  :emfviews:
H raised an interesting question: if an attribute is filtered out in the virtual
metamodel, it is also filtered out in the virtual model.  But how does that
happen?

Does EMF just disregard attributes that are not in the metamodel?  Do we also
need to filter the attributes from the model?

I'm guessing it's the former.  If I comment out the filtering attributes part in
the metamodel, they should appear on the model.

Yes, they do.

Hmm, when the attributes are present in the metamodel, we add them to the maps
of virtual to concrete features in MetamodelManager.  When the attributes are
absent, they are absent from the maps as well.  That's a hint.

* [2017-05-22 lun.]
** Writing tests for EMFViews before refactoring                   :emfviews:
I've got a couple of easy refactorings ahead, related to the EView and EViewtype
files.  But, before that, I want to write some tests to ensure I don't break any
functionality doing so (at least, any functionality we care about).

One problem with writing tests is the way Viewtype and View are written as
resources, you have to provide files through URI, otherwise you cannot construct
them properly.

We could refactor Viewtype and View so that the resource-specific code is
extracted, and calls into a model-specific part that does not have to deal with
files.  But that would be refactoring in order to write the tests for the
/other/ refactoring...

I'll try to write the tests passing files as URI first.

Okay, hit a snag: I'm using URI.createPlatformResourceURI to pass a
workspace-relative filename to the EViewtype file, and it doesn't work.
Presumably, because when I run the code there is no workspace!

So rather I should just use relative paths.  This works:

: URI.createURI("models/foo.eviewtype")

and this will look up the "models" directory in the current project, so it's
relative.  Hopefully that slash is portable as well.

Grmbl, now Viewtype tries to load the filters metamodel.  But it also uses
URI.createPlatformResourceURI, which in turn will use the resource factory
registry to find out how to create an Ecore.  But running in the tests, this
factory is empty:

: System.out.println(Resource.Factory.Registry.INSTANCE.getExtensionToFactoryMap().isEmpty());
: true

I guess I can populate it myself in the tests.

: Resource.Factory.Registry.INSTANCE.getExtensionToFactoryMap()
:     .put("ecore", new EcoreResourceFactoryImpl());

Now I have to find the correct path to set in the Eviewtype file so that it
loads my Ecore model from the right directory.

At the moment, it fails to find it.  I'm in
PlatformResourceURIHandlerImpl.createInputStream.

Amusingly, after prefixing my URI with 'platform:/resource', this method removes
the prefix

: String platformResourcePath = uri.toPlatformString(true);

Ultimately, it calls EcorePlugin.resolvePlatformResourcePath on this suffix,
which merely looks into its getPlatformResourceMap for the root project in order
to produce a platform-specific file URI...

Let's do this:

: EcorePlugin.getPlatformResourceMap().put("foo", URI
: .createURI("file:///home/fmdkdd/proj/emfviews/tests/fr.inria.atlanmod.emfviews.test/models"));

Yeah, it works!  Is there a way to make it relative at least?

In the end, the file URI calls new File(), passing everything to the right of
':'.  Ah, but that's only the URI for the base folder, and EMF uses it to
resolve the resource path below, and this cannot be relative:

#+BEGIN_SRC java
 public URI resolve(URI base, boolean preserveRootParents)
    {
      if (!base.isBase())
      {
        throw new IllegalArgumentException("resolve against non-hierarchical or relative base");
#+END_SRC

Hardcoded it is then.

Then:

: IllegalStateException: Workspace is closed.

Raaaah, we have code in Viewtype.loadCorrespondenceModel which queries the
workspace.  To construct absolute file URIs, again.  This time, to load the XMI
file of the correspondence model.

At this point, I have three options:

1. Fuck it, and not write tests before doing the changes.  That's not totally
   satisfactory; and I will need to write tests anyway for other changes down the
   line.
2. Make the slightest modifications to Viewtype so that it let us provide the
   proper URI
3. Run the tests as a plugin, so that a workspace is loaded


Now that I think of it, 3 would solve the previous problem as well.

Okay, that's better.  Now I can run the JUnit test using a headless Eclipse, but
still loading a workspace.  In fact, I did have to configure a "test" workspace
where I added the ECL, XMI and Ecore files needed by the viewtype to load.

I'd rather have the tests add these files to the test workspace... or even have the
Viewtype code to load them from anywhere.  But anyhow.

Managed to test the presence of features and absence of filtered features.  Now
to be a bit more thorough.

Hmm, hit a snag when trying to check the models.  All I get are
ReproduceElementImpl instances, so I can't cast them to EClass/EPackage to get
their contents or names.

I could cast to ReproduceElementImpl... but then I wouldn't be testing the
virtual access.

So maybe I'm missing something, and we should access these objects through the
EStore interface.  At least, EMF is able to construct a tree viewer from these
contents, so I should be able to inspect these as well.

*** DONE Fix the URI scheme in Eview/Eviewtype
CLOSED: [2017-06-07 mer. 17:26]
We mix platform URLs with http for finding packages of metamodels.  This is
confusing and complicates the code (there are couple instances of duplication
based solely on different URI schemes).

* [2017-05-23 mar.]
** How does the basic Ecore editor goes through our ReproduceElementImpl? :emfviews:
Because that's how I probably need to iterate on them as well.

In EcoreEditor.createModel, our reproduce rule is called by an iterator
resource.getAllContents(), which goes through all the properties.

The actual text is provided by label providers that are given by adapter
factories... EcoreItemProviderAdapterFactory is where the mapping is done from
Ecore objects (ERef, EClass, etc.) to the actual classes that do the work.

For EObjects, it uses the ReflectiveItemProvider.  Setting a breakpoint at
getText there and opening items in the tree confirms that this is the place.

#+BEGIN_SRC java
public String getText(Object object) {
  EObject eObject = (EObject)object;
  EClass eClass = eObject.eClass();
  String label = format(capName(eClass.getName()), ' ');

  EStructuralFeature feature = getLabelFeature(eClass);
  if (feature != null)
  {
    Object value = eObject.eGet(feature);
    if (value != null)
    {
      return label + " " + value.toString();
    }
  }
  return label;
}
#+END_SRC

It's just using eClass().getName().  Okay, let's try that.

It works!  I managed to test the presence of reproduced elements and virtual
associations, and the absence of filtered elements.  But somehow, I've gotten
some values from eClass.getName(), and some others from casting to an EReference
and using getName():

: assertEquals("ReqIF", l.get(1).eClass().getName());
: assertEquals(e.eClass().getName(), "Process");
: if (c instanceof EReference && ((EReference) c).getName().equals("detailedProcess"))

and I don't understand quite why I need to go to the eClass for some, but not
for others.  For the EReferences, eClass() returns EReference... which I guess
is expected.

In the model, I iterate over the /contents/ of the the BusinessArchitecture
object (presumably, a list of structural features).  For each, I can test:

: assertEquals(e.eClass().getName(), "Process");

This is what the Ecore reflective editor gives me: the name of the Eclass.  But
a "Process" in the model also has a name.  The editor gets it from
getLabelFeature and eGet above.

getLabelFeature search for a plausible feature to use as a label: if it's a
"name" attribute or if it's a String.

So I can do:

: e.eGet(e.eClass().getEStructuralFeature("name"))

to get the name of each Process instance.  Similarly, to get the detailedProcess
ref:

: e.eGet(e.eClass().getEStructuralFeature("detailedProcess"))

At first I was surprised with the results:

#+BEGIN_EXAMPLE
fr.inria.atlanmod.emfviews.elements.ReproduceElementImpl@72b10258 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@6113a26f (name: Process) (instanceClassName: null) (abstract: false, interface: false))
null
null
null
null
null
null
null
null
null
null
#+END_EXAMPLE

Only one reference went somewhere, the others null?

But then I opened the model in Modisco, and it turns out that, yes, only the
first process "Booking a trip" has a detailedProcess that leads somewhere.  All
the others are empty references.

Interestingly, even though it's a reference, we don't get an empty list when
there are no elements, or a list when there is only one element.  We get a list
only for two or more elements.

** Removing the correspondenceModelBase in the EView file          :emfviews:
This should be the simplest task on the list.

With the test written and the coverage tool, I can see that: 1) we never
actually do anything with the correspondenceModelBase in Viewtype (the code is
commented out), and 2) removing the correspondenceModelBase in Eview does not
fail the test.

That's because, if we don't specify a model base, we'll just use the existing
correspondence model.

On the other hand, if we do specify the model base, we rewrite the
correspondence model every time.  Except, when the file does not exist (?!).
Putting an empty file there works, which is a bit... meh.  The limitation is due
to getting the URI from finding the file first, rather than just constructing
the URI without looking if there's a file there.

Using createPlatformResourceURI fixes it.

** Getting filters from the virtual links XMI instead of the Ecore :emfviews:
This is slightly more involved.  At the moment, we filter the elements at the
metamodel level, getting the filters from an Ecore file.

For each contributing metamodel, we:

- copy it to our virtual resource set
- remove any feature matching a filter
- load the correspondence model and add associations

What we should do instead is to get the filters from the virtual links model,
and use them to remove features from the metamodels.

So, for each contributing metamodel, we should:

- copy it to our virtual resource set
- load the correspondence model
- remove any feature matching a filter
- add associations

Although, since we specify the elements to be filtered in a different format, we
must change the matching accordingly.  In the Ecore, we did the matching
structurally.  But in the virtual links metamodel, we have only 3 pieces of data
to match the filter element reference:

: <linkedElements elementRef="//Process" modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0" name="Process"/>

Clearly, we are losing the hierarchical component here.  Though, maybe
"elementRef" is actually intended to be XPath?  If so, I think it means
"any node named Process", which is not more information than "name", but at
least if it's used as XPath you could be more precise than that I guess.

It seems the element ref is used by the links projector in getReferencedObject:

: r.getEObject(elementRef);

So, no XPath then.  Well, regardless, I think I'll go with a pretty basic scheme
to begin with:

: <linkedElements elementRef="contentfwk.BusinessArchitecture.drivers"
:                 modelRef="http://www.obeonetwork.org/dsl/togaf/contentfwk/9.0.0"
:                 name="drivers"/>

This should give enough information to filter the correct element without ambiguity.

Writing the search was a bit more tricky than expected, due to it being a tree.
Using a queue did it.  Not the most readable code, but it works.

Test pass, elements are filtered on the metamodel and the model.

* [2017-05-29 lun.]
** Small morning refactorings                                      :emfviews:
Removing the unnecessary HashMap as arguments to load and save for a resource.
EMF handles null arguments just fine.

On a side note, there are multiple cases of calling load with an explicit input
stream, but the suggested way to load a resource is to first give it an URI,
then call load(null).

In fact, sometimes we call load with an explicit input stream, /and then/ set
the URI.

Now to rename a few things for better coherence with the paper:

- Viewtype to Viewpoint.  That was a pain, as we had also many example files
  with the eviewtype extension, and files that referred to them...  These
  examples might not be even working anymore for all I know, but hey, coherence.

- "Correspondence model base" to "Matching model".  I guess "correspondence" was
  alright, although different than the paper, but "matching" is shorter.  And we
  had many thing beginning with 'c' already, it was getting Confusing.

At this point I discover projectile-replace: much faster!  Though it doesn't
seem to save files automatically, there is projectile-save-project-buffers;
launching magit-status also prompts to save them individually.  Still leaving
the Java refactorings to Eclipse, since I have more faith in its correctness.

- "Correspondence model" to "Weaving model".  The correspondence model is
  actually just an instance of the virtual links metamodel.  But I suppose
  there's no reason to couple the two, so "weaving" will do (besides, it's
  shorter).

- "Composition metamodel" to "viewpoint", since that's what it is.

- "Contributing (meta)models" to "contributing".  Hmm, this one will wait for
  the unification of EView and Viewpoint, where we will have a single
  "contributingModel" line.  For coherence with the other properties in an
  EView/EViewpoint file, the suffix should stay, at least for the time being.


These morning refactorings went well in the afternoon I guess.

* [2017-05-30 mar.]
** Making Viewpoint a virtual metamodel                            :emfviews:
At the moment, to construct the Viewpoint, we merely clone the contributing
packages into a virtual resource set, then remove filtered attributes and add
references corresponding to virtual associations.

The idea is to use what we have in View already to construct a Viewpoint, by
feeding it Ecore as a metamodel.  First difficulty is that EView refers to a
Viewpoint.  If we use EView to represent a Viewpoint at the metamodel level,
then it would still need a Viewpoint.

What is the Viewpoint used for anyway?

In EView.doLoad, we load a full Viewpoint from the "viewpoint" property.  We
then use this viewpoint to get a reference to the matching model and the list of
contributing metamodels.

This list of contributing metamodels is used by View to populate the virtual
resource set of the View/EView (the attribute is declared by View, instantiated
by EView, and populated by View.loadContributingMetamodels).

It seems similar to what Viewpoint is doing, except we are /not/ copying the
packages we put in the virtual resource set of View.

So at this point, we have a virtual resource set with the original packages,
/and/ a Viewpoint with its own virtual resource set containing clones of the
exact same packages, albeit modified by virtual links.

How are both used?  First, the content of the virtual resource set of View is
only used by View.getContributingModels, that is: to produce a list of the
resources contained by the resource set (but we filter out Ecore resources for
some reason).

This list is used by other getters of View, and also in doSave.  Most
interestingly, its contents are passed unfiltered to the constructor of a
MetamodelManager in EView.doLoad, along with the viewpoint.  Another point of
use of interest is View.setVirtualContents: the (filtered) list is used to
populate the virtual contents with translated virtual elements.

The viewpoint of EView is /only/ used to pass to the MetamodelManager.  So it
seems this is where the link between concrete metamodels, virtual metamodels,
models and virtual models happen.

In fact, the third argument to the constructor of MetamodelManager takes a
reference to the EView instance that created it... the EView holds a reference
to the MetamodelManager, and that's the only class where the manager is
instantiated.  Seems to me they are rather coupled.

MetamodelManager holds maps of concrete to virtual features as I have [[*Investigating View/Eview][previously
covered]].

It uses the EView reference in only one place, this test:

#+BEGIN_SRC java
 if (virtualModel != null && virtualModel.getResourceSet() != null
        && virtualModel.getResourceSet().getPackageRegistry() != null
        && virtualModel.getResourceSet().getPackageRegistry().values() != null
        && virtualModel.getResourceSet().getPackageRegistry().values().size() > 0) {
      Collection<Object> listOfVirtualMMPackages =
          virtualModel.getResourceSet().getPackageRegistry().values();
#+END_SRC

Written in a rather defensive style, this list of virtual metamodel packages is
the same thing that we pass in the first argument to the constructor... which
the constructor collects into a list of EPackage: contributingMetamodels.

Now, coverage for the test I've written tells me that the test returns false
anyway, because getResourceSet() returns null.  So at the moment, we don't do
anything at all with the EView reference.

We do use the other two arguments: the list of (unaltered) contributing
metamodel packages is put into contributingMetamodels, and the viewpoint is used
to populate the compositionClassesByName, where we put the altered metamodel
classes.

Then, in buildMaps, we iterate over each EClass from the contributing
metamodels, and if we find an EClass of the same name, belonging to the same
package, in the map of composition classes (from the Viewpoint), then we add it
to the concreteToVirtualClass map, and iterate on their features.

It's the same thing for mapFeatures: for each concrete feature in the
contributing EClass, if it also exists (by name) in the virtual EClass (the
EClass from the viewpoint), then we add the feature to two maps:
virtualToConcreteFeature and concreteToVirtualFeature.

I'm puzzled by two things: why we use names for comparisons, and why we don't
just iterate on the virtual metamodel.

Using names is brittle, and leads to the redundant checks for classes that
belong to the same package.  Also, is there any guarantee of name uniqueness in
EMF?  It looks like there is: adding a feature or class with the name of an
existing one will fail the validation.  So that's a safe assumption.  We can use
names, but it might be best to have them qualified.

Iterating on the virtual metamodel: since we will only add classes and features
present in the virtual metamodel, and we will add all of them (save for
associations), it might make more sense to iterate on them to start with, and
just get the corresponding class/feature from the qualified name in the
contributing metamodels.

Or, do a parallel descent in the trees.

* [2017-05-31 mer.]
** Re: How are virtual model attributes filtered out?              :emfviews:
Coming back to [[*How are virtual model attributes filtered out?][How are virtual model attributes filtered out?]].  I've established
that when attributes are absent in the viewpoint, they will be filtered in the
models.  But where is the connection taking place?

Stepping into an eGet call to find out where it plugs into our code.

Interesting: an eGet(EStructuralFeature) call is delegated to another eGet,
which looks up the feature ID and delegate to an eGet(int).  But in that one,
the feature ID is turned into ... an EStructuralFeature!  This the exact same
object given to the first eGet call in my debug trace.

After a while, we end up in ReproduceRule.get, and since I'm testing a virtual
association feature, in ReproduceElementImpl.getVirtualAssociation.  In this
case, it's a single reference, so this just virtualizes the target element.

Note: we cache virtualized elements in a map, but EStore also has his own cache
(see isCaching).

In eGet, if the feature is absent from the metamodel (filtered out), then EMF
raises an exception.

When we iterate on the contents of BusinessArchitecture using eContents, we
iterate on the structural features of the eClass.  So this just looks up in the
Viewpoint.

Since EMF uses the structure of the metamodel to iterate on the actual values of
the model, when they are filtered at the metamodel level, they do not appear in
the virtual model.

However, does this mean that there is a way to access these values in the model
if you know the feature name?

* [2017-06-02 ven.]
** Writing a test for modifying models                             :emfviews:
Since we have a virtual model, it should reflect changes in the models, right?
I'm not sure we support that yet, but I figure that there's nothing in the code
that should prevent it.  Caching, maybe.

I've written a small test, and it looks like changing the model does /not/
propagate the changes to the virtual model.

What blocks it?

: vea_labels.get(0).eGet(label_name)

I would expect the first ~get~ to return a proxy to the concrete object, and the
eGet would be delegated to the concrete object.

What's happening: we end up in ReproduceRule.get, where we get the concrete
feature, and the concrete element:

#+BEGIN_SRC java
EStructuralFeature cFeature = vElement.getConcreteFeature(feature);
Object value = vElement.getConcreteElement().eGet(cFeature);
if (feature instanceof EReference) {
  if (feature.isMany()) {
    value = new VirtualModelList<>(object, feature, Arrays.asList((List<EObject>) value));
    if (index != NO_INDEX) {
      value = ((VirtualModelList<EObject>) value).get(index);
#+END_SRC

Since the concrete element is a reference with >1 multiplicity, we create a
virtual list.  Hmm, that means we create a /new/ virtual list every time the a
reference is requested.  Maybe that's how EMF does it as well, providing an
immutable list.  But that does not seem necessary, since it's just a proxy in
this case, we could instantiate it once and save it for further calls, since it
will only delegate to a concrete EList.  Anyway.

We create the virtual list, and if the index is ~> -1~, we return the correct
value, otherwise we return the whole list.

Inside the virtual list, we walk the sublists to get the concrete element:

#+BEGIN_SRC java
EObject concreteEO = (EObject) l.get(k);
EObject virtualEO = virtualModel.getVirtualLinkManager().getVirtualElement(concreteEO);
#+END_SRC

Here, my concrete element is the Label EClass, and the virtual element is a
ReproduceElement containing the concrete element.

Finally, we translate it (again?) to a virtual element before returning
it... hmm.

#+BEGIN_SRC java
return (E) virtualModel.translateToVirtualElement((EObject) l.get(index));
#+END_SRC

Oh, I see.  The first part of the code only wants to find out the true index of
the concrete element, since we can have filter element that should be hidden.
Then, once we have the index, we translate the concrete element to a virtual one
and return it.

So: the ~get(0)~ call returns the Label EClass wrapped in a ReproduceElement.
So far so good.  Except, the concrete element is not the same Label instance as
the one in the concrete model.

Which kind of make sense: to construct the virtual model, we loaded the
resource.  To construct the model, we also loaded the resource from XMI, a
second time.  There's no reason for the instances to be the same.

So what's happening is we are modifying a label instance in memory, but it's
completely disconnected from the instance kept in the virtual model.

The virtual model makes no guarantee to hook into every instance of the model to
watch for changes.  I guess we could use the notifying architecture of EMF..

Our view would be updated if we saved the changes to the model, and recreated
the view... but that's not really an update anymore.

But let's follow the ~eGet~ call.  We end up in EStoreEObjectImpl.dynamicGet,
where:

#+BEGIN_SRC java
Object result = eSettings[dynamicFeatureID];
if (result == null) {
  // actually get the result and cache it
}
return result;
#+END_SRC

Oh oh.  So it /is/ caching values for us.  Here it finds the "Software kind" in
its cache and returns it.  If we remove the cached value, it goes to
ReproduceRule.get, where... the concrete value is "Software Kind".

So, yeah.  The above.  We are dealing with separate instances: the virtual model
is completely disconnected from the model, since they are loaded as separate
resources.

I'm not even sure that the virtual model /should/ reflect changes in this way.
At the very least, I would expect that changes to the underlying concrete models
held by the virtual model are reflected in the virtual model.

But we need to access the contributing models.  Let's do that.

: java.lang.ClassCastException: org.eclipse.emf.ecore.impl.DynamicEObjectImpl cannot be cast to contentfwk.EnterpriseArchitecture

Hmm that's interesting, I could cast to concrete instances when loading the
model myself, but when they are loaded by EView, they are dynamic objects...

Okay, okay, let's make it all dynamic access.

: org.junit.ComparisonFailure: expected:<[foo]> but was:<[Software Kind]>

Of course.  I'm guessing the EStore caching is the culprit here.  If I bypass
it...  Yep!  The test passes.  The change is reflected to the virtual model.

And adding:

#+BEGIN_SRC java
protected boolean eIsCaching() {
  return false;
}
#+END_SRC

to our ReproduceElementImpl is sufficient to turn caching off definitely.

But I'm not sure in what scenario one would peek at the contributing models this
way, rather than taking them straight from the resource.

The notifying approach is more promising, /if/ you can subscribe to changes from
/every instances/ of the same model, which I don't think you easily can.

Maybe hooking into the resource factory or something.  But that's out of scope.

** Accessing a filtered feature in the models                      :emfviews:
Filtered features are removed from the metamodel, but they don't seem to affect
the models in any way.  There /is/ code for skipping instances of FilterElement
in the virtual model list, but we don't construct any instances of these at the
model level.

So, in theory, we should be able to access the content of a filtered feature.
But maybe EMF does not have any mechanism to let us do so.

Wrote a test.  If you give eGet a feature object, it will convert it to a
feature ID using the eAllStructuralFeatures array.  That array is built from the
metamodel, so again, it will fail to find the feature.

I'm not sure there's a way around it.  But I'm unclear on where the eClass for a
model is coming from.  When you load a model, how do we instruct EMF to use the
filtered metamodels?  More questions...

* [2017-06-06 mar.]
** Following the trail while it's hot                              :emfviews:
Picking up where I left things last time.

The eClass for our view is inside the eProperties of the ReproduceElementImpl.
That field comes from EStoreEObjectImpl, and the class is set in
ReproduceElementImpl.init:

:    this.eSetClass(eClass);

The init method is called by the two constructors, but one constructor is
seemingly unused.  So we are left with:

#+BEGIN_SRC java
public ReproduceElementImpl(View vModel, EObject concreteElement) {
  super();
  EClass tempEClass =
      vModel.getMetamodelManager().translateToVirtualEClass(concreteElement.eClass());
  this.init(vModel, concreteElement, tempEClass);
}
#+END_SRC

The eClass used by the reproduce element is looked up in the maps built by the
metamodel manager.  That's where we assign the virtual metamodel with the
filtered features to the virtual model.

Trying to add the feature to the eClass using:

: vba.eClass().getEStructuralFeatures().add(f);

I get a nice array index out of bounds exception, since the eSettings array used
to lookup the feature is not extended when we add the feature as above.

I'm not sure it's something you'd want to do anyway.  But it doesn't work.

So I'll assume that we cannot access features filtered by the virtual
metamodel.  Good thing.

On the other hand, following the code I was reminded of something interesting:
when we filter a reference, what happens to its opposite (it if exists?).  I'm
guessing: nothing, so EMF will probably complain if we try to reach the
opposite.

Let's try it.

Hmm, inconveniently, none of the features we already filter have opposites.
Let's make a new, minimal, test.

Created a minimal ECore metamodel.  Now I need a model.  Here is the code to
generate it:

#+BEGIN_SRC java
String mmURI = "/viewpoint-test/metamodels/minimalref.ecore";
EPackage p = (EPackage) (new ResourceSetImpl()
    .getResource(URI.createPlatformResourceURI(mmURI, true), true).getContents().get(0));

EFactory f = p.getEFactoryInstance();
EObject a = f.create((EClass) p.eContents().get(0));
EClass bClass = (EClass) p.eContents().get(1);
EObject b1 = f.create(bClass);
b1.eSet((EStructuralFeature) bClass.eContents().get(0), a);
EObject b2 = f.create(bClass);
b2.eSet((EStructuralFeature) bClass.eContents().get(0), a);

Resource r = (new ResourceSetImpl()).createResource(URI
    .createPlatformResourceURI("/viewpoint-test/models/minimal.xmi", true));
r.getContents().add(a);
r.getContents().add(b1);
r.getContents().add(b2);
r.save(null);
#+END_SRC

Now the eviewpoint and eview files.  Do I need multiple metamodels in the
eviewpoint?  I think I will trigger the extension part of the code in Viewpoint
if I don't.  But it doesn't matter for filters, since these are applied
regardless.

Ugghh, spent 10 minutes debugging a typo in the modelRef of a linkedElement from
the weaving XMI...  Some validation of these files could be helpful.

Now I need an ECL file.. even though I'm only using filters, so technically I
don't need it.  Wait.  I don't need the ECL file for the view... if it doesn't
exist we'll just skip it.  But I do need an XMI for the view as well... an empty
one will do.

Okay, I can load the view without errors.  Now, I just need to check that the
reference is filtered, that it's opposite is not, and then get the opposite of
the opposite to see what happens.

Oh, interesting.  If I filter out a containment reference: A contains a number
of B, then the view will only contain A.  Since there is no way to access the B
anymore, I cannot access the opposite ref.

Let's try a non-containment then.

Strangely, ~view.getContents()~ returns a list with only one reproduce element,
for the A class from the metamodel.  Even though I haven't filtered anything
yet!

Okay, in View.setVirtualContents, we do:

: oneOftheSublists.add(translateToVirtualElement(r.getContents().get(0)));

Except, with the files I have created for this example, r.getContents() returns
the list [A, B, B], and get(0) returns just the A instance.  So that's why only
A appears in the virtual model contents.

Now, in the working example, getContents returns [EnterpriseArchiteture].  This
is coherent with the model XMI, where everything is wrapped in an
EntrepriseArchitecture tag.  Same for the other ReqIf and BPMN model: they are
wrapped in ReqIf and BPMN tags.

Hmm.  Actually, they are wrapped because that's how the model are made: they
each contain a class with containment references where everything should go.

But that means the View code will only work with such models.  Why not take
everything contained by the resource rather than just the first object?

Seeing as we already have a VirtualContents class that takes sublists...

Okay, made the change.  It shouldn't affect the existing examples since the
behavior is the same for resources containing only one element.  Now we just
don't ignore the other ones.

Wrote a test.  The filtered reference is not available on the metamodel.  Its
opposite is still present.  I think that's acceptable, if we say that views are
"lightweight", that they do not enforce EMF invariants.

However, we can get a hold of the filtered reference by the getEOpposite method
on its opposite.  That's weird.  I would expect it to return null, given that
it's filtered at the metamodel level.  Where is this getEOpposite call looking
for it?  Maybe it's cached?

But more worrying, I would expect to be able to follow the opposite reference.
That currently does an NPE in EStructuralFeatureImpl.getSettingsDelegate.

#+BEGIN_SRC java
EReference eOpposite = getEOpposite();
if (eOpposite != null)
{
  eOpposite.getEContainingClass().getFeatureCount();
}
#+END_SRC

First of all, why is this code even there?  It accesses the feature count... and
does nothing with it.

Regardless, getEContainingClass returns null... but that's not even a containing
reference.  Weird.

* [2017-06-07 mer.]
** EOpposite is set when the model is loaded                   :emfviews:emf:
That's the first answer.  When loading the XMI, bidirectional references set
their opposites to each other.

So when we filter out one part of the reference, the other still has its
eOpposite field set.

Second problem was the null EContainingClass.  It should return the class
containing the feature.  But since the feature is filtered out, it has no
containing class anymore.

Actually, bypassing the code:

#+BEGIN_SRC java
if (eOpposite != null)
{
  eOpposite.getEContainingClass().getFeatureCount();
}
#+END_SRC

we do get access to the feature value, and the test succeeds.  So this bit is
problematic.

I really don't know why it's there.  I understand that this getter is memoized,
so calling it is a way to force the computation of whatever underlying data it
returns.  But if you need to force the computation, it's because you are peeking
under the sheets of the interface; ergo, doing something you shouldn't.  Or, you
don't really need to force the computation, and this code is useless.

Doing a bit of git spellhunking...

: http://git.eclipse.org/c/emf/org.eclipse.emf.git/
: git://git.eclipse.org/gitroot/emf/org.eclipse.emf.git

Found [[orgit-rev:~/proj/org.eclipse.emf/::22137e7][one commit]] from 2005 (!) where the code was updated, but the strange ~if~
was already there:

#+BEGIN_SRC diff
       if (eOpposite != null)
       {
-        eOpposite.getEContainingClass().getEAllStructuralFeatures();
+        eOpposite.getEContainingClass().getFeatureCount();
       }
#+END_SRC

Before that, I get the initial git commit from 2004 when the repo was created by
splitting from a previous CVS probably (there are .cvsignore files lying
around).  From what I can find, the CVS repository is now unavailable, so I
won't get any history beyond that.

** Cleaning up URI loading                                         :emfviews:
This was getting annoying to deal with a dummy workspace just to have the test
resources.

Asked G about it, he suggested I use createURI instead of
createPlatformResourceURI, to avoid being tied to the workspace.  We tried it
together, and using relative paths with createURI will load the files from the
current plugin.

Had to make changes in multiple places where we previously used platform URI, or
worse, findMember on the workspace.  Now it's more homogeneous.

He also suggested we pass URI to the EMFViews core instead of strings, so that
we leave the problem of creating and resolving them to the client.  I agree, and
would even go as far as passing resources directly.

*** TODO Investigate duplication of model loading from XMI
Since in Viewpoint we pass around URI strings when we really want to deal with
EPackages, there may be some duplication where we load a package from the XMI
instead of getting an EPackage directly, or getting it from a registry.

That seems like unnecessary work, and a potential source of bugs (since we have
clones of models lying around, so strict equality wouldn't work).

* [2017-06-09 ven.]
** Trying out Eclim for controlling Eclipse from Emacs        :emacs:eclipse:
Out of the box I set the bar a little too high for Eclim, since I'm running
Eclipse 4.7 M6, and only 4.6 is supported at the moment.

There is a development branch for 4.7 on the Git.  I try it out, follow the
build from source guide.  But it fails to build on my Eclipse config, since I
have a separate configuration folder and platform folder.

Ok ok.  Maybe I should try a plain Eclipse to see if it's even worth the
trouble.  I'm afraid it doesn't have useful stuff like Javadoc on hover (maybe
using Eldoc?).  Let's see.

It installs with 4.6.  Now I run the eclimd daemon from inside Eclipse
(View->Eclimd).

Not that slow.  You can get Javadoc for a type, not on hover, but with a
binding.  Auto-completion seems to work, although you don't have the Javadoc for
completion items.

I think the way windows are created and (not) disposed for each function is more
annoying than helpful.  I'll keep my current setup.

** Using Eview for metamodels                                      :emfviews:
To use EView for the metamodel level, we would need to provide a viewpoint.  The
viewpoint is used to populate the maps in the metamodel manager; essentially,
its role is to assert what features are present on the viewpoint.

If the Eview is used for the metamodel, its viewpoint should be the Ecore
metamodel itself.  Maybe I can try building a test around that.

* [2017-06-12 lun.]
** Made a class diagram of emfviews.core                          :emfviews:
A bit hairy.  PlantUML uses GraphViz behind the scenes, so the layout engine
quickly shows its limits when you get a dozen of boxes.

Regardless, it helps to see the whole picture.

I think I want a sequence diagram of Viewpoint.doLoad, and most importantly,
EView.doLoad.  Probably an object diagram of everything created by
EView/Viewpoint for the minimal example.
